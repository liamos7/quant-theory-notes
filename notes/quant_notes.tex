\documentclass{report}
\usepackage{graphicx} % Required for inserting images
\usepackage{amsmath} % AMS Math Package
\usepackage{amsthm} % Theorem Formatting
\usepackage{amssymb} % Math symbols such as \mathbb
\usepackage[hidelinks]{hyperref}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{filecontents}
\usepackage{subcaption}% Allows for eps images
\usepackage[table,xcdraw]{xcolor}
\usepackage{tikz}
\usepackage{siunitx}
\usepackage{tabularx} % Allows for table with custom column width
\usepackage{lipsum}
\usepackage{parskip}
\usepackage{booktabs}

\title{Quantitative Finance: Mathematical Foundations and Models}
\author{Liam O'Shaughnessy}
\date{December 2025}

\begin{document}

\maketitle

\chapter*{Preface}
These notes were written to consolidate the mathematical foundations of modern quantitative finance, with an emphasis on arbitrage pricing, stochastic calculus, and practical modeling considerations. They are not intended as a textbook, but as a structured reference bridging theory and implementation. This is more theoretically and academically focused, which I wanted to make sure I had a thorough understanding of - I would like to continue developing practical approaches to effectuate these methods.

\tableofcontents

\pagenumbering{arabic}

\chapter{Introduction}
This has been my attempt to touch on most topics relevent to quantitative finance theory. I start with the mathematics of modeling assets as stochastic processes, which culminates with the Kolmogorov equations/generator framework for Markov processes that gets used for pricing. I then formalize risk-neutral pricing and how the Girsanov's theorem establishes the criteria to change to a martingale measure. In the next chapter, I price flavors of options, and discuss models for fitting implied volatility. Following that, I model rates stochastically, and introduce credit and counterparty risk for complete pricing. I then address portfolio management and risk assessment, as well as market microstructure dynamics. I spend three chapters on statistical and computational techniques to solve equations detailed earlier and better model data, such as time series analysis, numerical methods, and machine learning. Finally, I include a discussion on "when things go wrong".

These notes are drawn from the following books and resources: \textit{Stochastic Calculus for Finance II} by Shreve, \textit{Arbitrage in Continuous Time} by Björk, \textit{Probability Theory} by Sinai and Koralov, \textit{Applied Stochastic Analysis} by Holmes-Cerfon, \textit{Brownian Motion} by Schilling and Partzsch, \textit{Kolmogorov Equations} by Ludvigsson, \textit{All of Statistics} by Wasserman, \textit{Convex Optimization} by Boyd and Vandenberghe, \textit{Monte Carlo Methods in Financial Engineering} by Glasserman, 1\textit{Advances in Financial Machine Learning} by de Prado, 8.S096 on MIT OCW, ECO362 from Princeton, Time Series Analysis from Baruch's MFE program, \textit{Credit Risk Modeling} by Hurd from McMaster, and, of course, ChatGPT.


\chapter{Mathematical Foundations}

\textbf{Motivation.} The first part of "quantitative finance" is "quantitative"! The purpose of this section is to develop the mathematical engine that will be applied to assets.

\section{Probability Theory}
\textbf{Motivation.} In order to model random events in the real world, the probabilistic framework must be rigorously constructed. As a result, the Kolmogorov axioms are used as a starting point for a measure-theoretic conception of probability, which will be essential for modeling stochastic processes.
\subsection{Axioms of Probability}

\textbf{Definition.} Let $\Omega$ be a non-empty set, the \textbf{sample space} of events, and $\mathcal{F}$ a collection of subsets of $\Omega$. $\mathcal{F}$ is called a \textbf{$\sigma$-algebra} if the empty set is in $\mathcal{F}$, complements of sets in $\mathcal{F}$ are in $\mathcal{F}$, and countably infinite unions of sets in $\mathcal{F}$ are in $\mathcal{F}$. The entries of $\mathcal{F}$ are called \textbf{measurable sets}, and $(\Omega, \mathcal{F})$ is called a \textbf{measurable space}.

\textbf{Definition.} For $A$ a collection of subsets of $\Omega$, the \textbf{$\sigma$-algebra generated by $A$}, $\sigma(A)$, is the intersection of all $\sigma$-algebras containing $A$ - that is, the minimal algebra containing $A$. The \textbf{Borel $\sigma$-algebra} on $\mathbb{R}$, $\mathcal{B}(\mathbb{R})$, is the $\sigma$-algebra generated by open subsets of $\mathbb{R}$.

\textbf{Definition.} Let $\Omega$ be a non-empty set (the sample space) and $\mathcal{F}$ a $\sigma$-algebra on $\Omega$. Define $\mathbb{P}:\mathcal{F} \rightarrow[0,1]$ such that $P(\Omega)=1$ and $\mathbb{P}(\bigcup_n A_n) = \sum_n \mathbb{P}(A_n)$ for countably infinite, disjoint sets $A_n \in \mathcal{F}$. Then $\mathbb{P}$ is a \textbf{probability measure}, and $(\Omega, \mathcal{F}, \mathbb{P})$ is a \textbf{probability space}. \textbf{"Measure zero"} means that the event has probability zero, and \textbf{"almost surely"} means that the event has probability one.

\textbf{Definition.} Let $(\Omega, \mathcal{F})$ be a measurable space. Define a function $g: \Omega \rightarrow \mathbb{R}$. $f$ is \textbf{$\mathcal{F}$-measurable} if $\forall A \in \mathcal{B}(\mathbb{R}),g^{-1}(A) \in \mathcal{F}$. An $\mathcal{F}$-measurable on a probability space is called a \textbf{random variable}. A $\sigma$-algebra generated by a random variable $X$ is the preimage of $X$ of Borel sets
\begin{align}
\sigma(X) = \{X^{-1}(B) |B \in \mathcal{B}(\mathbb{R}) \},
\end{align}
that is, the smallest $\sigma$-algebra that makes $X$ measurable.

\textbf{Remark.} This is similar to continuity in topology, and is particularly nice here because the probability that the random variable takes some set of values is thus the measure of a set that is guaranteed to be in the initial $\sigma$-algebra.

\textbf{Example (Discrete probability space).}
Consider the experiment of tossing a fair coin twice. The sample space is
\begin{align}
\Omega = \{HH, HT, TH, TT\},
\end{align}
where $H$ and $T$ denote heads and tails, respectively.

Let $\mathcal{F} = 2^{\Omega}$ be the power set of $\Omega$, and define a probability measure $\mathbb{P}$ by assigning equal mass to each outcome:
\begin{align}
\mathbb{P}(\{\omega\}) = \frac{1}{4}, \qquad \omega \in \Omega.
\end{align}

Then $(\Omega, \mathcal{F}, \mathbb{P})$ is a probability space satisfying the axioms of probability. For example,
\begin{align}
\mathbb{P}(\{HH, HT\}) = \mathbb{P}(\{HH\}) + \mathbb{P}(\{HT\}) = \frac{1}{2}.
\end{align}

Define the random variable $X : \Omega \to \mathbb{R}$ by letting $X(\omega)$ be the number of heads observed. The induced $\sigma$-algebra $\sigma(X)$ partitions $\Omega$ into events corresponding to $X=0,1,2$.


\textbf{Definition.} Let $X$ be a random variable on probability space $(\Omega, \mathcal{F}, \mathbb{P})$. The \textbf{distribution measure of $X$}, $\mu_X$, is a probability measure that assigns to each Borel subset $B \subset \mathbb{R}$ the mass
\begin{align}
\mu_X(B) = \mathbb{P}(X\in B)= \mathbb{P}(\omega : X(\omega)\in B).
\end{align}
This encodes the equivalent information as the \textbf{cumulative distribution function}, $F(x) = \mathbb{P}(X \leq x)$.

\textbf{Definition.} The distribution measure $\mu_X$ on $X$, a random variable on probability space $(\Omega, \mathcal{F}, \mathbb{P})$, can admit a \textbf{density function} if there exists an $f(x)$ such that
\begin{align}
\mu_X[a,b] = \mathbb{P}(a \leq X \leq b) = \int_a^b f(x) dx.
\end{align}
Alternatively, if $X$ takes finite set of numbers as its image, then the \textbf{probability mass function} defines $p_i = \mathbb{P}(X=x_i)$ for all output values.

\textbf{Example.} A \textbf{Gaussian random variable} has density $\mathcal{N}(\mu,\sigma)$:
\begin{align}
    f(x) = \frac{1}{\sqrt{2\pi \sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}.
\end{align}
This is applicable in almost everything. 

An \textbf{exponential random variable} has density $\text{exp}(\lambda)$:
\begin{align}
    f(t) = \lambda e^{-\lambda t}, t \geq 0.
\end{align}
This is applicable in modeling the probability of first arrival times. The exponential random variable is said to be \emph{memoryless}. Consider $\tau \sim \text{exp}(\lambda)$. Then
\begin{align}
    \mathbb{P}(\tau > t + s | \tau > s) = \frac{\mathbb{P}(\tau > t + s,\tau > s)}{\mathbb{P}(\tau > s)} = \frac{e^{-\lambda(t+s)}}{e^{-\lambda s}} = e^{- \lambda t}.
\end{align}

A \textbf{Poisson random variable} has probability mass $\text{Pois}(\lambda)$:
\begin{align}
    f(k) = \frac{\lambda^k}{k!} e^{-\lambda }, k \in \mathbb{N}.
\end{align}
This is useful for counting the number of arrivals in a certain time window by setting $\lambda = rt$.

\textbf{Definition.} Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, $\mathcal{G}, \mathcal{H} \subset \mathcal{F}$ sub-algebras. $\mathcal{G},\mathcal{H}$ are said to be \textbf{independent} if, for all $A \in \mathcal{G},B\in \mathcal{H}$,
\begin{align}
\mathbb{P}(A \cap B) = \mathbb{P}(A)\mathbb{P}(B).
\end{align}
Two random variables are independent if the $\sigma$-algebras generated from them are independent, and a random variable and a $\sigma$-algebra are independent if the $\sigma$-algebra generated from the random variable is independent of the $\sigma$-algebra.

\subsection{Lebesgue Integration}

\textbf{Motivation.} We would like to integrate to find things like expectation, yet there is no obvious way to partition the domain (the sample space $\Omega$) as the Riemann integral would require, in contrast to the simple real x-axis. Since the y-axis is indeed the real numbers, we can partition that instead, and measure how much of the domain is assigned to each y point.

\textbf{Definition.} Let $X$ be a random variable on probability space $(\Omega, \mathcal{F}, \mathbb{P})$ taking values in the positive real interval $[a,b]$. Let $\Pi$ be a set of sub-points $y_1, y_2,...$ partitioning that interval. For each sub-interval $[y_{k-1},y_k]$, define $A_k = (\omega \in \Omega : y_{k-1} \leq X(\omega) \leq y_k)$. Then as the supremum of sub-point distances goes to zero, the following sum converges to the \textbf{Lebesgue integral}:
\begin{align}
\sum_k y_k \mathbb{P}(A_k) \rightarrow \int_\Omega X(\omega) d\mathbb{P}(\omega).
\end{align}
If $\mathbb{P}(X=\infty)>0, \int_\Omega X(\omega) d\mathbb{P}(\omega) = \infty$.

\textbf{Definition.} Previously, the range was limited to positive intervals so as to not introduce problems with reordering and convergence. If $X$ takes both positive and negative values, call $X^+(x) = \max (X(\omega),0),X^-(\omega) = \max (-X(\omega),0)$. If both of those have finite Lebesgue integrals, $X$ is called \textbf{integrable}, and
\begin{align}
\int_\Omega X(\omega) d\mathbb{P}(\omega) = \int_\Omega X^+(\omega) d\mathbb{P}(\omega) - \int_\Omega X^-(\omega) d\mathbb{P}(\omega).
\end{align}

\textbf{Theorem.} Let $X$ be a random variable on probability space $(\Omega, \mathcal{F}, \mathbb{P})$. Then $\int_\Omega |X(\omega) |d\mathbb{P}(\omega) < \infty \iff X$ is integrable.

\textit{Proof:} Beginning with the forwards direction, $|X| = X^+ + X^-; X^+,X^- \geq0$ so $X^+,X^- \leq |X|$. Hence, via comparison property (in reference texts), $\int_\Omega |X(\omega) |d\mathbb{P}(\omega) \geq \int_\Omega X^\pm(\omega) d\mathbb{P}(\omega)$. So, $\int_\Omega |X(\omega) |d\mathbb{P}(\omega) < \infty$  implies $\int_\Omega X^\pm(\omega) d\mathbb{P}(\omega) < \infty$, so $X$ is integrable. Now for backwards direction: using linearity, since $|X| = X^+ + X^-$, and both parts have finite integrals, $\int_\Omega |X(\omega) |d\mathbb{P}(\omega) < \infty$. \hfill $\square$

\textbf{Definition.} Let $X$ be a random variable on probability space $(\Omega, \mathcal{F}, \mathbb{P})$. Then the \textbf{expectation of $X$} is
\begin{align}
\mathbb{E}[X] = \int_\Omega X(\omega) d\mathbb{P}(\omega).
\end{align}

\textbf{Definition.} Let $X, Y$ be a random variables with finite expectation. The \textbf{variance} of $X$ is
\begin{align}
Var(X) = \mathbb{E}[(X-\mathbb{E}(X))^2].
\end{align}
The \textbf{covariance} of $X,Y$ is
\begin{align}
Cov(X,Y) =\mathbb{E}[(X-\mathbb{E}(X))(Y-\mathbb{E}(Y))].
\end{align}

\textbf{Theorem.} Let $X$ be a random variable on probability space $(\Omega, \mathcal{F}, \mathbb{P})$. Then, for some Borel-measurable function $g$, if $\int_\Omega |g(x)| d\mu_X(x)<\infty$, then
\begin{align}
\mathbb{E}[g(X)] = \int_\Omega g(X(\omega)) d\mathbb{P}(\omega) = \int_\mathcal{B} g(x) d\mu_X(x).
\end{align}
If $X$ has a density, then
\begin{align}
\mathbb{E}[g(X)] = \int_\mathbb{R} g(x) f(x) dx.
\end{align}

\textit{Proof idea (Standard machine).} Show this is true for indicator functions, then for nonnegative simple functions, then for non-negative Borel-measurable functions, and finally for general Borel-measurable functions, since it is known that non-negative measurable functions are the monotone limit from below of simple functions.

\subsection{Conditioning and Change of Measure}

\textbf{Definition.} Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, $\mathcal{G} \subset \mathcal{F}$ a sub-algebra, and $X$ a random variable. Then the \textbf{conditional expectation of $X$ given $\mathcal{G}$}, $\mathbb{E}[X|\mathcal{G}]$, is any random variable that is both $\mathcal{G}$-measurable, and for which, for all $A \subset \mathcal{G}$,
\begin{align}
\int_A\mathbb{E}[X|\mathcal{G}](\omega) d\mathbb{P}(\omega) = \int_A X(\omega) d\mathbb{P}(\omega).
\end{align}
This is known as partial averaging.

\textbf{Remark.} The intuition here is that this is the best estimate of $X$, restricted by the information of the sub-algebra.

\textbf{Proposition.} Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, $\mathcal{H} \subset\mathcal{G} \subset \mathcal{F}$ sub-algebras, and $X,Y$ integrable random variables. If $X$ is $\mathcal{G}$-measurable, then $\mathbb{E}[XY|\mathcal{G}] = X\mathbb{E}[Y|\mathcal{G}]$. Additionally, $\mathbb{E}[\mathbb{E}[X|\mathcal{G}]|\mathcal{H}] = \mathbb{E}[X|\mathcal{H}]$ (the tower property). If $X$ is independent of $\mathcal{G}$, then $\mathbb{E}[X|\mathcal{G}] = \mathbb{E}[X]$.

\textbf{Example.}
Consider two consecutive fair coin tosses with sample space
\begin{align}
\Omega = \{HH, HT, TH, TT\},
\end{align}
equipped with the uniform probability measure.

Define the random variable $X$ as the total number of heads in the two tosses. Let
\begin{align}
\mathcal{G} = \sigma(\text{first toss}),
\end{align}
so that $\mathcal{G}$ represents the information revealed by observing the outcome of the first toss.

The $\sigma$-algebra $\mathcal{G}$ has atoms
\begin{align}
\{HH, HT\} \quad \text{and} \quad \{TH, TT\}.
\end{align}

We compute the conditional expectation $\mathbb{E}[X \mid \mathcal{G}]$ by averaging $X$ over each atom. On $\{HH, HT\}$, the first toss is heads, and
\begin{align}
\mathbb{E}[X \mid \mathcal{G}] = \frac{2 + 1}{2} = \frac{3}{2}.
\end{align}
On $\{TH, TT\}$, the first toss is tails, and
\begin{align}
\mathbb{E}[X \mid \mathcal{G}] = \frac{1 + 0}{2} = \frac{1}{2}.
\end{align}

Thus,
\begin{align}
\mathbb{E}[X \mid \mathcal{G}] =
\begin{cases}
\frac{3}{2}, & \text{if the first toss is } H, \\
\frac{1}{2}, & \text{if the first toss is } T.
\end{cases}
\end{align}


\textbf{Theorem.} Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space. Let $Z$ be a non-negative random variable almost surely and $\mathbb{E}(Z)=1$. Then for $A \subset \mathcal{F}$,
\begin{align}
\widetilde{\mathbb{P}} = \int_A Z(\omega) d\mathbb{P}(\omega)
\end{align}
is also a probability measure. $Z$ is called the \textbf{Radon-Nikodym derivative}, and facilitates a change of measure. Therefore, the expectation can be written as
\begin{align}
    \widetilde{\mathbb{E}}[X] = \mathbb{E}[XZ].
\end{align}

\subsection{Inference}
\textbf{Definition.} Let $\{X_1,X_2,...\}$ be a sequence of random variables. $\{X_n\}$ are called \textbf{independent and identically distributed (i.i.d.)} if all variables are independent of each other, and all variables have the same distribution function.

\textbf{Definition.} Let $\{X_n\}$ be a sequence of random variables, and let $X$ be another random variable. Then the sequence \textbf{converges in probability} if
\begin{align}
    \lim_{n\rightarrow \infty} \mathbb{P}(|X_n-X|>\epsilon) = 0, \forall \epsilon>0.
\end{align}
The sequence \textbf{converges in distribution} if, for distribution functions
\begin{align}
    \lim_{n\rightarrow \infty} F_n(x) = F(x), 
\end{align}
for all $x$ where $F(x)$ is continuous.

\textbf{Theorem (Weak Law of Large Numbers).} Let $\{X_n\}$ be a sequence of i.i.d. random variables with $\mathbb{E}[X_n]=\mu$. Then the sample mean $\Bar{X}$ converges in probability to the true mean:
\begin{align}
    \lim_{n\rightarrow \infty} \mathbb{P}(|(\frac{1}{n}\sum_{i=1}^nX_i)-\mu|>\epsilon) = 0.
\end{align}

\textbf{Theorem (Central Limit).} Let $\{X_n\}$ be a sequence of i.i.d. random variables with $\mathbb{E}[X_n]=\mu, Var[X_n]=\sigma^2$. Then the following converges in distribution to the standard normal distribution $\mathcal{N}(0,1)$:
\begin{align}
    Z_n = \frac{\Bar{X}_n-\mu}{\sqrt{Var[\Bar{X}_n]}} = \frac{\sqrt{n}(\Bar{X}_n-\mu)}{\sigma}.
\end{align}
Alternatively, this can be stated as
\begin{align}
    \lim _{n\rightarrow\infty}\mathbb{P}(Z_n \leq z) = \int_{-\infty}^z \frac{1}{\sqrt{2\pi}}e^{-x^2/2}dx.
\end{align}



\section{Stochastic Processes}
\textbf{Motivation.} In the real world, random processes occur over ranges of time, rather than simply being one variable. The conception of a family of random variables with a time parameter leads to the idea of a stochastic process, which is used to model the randomness in stock prices.
\subsection{Foundations of Stochastic Processes}

\textbf{Definition.} Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, and let $X(t): \Omega \rightarrow \mathbb{R}^d$ be a family of random variables, indexed by parameter $t \in T$, a parameter set (take $T$ a field such as the real ). Then $X(t)$ is called a \textbf{stochastic process}.

\textbf{Definition.} Let $\widetilde{\Omega}$ be the set of all functions $\widetilde{\omega}:T \rightarrow \mathbb{R}^d$ from the parameter set to the real numbers. For a finite set of points $\{t_1,...,t_k\}$ in the parameter set and a Borel set $A\in \mathcal{B}(\mathbb{R}^k)$, call a \textbf{finite-dimensional cylinder} the set of functions
\begin{align}
    \pi^{-1}_{t_1,...,t_k}(A) = \{ \widetilde{\omega}: (\widetilde{\omega}(t_1),...,\widetilde{\omega}(t_k)) \in A\}.
\end{align}
Additionally, call $\mathcal{B}_{t_1,...t_k}$ the set of all cylinders of fixed parameter set values, and allow $A$ to vary (this is a $\sigma$-algebra). Now call $\mathcal{B}$ the cylindrical $\sigma$-algebra, the smallest $\sigma$-algebra containing all $\mathcal{B}_{t_1,...t_k}$ for all choices of $k, t_1,...,t_k$:
\begin{align}
    \mathcal{B}= \sigma(\pi^{-1}_{t_1,...,t_k}(A): k \in \mathbb{N},t_i \in T, A\in \mathbb{R}^{kd}).
\end{align}
Then denote $(\widetilde{\Omega},\mathcal{B})$ the measurable space.

\textbf{Proposition.} Let $(\Omega, \mathcal{B}(\mathbb{R}^d)),(\widetilde{\Omega},\mathcal{B})$ be two measurable spaces. Define $\Phi:\Omega \rightarrow \widetilde{\Omega}$ as $\Phi(\omega)(t) = X(t)(\omega)$. Then this mapping is measurable, and thus there is a probability measure $\widetilde{\mathbb{P}} = \mathbb{P}\circ\Phi$ induced on $(\widetilde{\Omega},\mathcal{B})$.

\textbf{Definition.} Let $X(t)$ be a stochastic process. The \textbf{finite-dimensional distributions} are push forward measures into $\mathbb{R}^k$ defined by $\mathcal{B}_{t_1,...t_k}$:
\begin{align}
    \mathbb{P}^X_{t_1,...,t_k}(A)  = \mathbb{P}(\omega \in \Omega : (X(t_1)(\omega),...,X(t_k)(\omega))\in A)).
\end{align}

\textbf{Theorem (Kolmogorov Extension).} Let $\{\mathbb{P}_{t_1,...,t_k}\}$ be a family of finite-dimensional probability measures on $\mathcal{B}(\mathbb{R}^{dk})$. If the family of probability measures satisfies the following consistency conditions (permutation invariance and marginal consistency), taking $A \in \mathcal{B}(\mathbb{R}^k)$,
\begin{align}
    \mathbb{P}_{t_1,...,t_k}((\widetilde{\omega}(t_1),...,\widetilde{\omega}(t_k)) \in A) &= \mathbb{P}_{\pi(t_1,...,t_k)}(\pi((\widetilde{\omega}(t_1),...,\widetilde{\omega}(t_k))) \in A)\\
    \mathbb{P}_{t_1,...,t_k}((\widetilde{\omega}(t_1),...,\widetilde{\omega}(t_k)) \in A) &=\mathbb{P}_{t_1,...,t_{k+1}}((\widetilde{\omega}(t_1),...,\widetilde{\omega}(t_k)) \in A\times \mathbb{R}),
\end{align}
then there exists a probability measure $\widetilde{\mathbb{P}}$ on $(\widetilde{\Omega},\mathcal{B})$ whose finite-dimensional distributions coincide with the given family.

\textbf{Remark.} This is helpful in arguing that processes that satisfy certain properties exist, and is used to construct the Wiener process.

\subsection{Properties of Stochastic Processes}

\textbf{Definition.} Let $\Omega$ be a nonempty set. Assume that $\forall t \in T, \exists \mathcal{F}_t$ a $\sigma$-algebra. Additionally, assume that $s \leq t \implies \mathcal{F}_s \subset F(t)$. Then the collection of algebras $\mathcal{F}(t)$ is a \textbf{filtration}. If $X(t)$ is a collection of random variables indexed $[0,T]$, then $X(t)$ is called an \textbf{adapted stochastic process} if $X(t)$ is $\mathcal{F}(t)$-measurable for $t\in[0,T]$.

\textbf{Definition.} Let $\tau$ be a random variable taking values in $T$ on $(\Omega, \mathcal{F}, \mathbb{P})$ with a filtration $\mathcal{F}(t)$ defined for all $t \in T$. $\tau$ is called a \textbf{stopping time} if
\begin{align}
    \{\omega : \tau(\omega) \leq t\} = \{\tau \leq t\} \in \mathcal{F}(t), \forall t \in T.
\end{align}
A \textbf{stopped process} for $X(t)$ a stochastic process is
\begin{align}
    X(t \land \tau),
\end{align}
where $\land$ denotes the "min" operation.

\textbf{Remark.} $X(t)$ being $\mathcal{F}(t)$-measurable means that you can resolve all of the random variable's behavior at that time given the information known at that time. This is a way to formulate causality, since it means that information from after time $t$ cannot be used in determining $X(t)$. A stopping time being defined as such means that the decision to stop must be made only with information available at a given time. Any decision made by, say, a trader must occur at a stopping time.

\textbf{Definition.}  Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, $\mathcal{F}(t)$ a filtration of sub-$\sigma$-algebras of $\mathcal{F}$, and $M(t)$ an adapted stochastic process. $M(t)$ is called a \textbf{martingale} if, for all $s\leq t$,
\begin{align}
\mathbb{E}[M(t)|\mathcal{F}(s)] = M(s).
\end{align}
A \textbf{submartingale} has $\mathbb{E}[M(t)|\mathcal{F}(s)] \geq M(s)$, and a \textbf{supermartingale} has $\mathbb{E}[M(t)|\mathcal{F}(s)] \leq M(s)$.

\textbf{Proposition.} A stopped sub/super/martingale is still a sub/super/martingale.

\textbf{Theorem (Doob's Optional Stopping).} Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, $\mathcal{F}(t)$ a filtration, $M(t)$ a stochastic process, and $\tau$ a stopping time. Then $M(t)$ being a martingale is equivalent to, for any almost surely bounded $\tau$ with $\mathbb{E}[|M(\tau)|] < \infty$,
\begin{align}
    \mathbb{E}[M(\tau)]=\mathbb{E}[M(0)].
\end{align}

\textbf{Remark.} This theorem is often invoked to argue that it is impossible to truly win money on average at a fair game.

\textbf{Definition}: Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, and $\mathcal{F}(t)$ a filtration. Let $Z$ be an almost surely positive random variable with $\mathbb{E}(Z)=1$, and $\widetilde{\mathbb{P}}$ defined from the Radon-Nikodym derivative. Then, call the \textbf{Radon-Nikodym derivative process}
\begin{align}
    Z(t) = \mathbb{E}[Z|\mathcal{F}(t)].
\end{align}
This is a martingale, as, by conditional identities,
\begin{align}
    \mathbb{E}[Z|\mathcal{F}(t)] = \mathbb{E}[\mathbb{E}[Z|\mathcal{F}(s)]\mathcal{F}(t)] = \mathbb{E}[Z|\mathcal{F}(s)] = Z(s).
\end{align}

\textbf{Lemma.} Let $Z(t)$ be a Radon-Nikodym derivative process on a filtration, and $Y$ an $\mathcal{F}(t)$-measurable random variable. Then
\begin{align}
    \widetilde{\mathbb{E}}[Y] = \mathbb{E}[YZ(t)],
\end{align}
and
\begin{align}
    \widetilde{\mathbb{E}}[Y|\mathcal{F}(s)] = \frac{1}{Z(s)} \mathbb{E}[YZ(t)|\mathcal{F}(s)].
\end{align}
\textit{Proof.} For the first part, $\widetilde{\mathbb{E}}[Y] = \mathbb{E}[YZ] = \mathbb{E}[\mathbb{E}[YZ|\mathcal{F}(t)]]$, via the partial averaging property of conditional expectations. Since $Y$ is $\mathcal{F}(t)$-measurable, $\mathbb{E}[\mathbb{E}[YZ|\mathcal{F}(t)]] = \mathbb{E}[Y\mathbb{E}[Z|\mathcal{F}(t)]] = \mathbb{E}[YZ(t)] $. 

For the second part, let $A$ be an arbitrary subset of $\mathcal{F}(s)$. Then $\widetilde{\mathbb{E}}[\mathbb{I}_A\frac{1}{Z(s)} \mathbb{E}[YZ(t)|\mathcal{F}(s)]] = \mathbb{E}[\mathbb{E}[\mathbb{I}_AYZ(t)|\mathcal{F}(s)]]$, by the definition of the Radon-Nikodym derivative. Therefore, by partial averaging, this equals $\mathbb{E}[\mathbb{I}_AYZ(t)] = \widetilde{\mathbb{E}}[\mathbb{I}_AY]$. This is both $\mathcal{F}(s)$-measurable and partial averages, so this is indeed the conditional expectation. \hfill $\square$


\subsection{Markov Processes}
\textbf{Definition.}
Let $\{X(n)\}_{n\in\mathbb N}$ be a sequence of random variables taking values in a countable state space
$S=\{x_1,x_2,\dots\}$.  
The process $X(n)$ is called a \textbf{discrete-time Markov chain} if
\begin{align}
\mathbb P(X(n+1)=x_j \mid X(n),X(n-1), \dots)
=
\mathbb P(X(n+1)=x_j \mid X(n)=x_i).
\end{align}

The chain is called \textbf{time-homogeneous} if the transition probabilities do not depend on $n$. In this case,
there exists a \textbf{transition matrix}
\begin{align}
P = (p_{ij}), \qquad
p_{ij} = \mathbb P(X(n+1)=x_j \mid X(n)=x_i).
\end{align}

\textbf{Proposition.}
The Markov property implies that the entire probabilistic structure of the chain is determined by the
transition matrix and the initial distribution. In particular,
\begin{align}
\mathbb P(X(n)=x_j \mid X(0)=x_i) = (P^n)_{ij}.
\end{align}

\textbf{Definition.}
Let $(\Omega,\mathcal F,\mathbb P)$ be a probability space with filtration
$\{\mathcal F(t)\}_{t\ge0}$, and let $X(t)$ be an adapted stochastic process taking values in $\mathbb R^d$.
The process $X(t)$ is called a \textbf{Markov process (continuous time, continuous state space)} if, for all bounded Borel-measurable functions $f$,
and all $s\le t$,
\begin{align}
\mathbb E[f(X(t)) \mid \mathcal F(s)]
=
\mathbb E[f(X(t)) \mid X(s)].
\end{align}
Equivalently, there exists a Borel-measurable function $g$ such that
\begin{align}
\mathbb E[f(X(t)) \mid \mathcal F(s)] = g(X(s)).
\end{align}
The corresponding \textbf{transition probabilities} are defined by
\begin{align}
p(s,t,x,A) = \mathbb P(X(t)\in A \mid X(s)=x).
\end{align}
If the process is time-homogeneous, then
$p(s,t,x,A)=p(t-s,x,A)$.


\subsection{Brownian Motion}

\textbf{Motivation.} When modeling stocks, something must account for the random motion. That is modeled by Brownian motion, the characteristic zig-zag of a random walk.

\textbf{Theorem.} There exists a stochastic process $W(t)$ such that $W(0)=0$ almost surely, $W(t)$ is almost surely continuous, $W(t)$ has independent increments, and $W(t)-W(s) \sim \mathcal{N}(0,t-s)$. That process is called the \textbf{Wiener process} or \textbf{Brownian motion}. Multidimensional Brownian motion can likewise be defined as $W(t)= [W_1(t),W_2(t),...]$.

\textit{Proof idea.} Use Kolmogorov extension theorem.

\textbf{Definition.} Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space on which is defined $W(t)$. A \textbf{filtration for Brownian motion}, $\mathcal{F}(t)$ is a standard filtration such that, for $t \leq u$, $W(u)-W(t)$ is independent of $\mathcal{F}(t)$.

\textbf{Theorem.} Brownian motion is a martingale.

\textit{Proof.} $\mathbb{E}[W(t)|\mathcal{F}(s)] = \mathbb{E}[(W(t)-W(s)) + W(s)|\mathcal{F}(s)] = 0 + W(s)$, using independence and the $\mathcal{F}(s)$-measurability of $W(s)$. \hfill $\square$

\textbf{Theorem.} Brownian motion is a Markov process.

\textbf{Theorem.} Brownian motion accumulates \textbf{quadratic variation} - that is,
\begin{align}
[W,W](T) = \sum_j [W(t_{j+1})-W(t_j)]^2 \rightarrow T.
\end{align}
For multidimensional Brownian motion, this is instead $[W_i,W_j](t)=\delta^{ij}t$.


\textbf{Theorem (Lévy).} Let $M(t)$ be a martingale with respect to filtration $\mathcal{F}(t)$, such that $M(0)=0$, $M(t)$ has continuous paths, and $[M,M](t) = t$. Then $M(t)$ is a Brownian motion. For the multidimensional case, the statements are identical, except the quadratic variation becomes $[M_i,M_j](t)=\delta^{ij}t$

\textbf{Example (Scaling).}
Let $(W(t))_{t \ge 0}$ be a standard Brownian motion. For any constant $a > 0$, define the process
\begin{align}
\widetilde{W}(t) = \frac{1}{a} W(a^2t).
\end{align}
Then $\widetilde{W}(t)$ is also a standard Brownian motion. Indeed, $\widetilde{W}(0) = 0$, the paths are continuous as the underlying Brownian motion has not been muddled. $\widetilde{W}(t)$ is a martingale, as 
\begin{align}
    \mathbb{E}[\widetilde{W}(t)|\mathcal{F}(s)] = \mathbb{E}[\frac 1a W(a^2t)|\mathcal{F}(s)],
\end{align}
yet the natural filtration is $\mathcal{F}(s) = \sigma(\widetilde{W}(u), u \leq s) = \sigma(W(u), u \leq a^2s)$, so the expectation is
\begin{align}
    \frac 1a  \mathbb{E}[W(a^2t)|\sigma(W(u), u \leq a^2s].
\end{align}
Standard Brownian motion is a martingale with respect to its natural filtration, so this becomes $\frac 1a W(a^2 s)= \widetilde{W}(s)$, so this is a martingale.

Finally, we check quadratic variation:
\begin{align}
    [\frac 1a W(a^2t), \frac 1a W(a^2t)] = \frac{1}{a^2}a^2t = t,
\end{align}
Since the quadratic variation with arbitrary time input is that time input. Hence, via Lévy's theorem, this is indeed Brownian motion.

If an asset price follows a diffusion driven by Brownian motion, this scaling implies that volatility scales with the square root of time. In particular, if $\sigma_{\text{daily}}$ denotes daily volatility, then annualized volatility satisfies
\begin{align}
\sigma_{\text{annual}} \approx \sqrt{252}\,\sigma_{\text{daily}},
\end{align}
a convention widely used in financial practice.

\textbf{Proposition (Reflection).} Call $M(t)$ the maximum reached by $W(t)$ in the interval $[0,t]$, and call $\tau_m$ the first hitting time of the value $m$ by $W(t)$. Then,
\begin{align}
    \mathbb{P}(M(t)\geq a) = 2\mathbb{P}(W(t) \geq a),
\end{align}
and
\begin{align}
    \mathbb{P}(\tau_m \leq t, W(t) \leq w) = \mathbb{P}(W(t) \geq (2m - w)).
\end{align}


\section{Stochastic Calculus}

\textbf{Motivation.} Brownian motion famously does not have a time derivative. The following section will formulate a version of calculus for processes with Brownian motion with consistent notions of differentials and integrals, since that will be the backbone of stochastic modeling of derivatives.

\subsection{Itô Calculus}
\textbf{Definition.} Consider $W(t)$ Brownian motion and $\mathcal{F}(t)$ a filtration for it, defined on $[0,T]$. Let $\Delta (t)$ be an adapted stochastic process, and $\Pi$ a partition of sub-points on the interval. Then, as the supremum of sub-point distances goes to zero, the sum
\begin{align}
    \sum_j^{k-1}(\Delta(t_j)[W(t_{j+1})-W(t_j)]) + \Delta(t_k)[W(t_{k+1})-W(t_k)] 
\end{align}
converges to the \textbf{Itô integral}
\begin{align}
     I(T)=\int_0^T \Delta(t) dW(t),
\end{align}
provided that $\mathbb{E}[\int_0^T \Delta(t)^2 dW(t)] < \infty$.

\textbf{Theorem.} For Itô integral $I(T)=\int_0^T \Delta(t) dW(t)$, the integral is a martingale. The integral is continuous and $\mathcal{F}(t)$-measurable. The integral accumulates quadratic variation equal to
\begin{align}
    [I,I](t) = \int_0^t\Delta(u)^2du.
\end{align}
Additionally, the integral satisfies the following isometry:
\begin{align}
    \mathbb{E}[I^2(t)] = \int_0^t \Delta(u)^2 du.
\end{align}

\textbf{Definition.} Consider $W(t)$ Brownian motion and $\mathcal{F}(t)$ an associated filtration, defined on $[0,T]$. Let $\Delta(t), \Theta(t)$ be adapted stochastic processes. Then, define an \textbf{Itô process} for $X(0)$ non-random as
\begin{align}
    X(t) = X(0) + \int_0^t \Theta(u)du + \int_0^t \Delta(u) dW(u),
\end{align}
or, in differential notation,
\begin{align}
    dX(t)= \Theta(t)dt + \Delta(t) dW(t).
\end{align}

\textbf{Lemma (Itô).} Let $f(x,t)$ be a function for which the partial derivatives exist and are continuous, and $W(t)$ be a Brownian motion. Then, in differential form,
\begin{align}
    df(t,W(t)) = \frac{\partial f}{\partial t}(t,W(t))dt + \frac{\partial f}{\partial x}(t,W(t))dW(t) + \frac{1}{2}\frac{\partial^2f}{\partial x^2}(t,W(t))dt.
\end{align}
If $f(t,X(t))$ takes a general Itô process, then
\begin{align}
    df(t,X(t)) = \frac{\partial f}{\partial t}(t,X(t))dt + \frac{\partial f}{\partial x}(t,X(t))dX(t) + \frac{1}{2}\frac{\partial^2f}{\partial x^2}(t,X(t))dX(t)^2.
\end{align}
If the function involves a product of two Itô processes, then the product rule gives
\begin{align}
    d(X(t)Y(t)) = X(t)dY(t) + dX(t)Y(t) + dX(t)dY(t).
\end{align}
For a multi-dimensional process $X(t)$, where the coefficient functions are now vectors,
\begin{align}
    df(t,X(t)) = \frac{\partial f}{\partial t}(t,X(t))dt + \sum_i\frac{\partial f}{\partial x_i}(t,X(t))dX_i(t) \\+\frac{1}{2}\sum_{i,j}\frac{\partial^2f}{\partial x_i \partial x_j}(t,X(t))dX_i(t)dX_j(t).
\end{align}
\textit{Proof idea.} Use Taylor's formula along with the (informal) rule $dtdt = dWdt = 0, dWdW=dt$.

\textbf{Example (GBM).} One model of stock price motion, for $S(t)$ the asset's price over time, is.
\begin{align}
    dS(t) = \mu(t) S(t)dt + \sigma(t)S(t)dW(t).
\end{align}
The solution to this \textbf{stochastic differential equation}, an equation relating differentials of stochastic processes with Brownian motion, is obtained as follows:
\begin{align}
    \frac{dS(t)}{S(t)} = \mu(t)dt + \sigma(t)dW(t).
\end{align}
If this were ordinary calculus, one could simply use the chain rule to obtain a logarithm, yet this does not work here. Instead, we can propose something similar. By Itô's lemma, the differential of the function $f(t, S(t)) = \log(S(t))$ is
\begin{align}
    d(f(t,S(t))) &= \frac{\partial f}{\partial t}dt + \frac{\partial f}{\partial x}dS(t) + \frac{1}{2}\frac{\partial^2f}{\partial x^2}dS(t)^2\\
    &=0 +\frac{1}{S(t)}dS(t) + \frac{1}{2}\frac{-1}{S(t)^2}(dS(t))^2\\
    &=\mu(t)dt + \sigma(t)dW(t) -\frac{1}{2}\frac{1}{S(t)^2}\sigma(t)^2S(t)^2dt\\
    & = (\mu(t)-\frac{1}{2}\sigma(t)^2)dt + \sigma(t)dW(t).
\end{align}
Fortunately, this choice of substitution yields all $S(t)$ in the differential on one side. Integrating and exponentiating yields
\begin{align}
    S(t)=S(0)\exp(\int_0^t(\mu(u)-\frac{1}{2}\sigma(u)^2)du + \int_0^t\sigma(u)dW(u)).
\end{align}
This is known as \textbf{geometric Brownian motion}.

\textbf{Theorem (Girsanov).} Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, $W(t)$ a Brownian motion, and $\mathcal{F}(t)$ a filtration for the Brownian motion from $[0,T]$. Let $\Theta(t)$ be an adapted process, and define
\begin{align}
    Z(t) &= \exp(-\int_0^t \Theta(u)dW(u) - \frac{1}{2}\int_0^t \Theta(u)^2du)\\
    \widetilde{W}(t) &= W(t) + \int_0^t \Theta(u)du.
\end{align}
If $\mathbb{E}[\int_0^T \Theta(u)^2 Z(u)^2 du] < \infty$,
then, taking $Z=Z(T)$, $\mathbb{E}[Z]=1$, and $\widetilde{W}(t)$ is a Brownian motion under $\widetilde{\mathbb{P}}$.

The multidimensional case is identical, except the Itô integral uses a dot product between the adapted process and the Brownian motion, and the square turns into the Euclidean norm.

\textit{Proof idea.} Use Lévy's theorem by showing martingale property.

\textbf{Theorem (Martingale representation).} Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, $W(t)$ a Brownian motion, and $\mathcal{F}(t)$ a filtration for the Brownian motion from $[0,T]$. Let $M(t)$ be a martingale with respect to the filtration. Then there exists an adapted process $\Gamma(u)$ such that
\begin{align}
    M(t) = M(0) + \int_0^t\Gamma(u)dW(u).
\end{align}
If $\widetilde{M}(t)$ is likewise a martingale under $\widetilde{\mathbb{P}}$ with Girsanov-generated Brownian motion $\widetilde{W}(u)$, then there exists an adapted process $\widetilde{\Gamma}(u)$ such that
\begin{align}
    \widetilde{M}(t) = \widetilde{M}(0) + \int_0^t\widetilde{\Gamma}(u)d\widetilde{W}(u).
\end{align}
The multidimensional analogue is identical, except for the Itô integral gaining a dot product.

\subsection{SDE-PDE Connection}

\textbf{Proposition.} Consider the stochastic differential equation 
\begin{align}
dX(u) = \beta(u,X(u))du + \gamma(u,X(u))dW(u)
\end{align}
Under standard regularity conditions, the solution exists and defines a time-inhomogeneous Markov process. If $\beta,\gamma$ are time-independent, the process is time-homogeneous.

\textbf{Theorem (Feynman-Kac).} Let $dX(u) = \beta(u,X(u))du + \gamma(u,X(u))dW(u)$ be an SDE, and let $h(y)$ be any Borel-measurable function. For $0 \leq t \leq T $, define
\begin{align}
    g(t,x)= \mathbb{E}[h(X(T))|X(t)=x].
\end{align}
This exists as SDE solutions are Markov processes. Then $g$ satisfies the following PDE:
\begin{align}
    \frac{\partial g}{\partial t}(t,x)+\beta(t,x)\frac{\partial g}{\partial x}(t,x) + \frac{1}{2}\gamma(t,x)^2\frac{\partial^2 g}{\partial x^2}(t,x)=0,
\end{align}
with $g(T,x)=h(x)$.

If instead one defines a discounted process
\begin{align}
    f(t,x)= \mathbb{E}[e^{-r(T-t)}h(X(T))|X(t)=x],
\end{align}
then $f$ satisfies the following PDE:
\begin{align}
    \frac{\partial f}{\partial t}(t,x)+\beta(t,x)\frac{\partial f}{\partial x}(t,x) + \frac{1}{2}\gamma(t,x)^2\frac{\partial^2 f}{\partial x^2}(t,x)=rf(t,x),
\end{align}
with $f(T,x)=h(x)$.

\textit{Proof idea.} Show that $f,g$ is a martingale, then use Itô's lemma to evaluate $df,dg$ and impose the condition that the coefficient on $dt$ is zero to ensure martingale property.

\textbf{Remark.} This is a link between SDEs and PDEs. Many SDEs, which do not appear to have analytical solutions, can be solved via switching to the dual PDE, which can be solved numerically. The following theorems are more general elaborations on this theme.

\textbf{Definition.}
Define operators $P_t$ acting on bounded measurable functions.
Then $\{P_t\}_{t\ge0}$ forms a \textbf{semigroup} if
\begin{align}
P_0 = \mathrm{id}, \qquad P_{s+t}=P_s P_t.
\end{align}
If $P_t$ maps $C_0(\mathbb R^d)$ into itself and is strongly continuous, it is called a
\textbf{Feller semigroup}.

\textbf{Proposition.} For $X(t)$ a homogeneous Markov process, defining operators $P$ on bounded measurable functions $f$ as
\begin{align}
(P_t f)(x) := \mathbb E[f(X(t)) \mid X(0)=x]
\end{align}
forms a semigroup. If the process is inhomogeneous, there is instead a two-parameter family with an evolution property:
\begin{align}
    (P_{t,T} f)(x) = \mathbb E[f(X(T)) \mid X(t)=x],
    \quad
    P_{t,T}=P_{t,s} P_{s,T}.
\end{align}

\textit{Proof.} Since $X(0)=x$ almost surely under $\mathbb P(\,\cdot\,|X(0)=x)$, then $(P_0 f)(x)=\mathbb E[f(X(0)) \mid X(0)=x]=f(x)$. So $P_0 = \mathrm{id}$. 

To show the second property, fix $x\in\mathbb R^d$ and a bounded measurable function $f$.
By definition, $(P_{s+t}f)(x)=\mathbb E[f(X(s+t)) \mid X(0)=x]$.
Insert a conditional expectation with respect to $\mathcal F_s$ using the tower property:
$(P_{s+t}f)(x)=\mathbb E\!\left[\mathbb E[f(X(s+t)) \mid \mathcal F_s]\;\middle|\;X(0)=x\right]$.

Since $X(t)$ is Markov, we have $\mathbb E[f(X(s+t)) \mid \mathcal F_s]=\mathbb E[f(X(s+t)) \mid X(s)]$. By time-homogeneity, we also have $\mathbb E[f(X(s+t)) \mid X(s)=y] =(P_t f)(y)$, therefore $\mathbb E[f(X(s+t)) \mid \mathcal F_s]=(P_t f)(X(s))$.
Substituting back gives: $(P_{s+t}f)(x)=\mathbb E[(P_t f)(X(s)) \mid X(0)=x] =(P_s(P_t f))(x)$. Since this holds for all $x$ and all bounded measurable $f$, the second property holds. The inhomogeneous case is not shown. \hfill $\square$

\textbf{Definition.}
The \textbf{generator} $\mathcal L$ of the semigroup is defined by
\begin{align}
\mathcal L f
=
\lim_{t\downarrow0}
\frac{P_t f - f}{t},
\end{align}
for all $f$ in its domain. For the homogeneous Markov case, substituting the semigroup operators gives
\begin{align}
    \mathcal{L}f(x) = \lim_{t\downarrow 0} \frac{\mathbb{E}[f(X(t))\mid X(0)=x]-f(x)}{t},
\end{align}
or, for the inhomogeneous case,
\begin{align}
    \mathcal{L}_tf=\lim_{h\rightarrow0}\frac{P_{t,t+h}(f)-f}{h}.
\end{align}
The \textbf{adjoint} of the generator, $\mathcal{L}^*$, is defined such that $<\mathcal{L}f,g>=<f,\mathcal{L}^*g>$ for test functions and measures $f,g$ respectively, given that their integrals exist and boundary terms vanish. The adjoint acts on densities or measures.

\textbf{Proposition.} A homogeneous Markov process $X(t)$ is said to be \textbf{affine} if
\begin{align}
    \mathbb{E}[e^{uX(t)} | X(t)=x] = e^{A(T-t,u) + B(T-t,u)x},
\end{align}
for non-random functions $A,B$. This property is equivalent to the generator mapping exponentials to exponentials times an affine function of the state:
\begin{align}
    \mathcal{L}e^{ux}= (a(u)+b(u)x)e^{ux}.
\end{align}

\textbf{Proposition.} Let $X(t)$ satisfy the stochastic differential equation $dX(u) = \beta(u,X(u))\,du + \gamma(u,X(u))\,dW(u)$, and define the Markov semigroup $(P_t f)(x) = \mathbb E[f(X(t)) \mid X(0)=x]$, for $f\in C_b^2(\mathbb R)$. Then the generator of the semigroup for a time-inhomogeneous process, acting on the spatial variable, is
\begin{align}
\mathcal L_t f(x)
=
\beta(t,x)\frac{\partial f}{\partial x}(x)
+
\frac12 \gamma(t,x)^2\frac{\partial ^2 f}{\partial x^2}(x),
\end{align}
or, in the time-homogeneous case,
\begin{align}
\mathcal L f(x)
=
\beta(x)\frac{df}{dx}(x)
+
\frac12 \gamma(x)^2\frac{d^2 f}{dx^2}(x).
\end{align}
Note that this is coefficient in front of $dt$ in Itô's lemma. The adjoint is of the form
\begin{align}
\mathcal L^*_t p(t,x)
=
-\frac{\partial}{\partial x}(\beta(t,x)p(t,x))
+
\frac12\frac{\partial^2 }{\partial x^2} (\gamma(t,x)^2p(t,x)).
\end{align}

\textit{Proof idea.} Take the differential $df(X(u))$, take the conditional expectation, and take the limit to zero. For the adjoint, use integration by parts.

\textbf{Theorem (Kolmogorov backward equation).}
Let $u(t,x)=\mathbb E[f(X(t)) \mid X(0)=x]$. Then,
\begin{align}
\frac{\partial u}{\partial t}(t,x) = \mathcal L u(t,x),
\qquad
u(0,x)=f(x).
\end{align}
By replacing $t$ by $T-t$, as is more common with time flowing backwards from $T$, this takes the form
\begin{align}
-\frac{\partial u}{\partial t}(t,x) = \mathcal L u(t,x),
\qquad
u(T,x)=f(x).
\end{align}
If $X(t)$ is defined as $dX(u) = \beta(u,X(u))du + \gamma(u,X(u))dW(u)$, and the transition density as $p(t,T,x,y)\,dy = \mathbb{P}(X(T)\in dy \mid X(t)=x).
$, then this can be written
\begin{align}
    -\frac{\partial p}{\partial t}(t,T,x,y) =\beta(t,x)\frac{\partial p}{\partial x}(t,T,x,y) + \frac{1}{2} \gamma(t,x)^2 \frac{\partial^2 p}{\partial x^2}(t,T,x,y).
\end{align}
If instead, in the discounted case, $u(t,x)=\mathbb E\!\left[e^{-r(T-t)}f(X(T))\mid X(t)=x\right]
$, then
\begin{align}
\frac{\partial u}{\partial t}(t,x) + \mathcal L u(t,x)-ru(t,x)=0,
\quad
u(T,x)=f(x).
\end{align}


\textbf{Theorem (Kolmogorov forward equation).}
For $p$ the probability density of the random process
\begin{align}
\frac{\partial p}{\partial t}(t,x)= \mathcal{L}^*_t(p(t,x)).
\end{align}
Considering again the SDE $dX(u) = \beta(u,X(u))\,du + \gamma(u,X(u))\,dW(u)$, denote the transition density of the process $p(t,T,x,y)\,dy = \mathbb{P}(X(T)\in dy \mid X(t)=x).
$.
The transition density then satisfies the \textbf{Fokker-Planck equation}:
\begin{align}
\frac{\partial}{\partial T} p(t,T,x,y)
&=
- \frac{\partial}{\partial y}\!\left(\beta(T,y)\,p(t,T,x,y)\right)
+ \frac{1}{2}\frac{\partial^2}{\partial y^2}\!\left(\gamma(T,y)^2\,p(t,T,x,y)\right),
\end{align}
for $T>t$, with initial condition
\begin{align}
\lim_{T\downarrow t} p(t,T,x,y) = \delta(y-x).
\end{align}
\textit{Proof.} Take the backwards equation explicitly for $u$
\begin{align}
    \frac{\partial }{\partial t}\int f(x)p(t,x)dx &= \int \mathcal L_t (f(x))p(t,x)dx\\
    \int f(x)\frac{\partial p}{\partial t}(t,x)dx &=  \int \mathcal L_t(f(x))p(t,x)dx.
\end{align}
By definition of the adjoint, this gives
\begin{align}
    \int f(x)\frac{\partial p}{\partial t}(t,x)dx &=  \int f(x)\mathcal{L}^*_t(p(t,x))dx.
\end{align}
Since this holds for all functions in the domain, $\frac{\partial p}{\partial t}(t,x)= \mathcal{L}^*_t(p(t,x))$. Plugging in the form that the adjoint takes yields the Fokker-Planck and transition probability versions. \hfill $\square$
 
\textbf{Remark.}
The backward equation governs the evolution of observables, while the forward equation governs the evolution of probability distributions. Both are determined by the generator $\mathcal L$.

\section{Jump Diffusion}

\textbf{Motivation.} Pure diffusion models imply continuous price paths and fail to capture empirically observed features such as sudden price jumps, volatility clustering, and heavy-tailed return distributions.

\textbf{Definition:} Given a metric space $(M,d)$, a function $f$ is called \textbf{càdlàg} (\textit{continue à droite, limite à gauche}) if both the left and the right limit exist, and the right limit equals the function value at all points.

\textbf{Definition.} On filtered probability space, a stochastic process $X(t)$ is called a \textbf{Lévy process} if 
\begin{itemize}
    \item $X(0) = 0$ almost surely,
    \item the paths of $X(t)$ are càdlàg,
    \item $X(t)$ is adapted to $\mathcal{F}(t)$,
    \item the increments $X(t)-X(s)$ are mutually independent,
    \item the increments are stationary ($X(t)-X(s) = X(t-s)$ in distribution),
    \item the process is continuous in probability 
    \begin{align}
        \lim_{h \rightarrow 0} \mathbb{P}(|X(t+h)-X(t)|>0) = 0.
    \end{align}
\end{itemize}

\textbf{Theorem.} There exists a stochastic process $N(t)$ such that $N(0)=0$ almost surely, $N(t)$ is almost surely càdlàg, $N(t)$ has independent increments, and $N(t)-N(s)$ is distributed as a Poisson distribution with intensity $\lambda(t-s)$. That process is called a \textbf{Poisson process}.

\textit{Proof idea.} Use Kolmogorov extension theorem.

\textbf{Proposition.} The sum of independent Poisson processes with intensities $\lambda_1, \lambda_2$ is a Poisson process with intensity $\lambda_1 + \lambda_2$. Likewise, a Poisson process with intensity $\lambda_1 + \lambda_2$ can be decomposed into a sum of independent Poisson processes with intensities $\lambda_1, \lambda_2$.

\textbf{Remark.} For some intuition, if the idea of a Poisson process is to count the number of events in a window of time, then for some given window of time, the amount of events that should occur within that time for two processes is just the same one process with a larger rate.

\textbf{Definition.}
Let $N(t)$ be a Poisson process with intensity $\lambda>0$, and let $(Y_k)_{k\ge1}$ be a sequence of i.i.d.\ real-valued random variables with mean $\beta$, independent of $N(t)$. The process
\begin{align}
    Q(t) = \sum_{k=1}^{N(t)} Y_k
\end{align}
is called a \textbf{compound Poisson process}. $N(t)$ counts the number of jump events up to time $t$, while $Y_k$ represents the size of the $k$-th jump. The process $Q(t)$ therefore models random jump arrivals with random magnitudes.

\textbf{Proposition.}
A compound Poisson process is a Lévy process.

\textit{Proof.}
The increments are stationary and independent due to the corresponding properties of the Poisson process and the independence of the jump sizes. The paths are càdlàg with finitely many jumps on any compact interval. \hfill $\square$

\textbf{Definition.} For a Poisson process of intensity $\lambda$, the variable
\begin{align}
    M(t) = N(t)-\lambda t
\end{align}
is called a \textbf{compensated Poisson process}, and is a martingale. For a compound Poisson process, the martingale is
\begin{align}
    Q(t) - \beta t \lambda.
\end{align}

\textbf{Theorem (Lévy-Itô decomposition).}
Let $X(t)$ be a Lévy process. Then $X(t)$ a canonical decomposition into continuous and jump components, 
\begin{align}
    X(t)
    = b t + \sigma W(t)
    + \int_{|x|<1} x \,\widetilde{N}(t,dx)
    + \int_{|x|\ge 1} x \, N(t,dx),
\end{align}
where:
\begin{itemize}
    \item $b \in \mathbb{R}$ is a drift term,
    \item $\sigma \ge 0$,
    \item $W(t)$ is a standard Brownian motion,
    \item $N(t,dx)$ is a Poisson random measure,
    \item $\widetilde{N}(t,dx) = N(t,dx) - t\nu(dx)$ is the compensated Poisson measure,
    \item $\nu(dx)$ is the \textbf{Lévy measure}, satisfying
    \begin{align}
        \int_{\mathbb{R}} \min(1,x^2)\,\nu(dx) < \infty.
    \end{align}
\end{itemize}

\textbf{Remark.}
The Lévy measure $\nu$ governs the intensity and size distribution of jumps. Large jumps occur finitely often on finite intervals, while small jumps may occur infinitely often but with finite total quadratic variation.


\textbf{Definition.} A \textbf{jump diffusion} is a stochastic process of the form
\begin{align}
    X(t)
    = X(0)
    + \int_0^t \mu(s)\,ds
    + \int_0^t \sigma(s)\,dW(s)
    + \sum_{k=1}^{N(t)} Y_k,
\end{align}
where:
\begin{itemize}
    \item $W(t)$ is Brownian motion,
    \item $N(t)$ is a Poisson process with intensity $\lambda$,
    \item $Y_k$ are i.i.d.\ jump sizes, independent of $W$ and $N$.
\end{itemize}

\textbf{Remark.}
Jump diffusions combine continuous fluctuations with discrete shocks and are capable of modeling sudden price moves, crashes, and news arrivals that cannot be captured by pure diffusion models.

\textbf{Definition.}
A \textbf{stochastic differential equation with jumps} is written as
\begin{align}
    dX(t)
    = \mu(t,X({t^-}))\,dt
    + \sigma(t,X({t^-}))\,dW(t)
    + \int_{\mathbb{R}} \gamma(t,X({t^-}),x)\,N(dt,dx),
\end{align}
where $X({t^-})$ denotes the left limit of $X$ at time $t$.

\textbf{Remark.}
The presence of jumps destroys pathwise continuity and invalidates classical Itô calculus. Instead, one works with extensions of Itô's formula for semimartingales with jumps.


\textbf{Theorem (Itô's lemma with jumps).}
Let $X(t)$ be a jump diffusion and let $f \in C^{2}(\mathbb{R})$. Then
\begin{align}
    df(X(t)
    &= \frac{\partial f}{\partial x}(X(t^-))\,dX_t
    + \frac12 \frac{\partial^2 f}{\partial x^2}(X(t^-))\,\sigma^2(t,X(t^-))\,dt \\
    &\quad
    + \sum_{0<s\le t}
    \Big(
        f(X(s)) - f(X(s^-)) - \frac{\partial f}{\partial x}(X({s^-}))\Delta X_s
    \Big),
\end{align}
where $\Delta X(s) = X(s) - X({s^-})$ denotes the jump size at time $s$.

\textbf{Remark.} Jump diffusions provide a mathematically tractable framework for incorporating these effects and form the foundation for models such as the Merton jump-diffusion model and more general Lévy-driven asset price processes.



\chapter{Risk-Neutral Formulation}

\section{Risk-Neutral Pricing}
\textbf{Motivation.} Many economics models use the assumption of no-arbitrage when developing theories of asset pricing. This section elaborates on the mathematical requirements for and implications of no-arbitrage.

\subsection{One Asset}

\textbf{Definition.} A \textbf{portfolio} of an agent has value denoted $X(t)$, and is the value of a combination of stock and money-market investments (at risk-free rate $r$). Let the stock be geometric Brownian motion, and let $\Delta(t)$ be the number of shares of stock held, adapted to the underlying filtration. The differential for the portfolio with one stock is then
\begin{align}
    dX(t) = \Delta(t)dS(t) + r(X(t)-\Delta(t)S(t))dt.
\end{align}

\textbf{Definition.} For an adapted interest rate process, define the \textbf{discount process} as
\begin{align}
    D(t) = e^{-\int_0^tR(u)du},
\end{align}
with differential
\begin{align}
    dD(t) = -R(t)D(t)dt.
\end{align}
The \textbf{discounted stock price} (in light of the time value of money) is therefore
\begin{align}
    D(t)S(t)=S(0)\exp(\int_0^t(\mu(s)-R(s)-\frac{1}{2}\sigma(s)^2)ds + \int_0^t\sigma(s)dW(s)),
\end{align}
with differential
\begin{align}
    d(D(t)S(t))= \sigma(t)D(t)S(t)[\Theta(t)dt + dW(t)],
\end{align}
in which the \textbf{market price of risk} is defined as $\Theta(t) = \frac{\mu(t)-R(t)}{\sigma(t)}$.

\textbf{Definition.} In the above setting, using Girsanov's theorem to switch to $\widetilde{W}(t) = W(t) + \int_0^t \Theta(u)du$ yields
\begin{align}
     d(D(t)S(t))= \sigma(t)D(t)S(t)d\widetilde{W}(t).
\end{align}
Then $\widetilde{\mathbb{P}}$, the probability measure generated by applying Girsanov's theorem with the market price of risk as the adapted stochastic process, is called the \textbf{risk-neutral measure}. 

Under a risk-neutral measure, which is equivalent to the initial probability measure, the discounted price of an asset is a martingale, as is visible from the lack of $dt$ term in the differential.

\textbf{Proposition.} Discounted portfolio values are martingales under the risk-neutral measure - they have an average return of $R(t)$:
\begin{align}
    d(D(t)X(t))= \Delta(t)\sigma(t)D(t)S(t)d\widetilde{W}(t).
\end{align}

\textbf{Remark:} This is quite helpful for pricing assets. The usual formula, that the present value of a portfolio is equal to the risk-neutral expectation of discounted future cash flows, is reproduced from this. The insistence upon the martingale nature is helpful in that we can get expectations of future states given current information in straightforward expressions.

\textbf{Theorem (Risk-neutral pricing).} For $V(T)$, a $\mathcal{F}(T)$-measurable random variable, an interest rate process, and a risk-neutral probability measure, the value of $V(t)$ at time $t<T$ is
\begin{align}
    V(t) = \widetilde{\mathbb{E}}[e^{-\int_t^TR(u)du}V(T)|\mathcal{F}(t)].
\end{align}
\textit{Proof.} Under the risk-neutral measure, discounted asset prices are martingales. Hence, for hedge $X(t)$, $D(t)X(t) =\widetilde{\mathbb{E}}[D(T)X(T)|\mathcal{F}(t)]$. If a hedge can be constructed, $X(T)=V(T)$ almost surely, so this equals $\widetilde{\mathbb{E}}[D(T)V(T)|\mathcal{F}(t)]$. One can call this the equivalent price $V(t)$, discounted. Therefore, $ V(t) = \widetilde{\mathbb{E}}[e^{-\int_t^TR(u)du}V(T)|\mathcal{F}(t)]$. \hfill $\square$

\textbf{Proposition (Existence of hedges).} Earlier, it was unclear if hedges could be constructed - this proposition qualifies that. Consider $V(T)$, a $\mathcal{F}(T)$-measurable random variable, representing the payoff of a derivative security. In order to hedge/replicate a short position against the derivative, there must be a portfolio such that $X(T)=V(T)$ almost surely. For a single stock, choosing
\begin{align}
    X(0)=V(0), \quad
\Delta(t)=\frac{\widetilde{\Gamma}(t)}{\sigma(t)D(t)S(t)}
\end{align}
guarantees the hedge, assuming that the volatility is never zero, and that Brownian motion is the only source of uncertainty. If all securities can be hedged, a market is called \textbf{complete}.

\textit{Proof.} Under the risk-neutral measure, $D(t)V(t) =\widetilde{\mathbb{E}}[D(T)V(T)|\mathcal{F}(t)]$, as this is a martingale. Therefore, by the martingale representation theorem, this can be written $D(t)V(t) = V(0) + \int_0^t\widetilde{\Gamma}(u)d\widetilde{W}(u)$. Likewise, for a portfolio, $D(t)X(t)= X(0) + \int_0^t \Delta(u)\sigma(u)D(u)S(u)d\widetilde{W}(u)$. For these to be equal at all times (and hence to be a true replication/hedge), match terms to obtain the above expressions. \hfill $\square$

\textbf{Remark:} Note here that the existence of the martingale measure is allowing hedges to be created - this is key! Hedging perfectly in continuous time, however, is dubious in practice.

\subsection{Multiple Assets}

\textbf{Definition.} Under the \textbf{multidimensional market model}, consider $m$ stocks and $d$ Brownian motions. Define the stocks as
\begin{align}
    dS_i(t)=\mu_i(t)S_i(t)dt + S_i(t)\sum_{j=1}^d \sigma_{ij}(t)dW_j(t).
\end{align}
Rewriting as
\begin{align}
    \sigma_i(t)=\sqrt{\sum_{j=1}^d \sigma_{ij}(t)^2}, \quad
    dB_i(t)= \sum_{j=1}^d\frac{\sigma_{ij}(t)}{\sigma_i(t)}dW_j(t),
\end{align}
then $B_i(t)$ is Brownian via Lévy's theorem, and
\begin{align}
    dS_i(t) &= \mu_i(t)S_i(t)dt + \sigma_i(t)S_i(t)dB_i(t)\\
    dB_i(t)dB_k(t) &= \sum_{j=1}^d\frac{\sigma_{ij}(t)\sigma_{kj}(t)}{\sigma_i(t)\sigma_k(t)}dt = \rho_{ik}(t)dt,
\end{align}
with instantaneously correlated Brownian motions.

\textbf{Proposition.} Discounted stock prices under the multidimensional market model can be made martingales by change of measure if the following $m$ market price of risk equations can be solved for $\Theta_i(t)$:
\begin{align}
    \mu_i(t) - R(t) = \sum_{j=1}^d\sigma_{ij}(t)\Theta_i(t).
\end{align}
If this is true, analogous to previous results, discounted portfolio values are also martingales under the risk-neutral measure.

\textit{Proof.} Taking the differential of the discounted stock price via Itô's lemma yields $d(D(t)S_i(t)) = D(t)S_i(t)[(\mu_i(t)-R(t))dt + \sum_{j=1}^d\sigma_{ij}(t)dW_i(t)]$. In order to use Girsanov's theorem to switch into a risk-neutral probability measure where this becomes a martingale, the differential should be of the form $d(D(t)S_i(t)) = D(t)S_i(t)[\sum_{j=1}^d\sigma_{ij}(t)(\Theta _j(t)dt + dW_j(t))]$. This is possible if, by matching these two differentials, the above equations hold. \hfill $\square$

\textbf{Definition.} An \textbf{arbitrage} is a portfolio process $X(t)$ such that
\begin{align}
    X(0)=0, \quad
    \mathbb{P}(X(T)\geq 0), \quad
    \mathbb{P}(X(T)>0)>0.
\end{align}

\textbf{Theorem (First fundamental theorem of asset pricing).} If a market model admits a risk-neutral measure, then it does not admit arbitrages.

\textit{Proof.} Suppose there does exist a risk-neutral measure for a market (a collection of stocks). Then the discounted value of a portfolio is a martingale. Suppose $X(0)=0$, then $\widetilde{\mathbb{E}}[D(T)X(T)]=0$. Suppose $X(t)$ also satisfies $\mathbb{P}(X(T)\geq 0) =1$, so that $\widetilde{\mathbb{P}}(X(T)< 0) =0$. Then $\widetilde{\mathbb{P}}(X(T)> 0) =0$ must also be the case for the expectation to hold. Hence, $X(t)$ cannot be an arbitrage. \hfill $\square$

\textbf{Theorem (Second fundamental theorem of asset pricing).} For a market having a risk-neutral probability measure, the completeness of the market is equivalent to the uniqueness of the risk-neutral measure.

\section{Change of Numéraire}

\textbf{Motivation.} Asset prices do not have an intrinsic meaning in absolute terms, but only relative to a chosen unit of account, or numéraire. While risk-neutral pricing is often presented as a special change of probability measure under which discounted asset prices become martingales, this perspective generalizes naturally.

\textbf{Definition.}  
A \textbf{numéraire} is a strictly positive adapted process $N(t)$ such that $N(t) > 0$ almost surely for all $t \ge 0$, and such that $N$ is a traded asset (or replicable portfolio). Given any asset price process $S(t)$, its \textbf{relative price} with respect to the numéraire $N$ is defined as
\begin{align}
S^{(N)}(t) = \frac{S(t)}{N(t)}.
\end{align}

\textbf{Definition.} Recall that in a frictionless arbitrage-free market, the asset pricing theorems imply the existence of an equivalent probability measure under which discounted asset prices are martingales.

Let $M(t)$ denote the money market account,
\begin{align}
M(t) = \exp\!\left(\int_0^t R(u)\,du\right)
\end{align}
A probability measure $\mathbb Q$ is called a \textbf{risk-neutral measure} or \textbf{martingale measure} if every traded asset $S(t)$ divided by the numéraire is a $\mathbb Q$-martingale:
\begin{align}
\frac{S(t)}{N(t)} = \mathbb{E}^{\mathbb{Q}}[\frac{S(T)}{N(T)}|\mathcal{F}(t)].
\end{align}
Plugging in the money market account reproduces the usual risk-neutral measure.

\textbf{Theorem (Stochastic representation of assets).} Consider the multidimensional market model of the previous section with $m$ assets, and let $\widetilde{\mathbb{P}}$ be the risk-neutral measure with respect to the money market account numéraire, with $d$-dimensional independent Brownian motion $\widetilde{W}(t)$. Let $N(t)$ by a positive price process that does not pay dividends. Then there exists a vector volatility process
\begin{align}
    \nu(t) = (\nu_1(t),...,\nu_d(t)),
\end{align}
such that 
\begin{align}
    dN(t) = R(t)N(t)dt + N(t)\nu(t) \cdot \widetilde{W}(t),
\end{align}
or equivalently,
\begin{align}
    D(t)N(t) = N(0)\exp(\int_0^t(-\frac{1}{2}|\nu(u)|^2)dt + \int_0^t \nu(u) \cdot d\widetilde{W}(u)).
\end{align}
\textit{Proof.} By construction of risk-neutral pricing, $D(t)N(t)$ is a martingale under the risk-neutral measure. By the martingale representation theorem, there exists a $d$-dimensional $\widetilde{\Gamma}$ such that $d(D(t)N(t)) = \widetilde{\Gamma}(t) \cdot d\widetilde{W}(t)$. Defining $\nu_i(t) = \frac{\widetilde{\Gamma}_i(t)}{D(t)N(t)}$ yields $d(D(t)N(t)) = D(t)N(t)\nu (t) \cdot d\widetilde{W}(t)$. Using Itô with a good initial guess produces the above results. \hfill $\square$

\textbf{Theorem (Change of numéraire).} Let $S(t),N(t)$ be two asset prices in common currency with respective vector volatility processes. Denote this as
\begin{align}
    d(D(t)S(t)) &= D(t)S(t)\sigma(t) \cdot \widetilde{W}(t)\\
    d(D(t)N(t)) &= D(t)N(t)\nu(t) \cdot \widetilde{W}(t).
\end{align}
Take $N(t)$ as the numéraire. Then there exists a risk-neutral measure $\widetilde{\mathbb{P}}^{(N)}$ where the relative price $S^{(N)}(t)$ is a martingale. That relative price has differential
\begin{align}
    dS^{(N)}(t) = S^{(N)}(t)[\sigma(t)-\nu(t)] \cdot d\widetilde{W}^{(N)}(t).
\end{align}

\textit{Proof.} First, we establish the risk-neutral measure for the new numéraire. Consider the existing risk-neutral measure with money market account numéraire, and recall multidimensional Girsanov's theorem. Define $\Theta_j(t) = -\nu_j(t)$, such that the Radon-Nikodym derivative becomes $Z(t) = \exp(\int_0^t\nu(u)\cdot d\widetilde{W}(u) - \int_0^t|\nu(u)|^2du/2)$, and the new Brownian motion becomes $\widetilde{W}^{(N)}(t) = \widetilde{W}(t) - \int_0^t \nu(u)du$. By comparison with the results from the previous theorem, $Z(t) = D(t)N(t)/N(0)$.

Now, we evaluate the differential to show that the relative prices are martingales. Using the above theorem to obtain formulas for $D(t)S(t),D(t)N(t)$, then dividing yields $S^{(N)}(t)= \frac{S(0)}{N(0)} \exp(-\frac{1}{2}\int_0^t(|\sigma(u)|^2-|\nu(u)|^2)dt + \int_0^t (\sigma(u)-\nu(u)) \cdot d\widetilde{W}(u))$. To take the differential, apply Itô's formula, taking the exponent as the stochastic process. This reduces to $dS^{(N)}(t) = S^{(N)}(t)(\sigma(t)-\nu(t))(-\nu(t)dt + d\widetilde{W}(t))$. Substituting the previously proposed new Girsanov Brownian motion obtains the result. \hfill $\square$


\textbf{Theorem.} Let $V(T)$ be a contingent claim payable at time $T$. Its price at time $t$ expressed in units of the numéraire $N$ is given by
\begin{align}
\frac{V(t)}{N(t)} = \mathbb E^{(\mathbb Q^N)}\!\left[\left.\frac{X(T)}{N(T)} \right| \mathcal F(t) \right].
\end{align}

\textbf{Example (Zero-coupon bond numéraire).}
Let $B(t,T)$ denote the time-$t$ price of a zero-coupon bond maturing at time $T$. Consider a forward contract written at time $t$ with maturity $T$ on an asset with price $S(T)$.

Using the money market account as numéraire, the time-$t$ price of the forward is
\begin{align}
V(t) = \mathbb{E}^{(\mathbb{Q})}\!\left[ e^{-\int_t^T r(u)\,du} \big(S(T) - K\big) \,\middle|\, \mathcal{F}_t \right].
\end{align}

Now change numéraire to the zero-coupon bond $B(t,T)$, and let $\mathbb{Q}^T$ denote the associated forward measure. Under $\mathbb{Q}^T$, the discounted asset price
\begin{align}
\frac{S(t)}{B(t,T)}
\end{align}
is a martingale. The forward price is therefore given by
\begin{align}
F(t,T) = \mathbb{E}^{(\mathbb{Q}^T)}\!\left[ S(T) \mid \mathcal{F}_t \right],
\end{align}
as will be shown in the following chapters, and the drift term disappears under the $T$-forward measure. 




\chapter{Asset Pricing and Derivatives}

\textbf{Motivation.} Now that we have developed an asset pricing framework, how are real-world assets valued under the model? This section will develop prices for various derivatives using the risk-neutral model.

\section{Forwards and Futures}

\textbf{Proposition (cash flows).} For an asset generating cash flows $C(u)$, a portfolio holding this asset has value
\begin{align}
    X(t) = \frac{1}{D(t)}\widetilde{\mathbb{E}}[\int_t^TD(u)dC(u)|\mathcal{F}(t)].
\end{align}
\textit{Proof idea.} The discounted portfolio has differential $d(D(t)X(t)) = D(t)dC(t)$. Hence, taking the integral of this from $t$ to $T$, then applying the risk-neutral conditional expectation to exploit the martingale nature of the left-hand side reproduces the above expression.


\textbf{Proposition.} The price at time $t$ of a \textbf{zero-coupon bond} paying 1 at time $T$ is
\begin{align}
    B(t,T)= \frac{1}{D(t)}\widetilde{\mathbb{E}}[D(T)|\mathcal{F}(t)].
\end{align}
Define its \textbf{yield to maturity (YTM)} to be the rate equivalent to continuous compounding a single interest rate to maturity:
\begin{align}
    B(t,T) = e^{Y(t,T)(T-t)}.
\end{align}
\textbf{Definition.} A \textbf{forward contract} is an agreement to pay the amount $K$ at delivery time $T$ to receive an asset whose value at time $t$ is $S(t)$. As the forward does not require upfront payment to enter into the contract, by no arbitrage, the price of the forward is the value of $K$ that makes the forward worth zero at time $t$.

\textbf{Theorem.} Assuming bonds of all maturities are available, the price of a forward contract is
\begin{align}
    For_S(t,T) = \frac{S(t)}{B(t,T)}.
\end{align}
\textit{Proof.} The value of a forward contract at time $T$ is $S(T)-K$. Under the risk-neutral pricing system, the present value is $V(t) = \frac{1}{D(t)}\widetilde{\mathbb{E}}[D(T)(S(T)-K)|\mathcal{F}(t)]$. Using linearity of expectation and the fact that discounted prices are martingales, we obtain $V(t) = S(t) - KB(t,T)$. Yet the value of the forward contract at time $t$ must be zero, so setting $K$ as the forward price above guarantees this. \hfill $\square$

\textbf{Definition.} A \textbf{futures contract} for asset $S(t)$ with delivery time $T$ is an arrangement such that the contract requires no payment to enter into, the payments are marked-to-market via the establishment of a margin account such that holding a long position on the interval $[s,t]$ gives the holder $Fut_S(t,T)-Fut_S(s,T)$, and the holder at time $T$ pays $Fut_S(T,T)$ to receive the asset.

\textbf{Theorem.} The price of a futures contract is
\begin{align}
    Fut_S(t,T) = \widetilde{\mathbb{E}}[S(T)|\mathcal{F}(t)].
\end{align}
This satisfies $Fut_S(T,T)=S(T)$ and is a martingale under the risk-neutral measure. The value of a futures contract held over a period of time is zero.

\section{European Options}

\textbf{Definition.} A \textbf{European call option} on underlying asset $S(t)$ gives the holder the right, but not obligation, to buy the asset at time $T$ for price $K$. The value at time $T$ of a European call is thus $\max(S(T)-K,0)$. Likewise, a \textbf{European put option} on underlying asset $S(t)$ gives the holder the right, but not obligation, to sell the asset at time $T$ for price $K$. The value at time $T$ of a European put is thus $\max(K-S(T),0)$.

\textbf{Theorem (Black-Scholes).} A European call option for asset $S(t)$, satisfying geometric Brownian motion with constant $\mu,\sigma$, with expiry date $T$ and strike price $K$, where the risk-free rate is $r$, has price $c(t, S(t))$ for $0 \leq t \leq T$. That price, under the no-arbitrage condition, satisfies the \textbf{Black-Scholes partial differential equation}:
\begin{align}
    \frac{\partial c}{\partial t}(t,x) + rx\frac{\partial c}{\partial x}(t,x) + \frac{1}{2}\sigma^2x^2\frac{\partial^2 c}{\partial x^2}(t,x) = rc(t,x).
\end{align}

\textit{Proof.} Via the no-arbitrage condition, there exists a hedge to the call. This means that the hedge $\Delta(t)$ is chosen such that the discounted value of the portfolio is equal to the discounted value of the asset at all times, under no-arbitrage. Therefore,
\begin{align}
    d(e^{-rt}X(t)) = d(e^{-rt}c(t,S(t))).
\end{align}
Using Itô's lemma to evaluate both sides, and recalling that the stock in the portfolio obeys $dS(t) = \mu S(t)dt + \sigma S(t)dW(t)$, then the following is obtained by matching the differentials on both sides:
\begin{align}
    \Delta(t)(\mu-r)S(t)dt&=[\frac{\partial c}{\partial t} + \mu S(t)\frac{\partial c}{\partial x} + \frac{1}{2}\sigma^2S(t)^2\frac{\partial^2 c}{\partial x^2} -rc]dt \\
    \Delta(t)\sigma S(t)dW(t) &= \sigma S(t)\frac{\partial c}{\partial x}dW(t).
\end{align}
Hence, the criteria for the delta-hedge is that
\begin{align}
    \Delta(t) = \frac{\partial c}{\partial x}(t,S(t)).
\end{align}
Substituting this into the first equation yields that $c(t,S(t))$ must satisfy the Black-Scholes PDE. \hfill $\square$

\textbf{Theorem.} The solution to the Black-Scholes PDE is 
\begin{align}
    c(t,x) &= x\Phi(d_+(\tau,x)) - e^{-r\tau}\Phi(d_-(\tau,x))\\
    d_-(\tau,x) &= \frac{1}{\sigma\sqrt{\tau}}[\log(\frac{x}{K})+(r-\frac{1}{2}\sigma^2)\tau]\\
    d_+(\tau, x) &= d_-(\tau,x)+\sigma\sqrt{\tau},
\end{align}
where $\tau = T-t$ and $\Phi$ is the CDF of the standard normal distribution.

\textit{Proof idea.} Via the Feynman-Kac formula, the function that satisfies the Black-Scholes PDE is $c(t,x)= \widetilde{\mathbb{E}}[e^{r(T-t)}\max (S(T)-K,0)|\mathcal{F}(t)]$. Plugging in geometric Brownian motion for $S(t)$ and simplifying gives the above solution for the call price. Note that within the Feynman-Kac formula, the volatility does not need to be constant, and a version of Black-Scholes with non-constant volatility can be obtained.

\textbf{Definition.} The \textbf{Greeks} are derivatives of the option price function. \textbf{Delta}, \textbf{theta}, \textbf{vega}, and \textbf{gamma} are defined as
\begin{align}
    \Delta(t) &= \frac{\partial c}{\partial x}(t,S(t))\\
    \Theta(t) &= \frac{\partial c}{\partial t}(t,S(t))\\
    \mathcal{V}(t) &= \frac{\partial c}{\partial \sigma}(t,S(t))\\
    \Gamma(t) &= \frac{\partial^2 c}{\partial x^2}(t,S(t)).
\end{align}

\textbf{Theorem (Put-call parity).} For a forward, European call, and European put on asset $S(t)$ with expiry time $T$ and strike price $K$,
\begin{align}
    f(t,x) = S(t) - e^{rt}S(0) =  c(t,S(t))-p(t,S(t)).
\end{align}
\textit{Proof.} At time $T$, the forward is worth $S(T)-K$, which is equal to $\max(S(T)-K,0)-\max(K-S(T),0)$, which is the difference in the call and put payoffs at time $T$. This must hold at all times for no arbitrage. \hfill $\square$

\section{Exotic Options}

\textbf{Definition.} European options depend only on the terminal value of the underlying asset. In contrast, \textbf{exotic options} are derivatives whose payoff depends on the path of the underlying process, on multiple assets, or on additional features such as barriers or averages.

\subsection{Asian Options}

\textbf{Definition.} An \textbf{Asian option} depends on previous sampled values of the stock. A fixed-strike Asian call, sampled continuously, pays
\begin{align}
    V(T) = \max (\frac{1}{T}\int_0^T S(u)du-K,0).
\end{align}

\textbf{Remark.} For an exotic option, the underlying process $S(t)$, being an SDE solution, is Markov, yet the payoff depends on more than $S(T)$. In this case, it also depends on $A(T) = \int_0^TS(u)du$. One approach to recovering the Markov property is then to define a \emph{joint process} $Y(t)=(S(t),A(t))$, enlarging the state space. Now the relevant history or "hidden memory" appears explicitly. 

\textbf{Theorem.} For an Asian option, define the price function
\begin{align}
u(t,s,a)
=
\mathbb E^{(\mathbb Q)}\!\left[
e^{-r(T-t)}\,
h\!\left(\frac{A(T)}{T}\right)
\;\middle|\;
S(t)=s,\;A(t)=a
\right].
\end{align}
Then $u$ satisfies
\begin{align}
\frac{\partial u}{\partial t} +r s \frac{\partial u}{\partial s}+s \frac{\partial u}{\partial a}+\frac12 \sigma^2 s^2 \frac{\partial^2 u}{\partial s^2}-r u=0,
\end{align}
with terminal condition
\begin{align}
u(T,s,a) = h\!\left(\frac{a}{T}\right).
\end{align}

\textit{Proof.} Define the auxiliary process $A(t) = \int_0^t S(u)du$. Then the payoff may be written solely in terms of $A(T)$ as $H = h(A(T)/T)$. The joint process $(S(t),A(t))$ contains all information relevant for pricing the Asian option. Assume that under the risk-neutral measure $\mathbb Q$, the asset price follows $dS(t) = r S(t)dt + \sigma S(t)dW(t)$,
where $r$ and $\sigma$ are constants. The process $A(t)$ then satisfies $dA(t) = S(t)dt$, with $A(0)=0$. This defines the dynamics of the joint process.

Moreover, the process $(S(t),A(t))$ is Markovian. For $h>0$, $A(t+h)=A(t)+\int_t^{t+h} S(u)du$. The future increment of $A$ depends only on the future path of $S$, whose conditional distribution depends only on $S(t)$. Consequently, conditional on $(S(t),A(t))$, the future evolution of the process is independent of the past. Hence, $(S(t),A(t))$ is a time-homogeneous Markov process. This means that we can now use the Kolmogorov/generator formalism.

Now, let $f \in C^2(\mathbb R^2)$ be a smooth test function. Applying Itô's formula to $f(S(t),A(t))$ yields $df=\frac{\partial f}{\partial s}\,dS+\frac{\partial f}{\partial a}\,dA+\frac12\frac{\partial^2 f}{\partial s^2}\,(dS)^2$.
Solving for the coefficient on the $dt$ term, the generator $\mathcal L$ of the joint process $(S(t),A(t))$ is therefore:
\begin{align}
\mathcal L f(s,a)=r s \frac{\partial f}{\partial s}+s\frac{\partial f}{\partial a}+\frac12 \sigma^2 s^2 \frac{\partial^2 f}{\partial s^2}.
\end{align}
Define the Asian option price function
\begin{align}
u(t,s,a)
=
\mathbb E^{(\mathbb Q)}\!\left[
e^{-r(T-t)}\,
h\!\left(\frac{A(T)}{T}\right)
\;\middle|\;
S(t)=s,\;A(t)=a
\right].
\end{align}
Since $(S(t),A(t))$ is Markovian, $u$ depends only on $(t,s,a)$. By the Feynman--Kac theorem, $u$ satisfies the backward Kolmogorov equation,
\begin{align}
\frac{\partial u}{\partial t}+\mathcal L u-r u=0,
\end{align}
the expansion of which is given in the theorem. \hfill $\square$

\subsection{Barrier and Lookback Options}

\textbf{Definition.} A \textbf{barrier option} known as a knock-out option is a standard European option, with the condition that if the asset crosses a barrier, the option is worthless. A knock-in option is a standard European option, with the condition that the option is worthless unless the asset crosses a barrier. A knock-out option where the barrier is above the current asset price is called "up-and-out".

\textbf{Proposition.} Let $(\Omega, \mathcal{F}, \widetilde{\mathbb{P}})$ be a probability space and $\widetilde{W}(t)$ a Brownian motion. Define
\begin{align}
    \Hat{W}(t) = \alpha t + \widetilde{W}(t),
    \quad
    \Hat{M}(t) = \max_{0 \leq t \leq T} \Hat{W}(t).
\end{align}
Then, the joint density under $\widetilde{\mathbb{P}}$ of $(\Hat{M}(t), \Hat{W}(t))$ is
\begin{align}
    \widetilde{f}_{(\Hat{M}(t), \Hat{W}(t))}(m,w) = \frac{2(2m-w)}{T\sqrt{2\pi T}}\exp{(\alpha w - \frac{1}{2}\alpha^2T - \frac{1}{2T}(2m-w)^2)}.
\end{align}
\textit{Proof idea.} Use Girsanov to switch into the hat measure, then the joint density is a standard result. Then, use the trick that probability is equal to expectation of an indicator function, and explicitly write the Radon-Nikodym derivative. Evaluating this gives the above expression.

\textbf{Theorem.} An up-and-out call price $v(t,S(t))$ satisfies the Black-Scholes equation in the region ($[0,T] \times [0,B]$)
\begin{align}
    \frac{\partial v}{\partial t}(t,x) + rx\frac{\partial v}{\partial x}(t,x) + \frac{1}{2}\sigma^2x^2\frac{\partial^2 v}{\partial x^2}(t,x) = rv(t,x),
\end{align}
subject to
\begin{align}
    v(t,0) = v(t,B)= 0 , 
    \quad
    v(T,x) = \max(x-K,0).
\end{align}
The risk-neutral expectation can also be taken given the above joint density.

\textbf{Definition.} A \textbf{lookback option}, which depends on the maximum of the asset price attained, called a floating strike lookback call pays, for the maximum attained,
\begin{align}
    Y(t) = \max _{0 \leq u \leq t}S(u),
\end{align}
the following:
\begin{align}
    v(T) = Y(T) - S(T).
\end{align}

\textbf{Theorem.} A floating strike lookback call price $v(t,S(t),Y(t))$ satisfies Black-Scholes:
\begin{align}
    \frac{\partial v}{\partial t}(t,x,y) + rx\frac{\partial v}{\partial x}(t,x,y) + \frac{1}{2}\sigma^2x^2\frac{\partial^2 v}{\partial x^2}(t,x,y) = rv(t,x,y),
\end{align}
subject to
\begin{align}
    v(t,0,y) = e^{-r(T-t)}y,
    \quad
    v(t,y,y)= 0 , 
    \quad
    v(T,x,y) = y-x.
\end{align}

\section{American Options}

\textbf{Definition.}  
Let $S(t)$ be an asset whose price under the risk-neutral measure $\mathbb Q$ satisfies
\begin{align}
dS(t) = r S(t)\,dt + \sigma S(t)\,d\widetilde W(t),
\end{align}
where $r>0$ is the constant risk-free rate and $\widetilde W(t)$ is a Brownian motion under $\mathbb Q$.  

An \textbf{American option} written on $S(t)$, with strike price $K$ and expiration date $T$, differs from a European option in that it may be exercised at any stopping time prior to maturity. The holder of the option chooses an exercise time so as to maximize the expected discounted payoff.

Formally, the value of an American option with payoff function $h:\mathbb R_+\to\mathbb R_+$ is given by the \textbf{optimal stopping problem}
\begin{align}
v(t,x)=\sup_{\tau \in \mathcal T_{t,T}}\mathbb E^{(\mathbb Q)}\!\left[e^{-r(\tau-t)}\,h(S(\tau))\;\middle|\;S(t)=x\right],
\end{align}
where $\mathcal T_{t,T}$ denotes the set of stopping times taking values in $[t,T]$.

\textbf{Proposition.} The American option pricing problem is an instance of optimal stopping theory. The value function $v(t,x)$ satisfies
\begin{itemize}
    \item $v(t,x) \ge h(x)$ for all $(t,x)$, since immediate exercise is always allowed,
    \item $e^{-rt}v(t,S(t))$ is the smallest supermartingale dominating the discounted payoff process $e^{-rt}h(S(t))$.
\end{itemize}
This characterization is known as the \textbf{Snell envelope} and provides the probabilistic foundation for the PDE formulation of American option pricing.

\textbf{Theorem (Variational Inequality).} Let $\mathcal L$ denote the generator of the Markov process $S(t)$,
\begin{align}
\mathcal L f(x)=r x \frac{\partial f}{\partial x}(x)+\frac12 \sigma^2 x^2 \frac{\partial^2 f}{\partial x^2}(x).
\end{align}
 
The value function $v(t,x)$ of an American option satisfies the \textbf{free boundary problem}
\begin{align}
\max\!\left(\frac{\partial v}{\partial t}(t,x)+\mathcal L v(t,x)-r v(t,x),\;h(x)-v(t,x)\right)=0,
\end{align}
with terminal condition
\begin{align}
v(T,x) = h(x).
\end{align}

The region
\begin{align}
\mathcal E = \{(t,x) : v(t,x)=h(x)\}
\end{align}
is called the \textbf{exercise region}, while
\begin{align}
\mathcal C = \{(t,x) : v(t,x)>h(x)\}
\end{align}
is the \textbf{continuation region}. The boundary separating these regions is an unknown, time-dependent \textbf{free boundary}.

\textbf{Theorem.} For an American put option, the payoff is
\begin{align}
h(x) = \max(K-x,0).
\end{align}
Early exercise may be optimal, and the value function satisfies the following \textbf{linear complementarity conditions} for $x\ge 0$ and $t\in[0,T]$:
\begin{align}
&rv(t,x)-\frac{\partial v}{\partial t}(t,x)-r x \frac{\partial v}{\partial x}(t,x)-\frac12 \sigma^2 x^2 \frac{\partial^2 v}{\partial x^2}(t,x)\ge 0,\\&v(t,x) \ge K-x,\\&\left(rv(t,x)-\frac{\partial v}{\partial t}(t,x)-r x \frac{\partial v}{\partial x}(t,x)-\frac12 \sigma^2 x^2 \frac{\partial^2 v}{\partial x^2}(t,x)\right)\!\left(v(t,x)-(K-x)\right)=0.
\end{align}
There exists a free boundary $x=b(t)$ such that
\begin{itemize}
    \item if $x \le b(t)$, it is optimal to exercise immediately,
    \item if $x>b(t)$, it is optimal to continue holding the option.
\end{itemize}

At the free boundary, the value function satisfies the \emph{value-matching} and \emph{smooth-pasting} conditions:
\begin{align}
v(t,b(t)) &= K-b(t),\\
\frac{\partial v}{\partial x}(t,b(t)) &= -1.
\end{align}

\textbf{Theorem.}  
If the underlying asset pays no dividends, the price of an American call option equals the price of the corresponding European call option with the same strike and maturity:
\begin{align}
v(t,x) = c(t,x).
\end{align}

\textit{Remark.}  
In this case, early exercise is never optimal. Consequently, the continuation region coincides with the entire state space, and the American call option satisfies the standard Black--Scholes PDE without a free boundary.

\section{Local and Stochastic Volatility}

\textbf{Motivation.} Using the Black-Scholes model for European options, one can plug in the call prices at different strikes and expiry times to back out an "implied volatility". Black-Scholes assumes that this is constant, however it varies with strike and expiry in what are known as \emph{volatility smiles/skews}. The following models are attempts to model volatility more dynamically.

\subsection{Dupire Model}

\textbf{Definition.} 
Market option prices imply a surface of implied volatilities $\sigma_{\text{imp}}(K,T)$ across strikes $K$ and maturities $T$. A natural question is whether there exists a diffusion process for the underlying asset whose model prices exactly reproduce this surface.

Let $(\Omega,\mathcal F,\mathbb Q)$ be a risk-neutral probability space. A \textbf{local volatility model} assumes that the asset price $S(t)$ follows
\begin{align}
dS(t)=r(t)S(t)\,dt+\sigma_{\text{loc}}(t,S(t))\,S(t)\,dW(t),
\end{align}
where $\sigma_{\text{loc}}(t,s)$ is a deterministic function called the \textbf{local volatility}. This model is Markovian, time-inhomogeneous, and arbitrage-free under $\mathbb Q$.

\textbf{Proposition.} Let $c(t,T)$ denote the price at time $t$ of a European call option with strike $K$ and maturity $T$. Under mild regularity assumptions, the call price satisfies the forward PDE:
\begin{align}
\frac{\partial c}{\partial T}=-r(T)K \frac{\partial c}{\partial K} + \frac12 \sigma_{\text{loc}}^2(T,K) K^2 \frac{\partial^2 c}{\partial K^2}
\end{align}
This equation is the forward Kolmogorov equation expressed in strike space.

\textit{Proof idea.} Take the forward Kolmogorov equation with the generator evaluated for this particular $S(t)$.

\textbf{Theorem (Dupire's formula).}  
Assume that European call prices $c(0,T;K)$ are observed for all strikes and maturities and are sufficiently smooth. Then the local volatility function consistent with these prices is given by
\begin{align}
\sigma_{\text{loc}}^2(T,K)=\frac{\frac{\partial c}{\partial T}(0,T;K)+r(T)K \frac{\partial c}{\partial K}(0,T;K)}{\frac12 K^2 \frac{\partial^2 c}{\partial K^2}(0,T;K)}.
\end{align}
\textit{Proof.} Rearrange the forward equation. \hfill $\square$

\textbf{Definition.} The \textbf{stochastic volatility inspired (SVI) model} allows for fitting implied volatility as a function of time to expiry and strike price. Define total implied variance as $w(\tau,k)=\sigma_{BS}^2(\tau,k)^\tau$ for $k$ the logarithm of the strike price, and $\tau$ the time to expiry. The raw SVI model is then, for a given expiry time,
\begin{align}
    w(k) = a + b(\rho(k-m) + \sqrt{(k-m)^2+\sigma^2}),
\end{align}
where parameters can be fit. The model is free of calendar arbitrage if its time derivative is nowhere negative.

\textit{Remark.}  
Dupire's formula shows that the local volatility surface can be recovered uniquely from the observed implied volatility surface, provided sufficient smoothness. Local volatility models exactly fit the observed implied volatility surface, remain Markovian and one-dimensional, and admit efficient PDE and Monte Carlo pricing methods. However, their volatility dynamics are deterministic, they exhibit poor performance for forward-start and path-dependent options, and they are unable to reproduce realistic volatility dynamics.

\subsection{Heston Model}

\textbf{Definition.}
Empirical evidence suggests that volatility exhibits
mean reversion, clustering, and randomness independent of asset price movements. Stochastic volatility models address these features by introducing a second source of randomness.

The \textbf{Heston model} specifies the joint dynamics of the asset price $S(t)$ and its instantaneous variance $V(t)$ under the risk-neutral measure:
\begin{align}
dS(t)&=r S(t)\,dt+\sqrt{V(t)}\,S(t)\,dW_1(t)\\dV(t)&=\kappa(\theta - V(t))\,dt+\xi\sqrt{V(t)}\,dW_2(t),
\end{align}
where $\kappa > 0$ is the rate of mean reversion, $\theta > 0$ is the long-run variance, $\xi > 0$ is the volatility of volatility, and $W_1$ and $W_2$ are Brownian motions with correlation $\rho$.

\textbf{Proposition.} The joint process $(S(t),V(t))$ is a two-dimensional Markov diffusion with generator
\begin{align}
\mathcal L f&=r s \frac{\partial f}{\partial s}+\kappa(\theta - v)\frac{\partial f}{\partial v}+\frac12 v s^2 \frac{\partial^2 f}{\partial s^2}+\rho \xi v s \frac{\partial^2 f}{\partial s \partial v}+\frac12 \xi^2 v \frac{\partial^2 f}{\partial v^2}
\end{align}
\textit{Proof idea.} Use the multidimensional Itô formula on the joint process and read off the coefficient on the $dt$ term.

\textbf{Theorem.} Let $u(t,s,v)$ denote the price of a European derivative with payoff $h(S(T))$. Then $u$ satisfies
\begin{align}
\frac{\partial u}{\partial t}+\mathcal L u-r u=0,
\qquad
u(T,s,v)=h(s).
\end{align}
\textit{Proof.} Given the above generator, this is the Kolmogorov backward equation. \hfill $\square$

\textbf{Theorem.} To ensure strict positivity of the variance process, the parameters must satisfy the \textbf{Feller condition}
\begin{align}
2\kappa\theta \ge \xi^2.
\end{align}
This guarantees that the boundary $V(t)=0$ is unattainable.

\textbf{Remark.} Explicitly evaluating the risk-neutral expectation to calculate asset prices will not be successful, as there is no closed-form probability density for the Heston model. There are still many ways to price assets using the Heston model. One popular one relies on the characteristic function of the logarithm of the asset price, which does have a closed form, and the Fourier transform, which can be performed quickly using the Fast Fourier Transform. 

\textbf{Proposition (Fourier pricing).} Let $S(t)$ be an asset price over time, and define $X(t) = \log{S(t)}$. Let the \textbf{characteristic function} of $X(t)$ be defined as
\begin{align}
    \varphi(u) = \mathbb{E}^{(\mathbb{Q})}[e^{iuX}].
\end{align}
If $\phi$ denotes the payoff of a derivative as a function of the logarithm of the asset price and admits a Fourier representation,
\begin{align}
    \phi(x) = \frac{1}{2\pi}\int_{-\infty}^{\infty} e^{-ipx}\Hat{\phi}(p)dp,
\end{align}
then the initial price of the derivative is
\begin{align}
    V(0) = e^{-rT}\mathbb{E}^{(\mathbb{Q})}[\phi(X(T))]= \frac{e^{-rT}}{2\pi}\int_{-\infty}^{\infty}  \varphi(-p)\Hat{\phi}(p)dp.
\end{align}

\textbf{Theorem.} For $X(t)$, the logarithm of a Heston model asset price, the characteristic function of $X(T)$ is
\begin{align}
    \varphi_{X(T)}(u) = \exp{(C(T,u) + D(T,u)V(0) + iuX(0))},
\end{align}
for $C,D$ solutions to Riccati differential equations (discussed in next section). 

\textit{Proof idea.} Guess a solution similar in form to the above function and plug it into the Kolmogorov backwards equation, then solve the ODEs. 

\textbf{Remark.} The payout of a European call is not absolutely integrable, hence there is no Fourier transform for it. Nevertheless, the \textbf{Carr-Madan approach} dampens the payoff by an exponential so that the Fourier transform exists. This allows standard options to be computed using the Heston model.

\textbf{Example (Carr-Madan).} Consider a European call option with strike $K$ and maturity $T$ on an asset $S(t)$ following the Heston model.  

Define
    \begin{align}
    X(T) = \log S(T), \qquad k = \log K.
    \end{align}
Introduce a damping factor $\alpha \in (0,1)$ and define
    \begin{align}
    C_\alpha(K) := e^{-\alpha k} \mathbb{E}^{(\mathbb{Q})}\Big[ (e^{X(T)} - e^k)^+ \Big].
    \end{align}
Using the Carr-Madan approach, the call price can be written as
    \begin{align}
        C(K) = e^{-\alpha k} \frac{1}{\pi} \int_0^\infty 
        \mathrm{Re} \Bigg[ 
        e^{-i v k} 
        \frac{\varphi_{X(T)}(v - i (\alpha + 1))}{(\alpha + i v)(\alpha + 1 + i v)} 
        \Bigg] dv,
    \end{align}
where $\varphi_{X(T)}(u) = \mathbb{E}[ e^{i u X(T)} ]$ is the characteristic function of the log-price under the Heston model.

From the previous theorem, we have
    \begin{align}
    \varphi_{X(T)}(u) = \exp\Big( C(T,u) + D(T,u) V(0) + i u X(0) \Big),
    \end{align}
where $C(T,u)$ and $D(T,u)$ solve the Riccati ODEs associated with the Heston model. Compute the integral to solve for the price.

\textbf{Remark:}  
This method allows efficient computation of European option prices under stochastic volatility models. The damping factor $\alpha$ ensures integrability, and the integral can be evaluated using standard quadrature methods or the Fast Fourier Transform (FFT). The same approach can be extended to other European-style payoffs.



\subsection{SABR Model}

\textbf{Definition.}
Let $F(t)$ denote a forward price or forward interest rate. Under a pricing measure, the \textbf{SABR (Stochastic Alpha Beta Rho) model} is defined by the system of stochastic differential equations
\begin{align}
    dF(t) &= \alpha_t F(t)^\beta \, dW_1(t), \\
    d\alpha(t) &= \nu \alpha(t) \, dW_2(t), \\
    d\langle W_1, W_2 \rangle(t) &= \rho \, dt,
\end{align}
where:
\begin{itemize}
    \item $\alpha_t > 0$ is the instantaneous volatility level,
    \item $\beta \in [0,1]$ controls the elasticity of the forward process,
    \item $\nu \ge 0$ is the volatility of volatility,
    \item $\rho \in [-1,1]$ is the instantaneous correlation.
\end{itemize}

\textbf{Proposition.} The forward price $F(t)$ is a martingale under the chosen measure. The SABR model therefore preserves no-arbitrage conditions for forwards and rates.

\textbf{Remark.} Several classical models arise as special cases:
\begin{itemize}
    \item $\beta = 1$: lognormal SABR, consistent with Black's model,
    \item $\beta = 0$: normal SABR, consistent with Bachelier's model,
    \item $\nu = 0$: constant elasticity of variance (CEV) model,
    \item $\rho = 0$: uncorrelated volatility and underlying.
\end{itemize}
The implied volatility smile in SABR arises from stochastic volatility ($\nu > 0$), correlation between price and volatility ($\rho \neq 0$), and nonlinear dependence of volatility on the forward level ($\beta \neq 1$). In particular, negative correlation ($\rho < 0$) produces left-skewed smiles commonly observed in interest rate markets.



\textbf{Theorem (Hagan et al.\ approximation).} Closed-form option prices are unavailable in the SABR model. However, an asymptotic expansion for implied volatility is available. Let $K$ denote the option strike and $T$ the maturity. For $F(0),K>0$ and small $T$, the Black implied volatility under the SABR model admits the approximation
\begin{align}
    \sigma(F(0),K)
    =
    \frac{z\alpha_0}{\chi(z)(F(0) K)^{(1-\beta)/2}}
    \Bigg[
        1
        +
        \Bigg(
            \frac{\alpha_0^2(1-\beta)^2}{24(F(0) K)^{1-\beta}}
            + \frac{\rho \beta \nu \alpha_0}{4 (F(0) K)^{(1-\beta)/2}}
            + \frac{2-3\rho^2}{24}\nu^2
        \Bigg)T
    \Bigg],
\end{align}
where
\begin{align}
    z &= \frac{\nu}{\alpha_0}(F(0) K)^{(1-\beta)/2}\log\!\left(\frac{F(0)}{K}\right), \\
    \chi(z) &= \log\!\left(
        \frac{\sqrt{1 - 2\rho z + z^2} + z - \rho}{1 - \rho}
    \right).
\end{align}

\textbf{Remark.}
This formula is used almost universally for calibration in interest rate markets.

\textbf{Corollary.}
At-the-money ($F(0) = K$), the implied volatility simplifies to
\begin{align}
    \sigma_{\text{ATM}}
    =
    \frac{\alpha_0}{F(0)^{1-\beta}}
    \Bigg[
        1
        +
        \Bigg(
            \frac{(1-\beta)^2}{24}\frac{\alpha_0^2}{F(0)^{2-2\beta}}
            + \frac{\rho \beta \nu \alpha_0}{4 F(0)^{1-\beta}}
            + \frac{2-3\rho^2}{24}\nu^2
        \Bigg)T
    \Bigg].
\end{align}


\chapter{Fixed-Income and Credit}

\section{Term-Structure Models}

\textbf{Motivation.} The market does not have one single interest rate, nor does that interest rate stay constant over time. This section addresses models attempting to reflect that.

\subsection{Short Rate Models} 

\textbf{Definition.} The \textbf{short rate} $R(t)$ is the instantaneous yield/interest rate at time $t$
\begin{align}
    R(t) = \lim _{T \rightarrow t}-\frac{\partial}{\partial T}\log(B(t,T)).
\end{align}

\textbf{Definition.} The \textbf{Vasicek model} assumes that the short rate $R(t)$ follows an \textbf{Ornstein-Uhlenbeck process}:
\begin{align}
dR(t) = \left(\alpha - \beta R(t)\right)dt + \sigma d\widetilde{W}(t).
\end{align}

\textbf{Theorem.} The rate under a Vasicek process is 
\begin{align}
    R(t) = e^{-\beta t} + \frac{\alpha}{\beta}(1-e^{-\beta t}) + \sigma e^{-\beta t} \int_0^t e^{-\beta s} d\widetilde{W}(s),
\end{align}
with mean $ e^{-\beta t} + \frac{\alpha}{\beta}(1-e^{-\beta t})$ and variance $\frac{\sigma^2}{2\beta}(1-e^{-2\beta t})$.

\textit{Proof.} This could be immediately integrated, but the rate appears on the right side. To eliminate this, consider the differential $d(e^{\beta t}R(t)) = e^{\beta t} dR(t) + \beta e^{\beta t}R(t)dt$. Substituting the Vasicek differential gives $d(e^{\beta t}R(t)) = \alpha e^{\beta t} dt + e^{\beta t}\sigma d\widetilde{W}(t) $. Integrating this gives the above equation. The only random part of the rate is the Itô integral. 

Since this is a martingale, and Brownian motion starts at zero, this has mean zero, so the mean is the constant terms. Using Itô isometry, the variance is $\sigma^2 e^{-2\beta t}\int_0^t e^{2\beta s}ds$, which gives the above result. \hfill $\square$

\textbf{Theorem.} The price of a zero-coupon bond of maturity $T$, $B(t,r;T)$, under the Vasicek model satisfies
\begin{align}
    \frac{\partial B}{\partial t}(t,r;T) + (\alpha - \beta r)\frac{\partial B}{\partial r}(t,r;T) + \frac{1}{2}\sigma^2\frac{\partial^2 B}{\partial r^2}(t,r;T) - rB(t,r;T) &=0\\
    B(T,r;T)&=1.
\end{align}
The Vasicek model is an affine term structure model, and zero-coupon bonds under them have prices of the form
\begin{align}
    B(t,r;T) = e^{g(t,T) + h(t,T)r}.
\end{align}


\textit{Proof.} The value of a zero coupon bond under the standard risk-neutral measure is $D(t)B(t,T) = \widetilde{\mathbb{E}}[D(T)1|\mathcal{F}(s)]$, so $B(t,T) = \widetilde{\mathbb{E}}[e^{\int_t^T R(u)du}|\mathcal{F}(t)]$. Using the standard Kolmogorov/generator framework with the SDE being the Vasicek process $\mathcal{L}f = (\alpha - \beta r)\frac{\partial f}{\partial r} + \frac{1}{2}\sigma^2\frac{\partial^2 f}{\partial r^2}$ yields the above result. The generator satisfies the affine condition $\mathcal{L}e^{ur}=(\alpha - \beta r)u e^{ur} + \frac 12 \sigma^2u^2e^{ur} = [(\alpha u + \frac 12 \sigma^2u^2) + (\beta u)r]e^{ur}$. This affine form can serve as an ansatz for a closed-solution from Riccati ODEs. \hfill $\square$

\textbf{Proposition.} If, under the risk-neutral measure, a short rate model has the form
\begin{align}
    dR(t) = a(t,R(t))dt + b(t,R(t))d\widetilde{W}(t),
\end{align}
for
\begin{align}
    a(t,R(t)) = \kappa (t) R(t) +\eta(t), \quad b(t,R(t)) = \sqrt{\gamma(t)R(t) + \delta(t)},
\end{align}
then the model is affine, and the functions in the exponent of the bond price satisfy the \textbf{Riccati differential equations}
\begin{align}
    \frac{dh}{dt}(t,T) &= -\kappa(t)h(t,T)- \frac 12 \gamma(t)h^2(t,T) + 1\\
    \frac{dg}{dt}(t,T) &= -\eta(t)h(t,T) - \frac 12 \delta(t) h^2(t,T),
\end{align}
with $g(T,T) = h(T,T) = 0$.

\textbf{Remark.} This model allows for negative interest rates.


\textbf{Definition.} The \textbf{Cox-Ingersoll-Ross (CIR) model} modifies the diffusion term to preserve positivity:
\begin{align}
dR(t) = \kappa \left(\theta - R(t)\right)dt + \sigma \sqrt{R(t)}d\widetilde{W}(t).
\end{align}
Under the Feller condition $2\kappa\theta \ge \sigma^2$, the short rate remains strictly positive. Like Vasicek, the CIR model is affine and yields closed-form bond prices, but introduces state-dependent volatility.

\textbf{Definition.} The \textbf{Hull-White model} extends the Vasicek framework by allowing time-dependent parameters to fit the initial yield curve exactly:
\begin{align}
dR(t) = \left(\alpha(t) - \beta(t) R(t)\right)dt + \sigma(t)\,d\widetilde{W}(t).
\end{align}
This produces yet another affine, Gaussian model.

\textbf{Proposition.} Given a simplified Hull-White model,
\begin{align}
    dR(t)=(\theta(t)-aR(t))dt + \sigma d\widetilde{W}(t),
\end{align}
the model can be calibrated given the present forward rate $f^{mkt}(t,T)$:
\begin{align}
    \theta(t) = \frac{\partial f^{mkt}}{\partial t}(0,t) + af^{mkt}(0,t) + \frac{\sigma^2}{2a}(1-e^{-at})^2.
\end{align}
$a,\sigma$ can then be calibrated.

\textbf{Remark.} There likewise exist \textbf{multifactor models} that consider the differential of the short rate to depend on multiple processes.

\subsection{Forward Rate Models}

\textbf{Definition.} The \textbf{forward rate} at time $t$ over the interval $[T, T +\delta T]$ is
\begin{align}
    e^{f(t, T, T +\delta T) \delta T}B(t, T) = B(t,T+\delta T).
\end{align}
Limiting $\delta t$ to zero gives the instantaneous interest rate at time $T$ that can be locked in at time $t$:
\begin{align}
    f(t,T) = -\frac{\partial}{\partial T}\log(B(t,T)).
\end{align}
Consequently, the short rate is $f(t,t)$, and
\begin{align}
    B(t,T) = e^{-\int_t^T f(t,v)dv}.
\end{align}

\textbf{Definition.} The \textbf{Heath-Jarrow-Morton (HJM) framework} models the entire forward rate curve directly. Let $f(t,T)$ denote the instantaneous forward rate at time $t$ for maturity $T$. Under the risk-neutral measure, its dynamics are
\begin{align}
df(t,T) = \alpha(t,T)\,dt + \sigma(t,T)\,dW(t),
\end{align}
with $f(0,T)$ being set to the initial observed forwards rate curve.

\textbf{Theorem.} Absence of arbitrage requires that there must a process such that
\begin{align}
\alpha(t,T)
= \sigma(t,T)(\sigma^*(t,T) + \Theta(t)),
\end{align}
for
\begin{align}
    \sigma^*(t,T) = \int_t^T \sigma(t,u)\,du.
\end{align}

\textit{Proof.} $d(D(t)B(t,T))$ should be a martingale for no-arbitrage to hold. This evaluates to $-R(t)D(t)B(t,T)dt + D(t) dB(t,T)$. Evaluating $dB(t,T)$ using Itô's lemme requires considering the exponential as the function, as the exponent as the stochastic process, whose differential is $d(-\int_t^Tf(t,v)dv) = f(t,t)dt -\int_t^T df(t,v)dv$. 

Evaluating this simplifies the original differential to $D(t)B(t,T)[(-\alpha^*(t,T) + \frac 12 \sigma^*(t,T)^2)dt - \sigma^*(t,T)dW(t)]$, where the stars represent the quantity time integrated in the second argument over $[t,T]$, written explicitly in the statement. To make this a martingale, this must be able to be made into the form $-D(t)B(t,T)\sigma^*(t,T)[\Theta(t)dt + dW(t)]$, so as to use Girsanov's theorem to switch into a risk neutral measure. The characterization of this random process is concretized in the statement above. The fact that this market price of risk is unique means that there is a unique risk-neutral measure, so the model is also complete. \hfill $\square$

\textbf{Theorem.} Assuming that the no-arbitrage condition is satisfied, forwards rates evolve as
\begin{align}
    df(t,T) = \sigma(t,T)\sigma^*(t,T)dt + \sigma(t,T) d\widetilde{W}(t),
\end{align}
and zero-coupon bond prices follow
\begin{align}
    B(t,T)= \frac{B(0,T)}{D(t)}\exp [-\int_0^t\sigma^*(u,T)d\widetilde{W}(u) - \frac 12 \int_0^t \sigma^*(u,T)^2 du].
\end{align}

\textbf{Remark.} This model can reproduce the Hull-White model. Unfortunately, if this formula is used to try to apply Black-Scholes to equity options, forwards rates explode.

\subsection{Market Models}

\textbf{Motivation.} Historically, interest rate derivatives were quoted, hedged, and settled in terms of forward-looking LIBOR (London Inter-Bank Offered Rate) rates rather than instantaneous short rates. Products such as caps, floors, and swaptions reference discretely compounded forward rates over fixed accrual periods, motivating models that directly specify the dynamics of these observable quantities.

Unlike short-rate models, which infer forward rates indirectly through bond prices, the LIBOR Market Model (LMM) specifies the joint dynamics of a finite set of forward rates consistent with market conventions.

\textbf{Definition.} Fix a discrete \textbf{tenor}
\begin{align}
    0 = T_0 < T_1 < \cdots < T_N,
\end{align}
with accrual periods $\delta_i = T_{i+1} - T_i$. The \textbf{forward LIBOR rate} for the period $[T_i, T_{i+1}]$, observed at time $t \le T_i$, is defined by
\begin{align}
    L_i(t)=\frac{1}{\delta_i}\left(\frac{B(t,T_i)}{B(t,T_{i+1})} - 1\right),
\end{align}
where $B(t,T)$ denotes the time-$t$ price of a zero-coupon bond maturing at $T$.

\textbf{Remark.}
LIBOR rates are discretely compounded and are defined only on the tenor dates, in contrast to continuously compounded instantaneous forward rates.

\textbf{Proposition.}
For each maturity $T_{i+1}$, define the \textbf{$T_{i+1}$-forward measure} $\mathbb{Q}^{(T_{i+1})}$ via the numéraire $B(t,T_{i+1})$. Under the measure $\mathbb{Q}^{(T_{i+1})}$, the forward LIBOR rate $L_i(t)$ is a martingale.

\textit{Proof Sketch.} Since $L_i(t)$ is a tradable payoff at $T_{i+1}$ expressed in units of the numéraire $B(t,T_{i+1})$, absence of arbitrage implies the martingale property under $\mathbb{Q}^{(T_{i+1})}$.

\textbf{Assumptions.} The \textbf{LIBOR Market Model (LMM)} proposes the following assumptions:

Under its associated forward measure $\mathbb{Q}^{(T_{i+1})}$, the LIBOR rate follows
\begin{align}
    dL_i(t)
    =
    \sigma_i(t) L_i(t)\, d\widetilde{W}_i^{(T_{i+1})}(t),
    \qquad t \le T_i,
\end{align}
where $\sigma_i(t)$ is a deterministic volatility function.

The Brownian motions satisfy
\begin{align}
    d\widetilde{W}_i^{(T_{i+1})}(t)\, d\widetilde{W}_j^{(T_{i+1})}(t)
    =
    \rho_{ij}\, dt,
\end{align}
with a positive semidefinite correlation matrix $(\rho_{ij})$.

\textbf{Proposition.} When expressed under a single measure (e.g.\ the terminal measure $\mathbb{Q}^{(T_N)}$), the dynamics of $L_i(t)$ acquire a drift:
\begin{align}
    dL_i(t)=\mu_i(t)\, dt+\sigma_i(t) L_i(t)\,d\widetilde{W}_i^{(T_{N})}(t),
\end{align}
where the drift depends on all subsequent LIBOR rates:
\begin{align}
    \mu_i(t)=- \sigma_i(t) L_i(t)\sum_{j=i+1}^{N-1}\frac{\delta_j L_j(t)\sigma_j(t)\rho_{ij}}{1 + \delta_j L_j(t)}.
\end{align}

\textbf{Remark.}
This coupling is the principal source of analytical complexity in the LMM. While each LIBOR is lognormal under its own measure, the joint system is not jointly lognormal under a single measure.

\textbf{Definition.} A \textbf{caplet} on the period $[T_i,T_{i+1}]$ with strike $K$ pays
\begin{align}
    \max(\delta_i (L_i(T_i) - K),0).
\end{align}

\textbf{Proposition.} Under the $T_{i+1}$-forward measure, caplets price as
\begin{align}
    V_{cap}(t)=B(t,T_{i+1}) \widetilde{\mathbb{E}}^{(T_{i+1})}\!\left[\max(\delta_i(L_i(T_i)-K),0) \mid \mathcal F(t) \right].
\end{align}
Since $L_i$ is lognormal under $\mathbb{Q}^{(T_{i+1})}$, the price is given by the Black formula. Caplets price cleanly because their payoff depends on a \emph{single} LIBOR rate, which is lognormal under the appropriate forward measure.

\textbf{Definition.} The forward \textbf{swap rate} for a swap starting at $T_\alpha$ and ending at $T_\beta$ is
\begin{align}
    S_{\alpha,\beta}(t)=\frac{B(t,T_\alpha) - B(t,T_\beta)}
    {\sum_{k=\alpha}^{\beta-1} \delta_k B(t,T_{k+1})}.
\end{align}
The swap rate is a nonlinear function of multiple LIBOR rates. There exists no measure under which it is exactly lognormal.

\textbf{Procedure.} To calibrate the LMM:
\begin{itemize}
    \item Calibrate individual $\sigma_i(t)$ to caplet implied volatilities.
    \item Fit the correlation matrix to swaption prices.
    \item Validate joint dynamics via Monte Carlo pricing of exotic payoffs.
\end{itemize}

\textbf{Remark (Post-LIBOR).} Although LIBOR has been discontinued, the modeling framework survives in adapted forms (e.g.\ for SOFR-based forward rates), and the LMM remains foundational for understanding multi-rate interest rate modeling.

\section{Credit Risk Modeling}

\textbf{Motivation.} It is possible that a counterparty fails to meet its contractual obligations. How should parties factor that risk into their prices? The central object of interest is thus the random default time, whose distribution determines survival probabilities, credit spreads, and the valuation of credit-sensitive instruments, which will be investigated in this section.

\subsection{Structural Credit Risk Models}

\textbf{Motivation.} Structural models view default as the outcome of the firm’s asset value deteriorating relative to its liabilities. These models provide strong economic intuition and link credit risk to equity dynamics.

\textbf{Theorem.} Let the firm asset process $(A_t)$ follow a geometric Brownian motion
\begin{align}
dA(t) = \mu A(t)\,dt + \sigma A(t)\,dW_t.
\end{align}
Default occurs at maturity $T$ if
\begin{align}
A(T) < D,
\end{align}
where $D$ denotes the face value of the firm’s debt.
The \textbf{distance to default} is defined by
\begin{align}
\text{DD} = \frac{\log(A(0)/D) + (\mu - \frac{1}{2}\sigma^2)T}{\sigma\sqrt{T}}.
\end{align}

Under the \textbf{Merton model}, the probability of default is
\begin{align}
\mathbb{P}(A(T) < D) = \Phi(-\text{DD}),
\end{align}
where $\Phi$ denotes the standard normal cumulative distribution function.

\textbf{Remark.}
The Merton model implies that default can only occur at maturity and typically underestimates short-term credit spreads. Furthermore, credit spreads are strongly tied to equity volatility, which is inconsistent with observed market behavior for distressed firms.

\textbf{Definition.}
Let $(\Omega,\mathcal{F},(\mathcal{F}_t)_{t\ge0},\mathbb{P})$ be a filtered probability space. A \textbf{default time} $\tau$ is a non-negative random variable representing the time at which default occurs. In barrier models such as \textbf{Black-Cox}, \textbf{barrier default} occurs at the stopping time
\begin{align}
\tau = \inf\{t \ge 0 : A(t) \le K(t)\},
\end{align}
where $K(t)$ is a deterministic default barrier. This becomes a first hitting time problem for Brownian motion.

\textbf{Remark.}
Barrier models allow for early default and improve short-term spread behavior relative to the Merton model, but remain sensitive to equity dynamics and the specification of the default barrier.

\subsection{Reduced-Form Credit Models}

Reduced-form models treat default as an exogenous jump event and are the dominant framework for pricing and calibration in practice.

\textbf{Definition.} The survival process is defined by a \textbf{survival indicator}
\begin{align}
\mathbb{I}_{\{\tau > t\}}.
\end{align}
The \textbf{survival probability} from time $t$ to maturity $T$ is
\begin{align}
Q(t,T) = \mathbb{P}(\tau > T \mid \mathcal{F}(t)).
\end{align}

\textbf{Definition.}
The \textbf{recovery rate} $R \in [0,1]$ is the fraction of notional recovered in the event of default.

\textbf{Remark.}
Common modeling choices include constant recovery, stochastic recovery correlated with default, and alternative recovery conventions such as recovery of par or recovery of market value. In practice, constant recovery is widely assumed due to tractability and calibration constraints.

\textbf{Definition.} A non-negative adapted process $(\lambda(t))_{t\ge0}$ is called the \textbf{default intensity} if
\begin{align}
\mathbb{P}(\tau \in [t,t+dt) \mid \mathcal{F}(t), \tau > t) = \lambda(t)\,dt.
\end{align}

\textbf{Proposition.} In the \textbf{survival probability representation}, if $\lambda_t$ is the default intensity, then
\begin{align}
Q(0,T) = \mathbb{E}\!\left[\exp\!\left(-\int_0^T \lambda(s)\,ds\right)\right].
\end{align}
If $\lambda_t$ is deterministic,
\begin{align}
Q(0,T) = \exp\!\left(-\int_0^T \lambda(s)\,ds\right).
\end{align}

\textbf{Remark.}
Market instruments reveal default intensities under the risk-neutral measure $\mathbb{Q}$, which embed both expected default losses and risk premia. Physical default probabilities require additional modeling assumptions or historical estimation.

\textbf{Definition.} The \textbf{credit spread} $s(T)$ is the yield difference between a defaultable zero-coupon bond and a default-free bond of the same maturity.

\textbf{Proposition.}
Under deterministic interest rates, deterministic intensity $\lambda(t)$, and recovery rate $R$, the credit spread satisfies approximately
\begin{align}
s(T) \approx (1-R)\frac{1}{T}\int_0^T \lambda(s)\,ds.
\end{align}

\subsection{CDSs and CDOs}

\textbf{Definition.} A \textbf{credit default swap (CDS)} on a defaultable security exchanges periodic premium payments for a default-contingent payment of $(1-R)$ upon default.

\textbf{Proposition.}
The CDS spread $S$ must respect no arbitrage. Since the CDS has no value at the initial time,
\begin{align}
\text{PV}_{\text{premium}} = \text{PV}_{\text{protection}}.
\end{align}
The present value of the protection leg is the expectation of the discounted future $(1-R)$ payout
\begin{align}
    \text{PV}_{\text{protection}} &= \mathbb{E}\left[(1 - R)\int_0^T D(0,t) \, d\mathbb{I}_{\{\tau \le t\}}\right].
\end{align}
Since $\mathbb{E}[d\mathbb{I}_{\{\tau \le t\}}] = d\mathbb{P}(\tau \leq t)$, this is
\begin{align}
    \text{PV}_{\text{protection}} &= (1 - R)\int_0^T D(0,t) \, d(1-Q(0,t)).
\end{align}
The buyer pays $S\mathbb{I}_{\{\tau > t\}}dt$ at each moment in time, so the present value of the premium is similarly
\begin{align}
    \text{PV}_{\text{premium}} = \mathbb{E}\left[\int_0^T D(0,t) \, S\mathbb{I}_{\{\tau > t\}}dt\right]
    =S \int_0^T D(0,t) \, Q(0,t)dt.
\end{align}
In discretized premium payments, this is
\begin{align}
S \sum_i \Delta_i D(0,T_i) Q(0,T_i)
=
(1-R)\int_0^T D(0,t)\, d(1-Q(0,t)).
\end{align}

\textbf{Remark.} If default occurs between payment dates, the \textbf{accrued premium} must be included in the valuation.

\textbf{Procedure (Bootstrapping).}
Given market CDS spreads:
\begin{enumerate}
\item Assume piecewise-constant default intensities.
\begin{align}
\lambda(t) = \lambda_i, \quad t \in [T_{i-1},T_i).
\end{align}
\item Solve sequentially for $\lambda_i$ such that model CDS spreads match market quotes.
\item Recover survival probabilities via
\begin{align}
Q(0,T_i) = \exp\!\left(-\sum_{j \le i} \lambda_j \Delta T_j\right).
\end{align}
\end{enumerate}

\textbf{Remark.} Single-name calibration does not determine joint default behavior. Modeling portfolio credit risk requires explicit assumptions on default dependence.

\textbf{Definition.} A \textbf{collateralized debt obligation (CDO)} redistributes the payouts and losses of a credit portfolio into tranches with different seniority levels. Tranche losses depend critically on default correlation.

Call $L(t)$ the cumulative \textbf{portfolio loss} at time $t$
\begin{align}
    L(t) = \sum_{i=1}^d (1-R_i)\mathbf{1}_{\{\tau_i \le t\}}.
\end{align}
For a tranche with attachment point $A$ and detachment point $D$, the \textbf{tranche loss} at time $t$ is
\begin{align}
    L^{A,D}(t)=\min\!\bigl(D-A,\;\max(L(t)-A,0)\bigr).
\end{align}

\textbf{Remark.}
Expected tranche losses depend on the full joint distribution of default times, and are therefore sensitive to default correlation. In a single-name credit model, $Q_i(t) = \mathbb{P}(\tau_i > t)$, yet in something like a CDO, $\mathbb{P}(\tau_1 >t_1,...,\tau_n>t_n)$ would be needed. We would like to add the joint dependence between otherwise independently calibrated default times (marginals).

\textbf{Definition.} Let $(X_1,...,X_d)$ be a random vector, with each random variable having continuous marginal cumulative distribution functions $F_i(x) = \mathbb{P}(X_j \leq x)$. Via the probability integral transform,
\begin{align}
    (U_1,...,U_d) = (F_1(X_1),...,F_d(X_d))
\end{align}
has uniform distribution marginals. The \textbf{copula} is the joint cumulative distribution function of this distribution
\begin{align}
    C(u_1,...,u_d) = \mathbb{P}(U_1 \leq u_1,...,U_d \leq u_d).
\end{align}

\textbf{Proposition.} Let $F_i(t) = \mathbb{P}(\tau_i \le t)$ denote the marginal default distribution of name $i$, calibrated from single-name CDS data.
Let $(U_1,\dots,U_d)$ be a random vector with copula $C$.
Define default times by
\begin{align}
    \tau_i = F_i^{-1}(U_i).
\end{align}
Then each $\tau_i$ has marginal distribution $F_i$, and the joint dependence between default times is fully characterized by the copula $C$.

\textbf{Definition.} A $d$-dimensional \textbf{Gaussian copula} with $d \times d$ correlation matrix $\Sigma$ is
\begin{align}
    C^{Gauss}_R((u_1,...,u_d)) = \Phi_R(\Phi^{-1}(u_1),...,\Phi^{-1}(u_d)),
\end{align}
for $\Phi^{-1}$ the inverse standard normal CDF and $\Phi_R$ the multivariate CDF of a Gaussian with mean zero and covariance matrix equal to the correlation matrix.

In the \textbf{one-factor Gaussian copula model}, latent variables $(Z_1,\dots,Z_d)$ are defined by
\begin{align}
    Z_i = \sqrt{\rho}\,X + \sqrt{1-\rho}\,\varepsilon_i,
\end{align}
where $X,\varepsilon_i \sim \mathcal{N}(0,1)$ are independent, and $\rho \in [0,1]$ is the asset correlation parameter.
The default times are then defined as
\begin{align}
    \tau_i = F_i^{-1}(\Phi(Z_i)).
\end{align}
The parameter $\rho$ controls the proportion of default risk attributable to a common systemic factor. Equity tranches are primarily driven by idiosyncratic risk, while senior tranches are dominated by systemic risk.

\textbf{Example (CDS and CDO pricing).}

Consider a 5-year CDS on a corporate bond with recovery $R=40\%$ and risk-free discount factor $D(0,t) = e^{-0.02 t}$. Suppose the market quotes the 5-year CDS spread as $S = 100$ bps.  

Assume piecewise-constant default intensity $\lambda(t) = \lambda$ over $[0,5]$ years. The survival probability is
\begin{align}
Q(0,T) = e^{-\lambda T}.
\end{align}

The present value of the premium leg is
\begin{align}
S \int_0^5 D(0,t) Q(0,t) \, dt = S \int_0^5 e^{-0.02 t} e^{-\lambda t} dt \\
= S \int_0^5 e^{-(\lambda + 0.02)t} dt.
\end{align}

The present value of the protection leg is
\begin{align}
(1-R) \int_0^5 D(0,t) \, d(1-Q(0,t)) 
= 0.6 \int_0^5 e^{-0.02 t} \lambda e^{-\lambda t} dt \\= 0.6 \lambda \int_0^5 e^{-(\lambda + 0.02) t} dt.
\end{align}

Equating PVs for no-arbitrage,
\begin{align}
S \int_0^5 e^{-(\lambda + 0.02)t} dt = 0.6 \lambda \int_0^5 e^{-(\lambda + 0.02) t} dt
\quad \implies \quad
\lambda   \approx 0.0167.
\end{align}

Thus, the implied default intensity is $\lambda \approx 1.67\%$ per year. The 5-year survival probability is
\begin{align}
Q(0,5) = e^{-0.0167 \cdot 5} \approx 0.921.
\end{align}

\bigskip

Now, consider a 10-name portfolio of identical names with marginal default distributions calibrated as above. Take the 0--3\% equity tranche.  

Using a one-factor Gaussian copula, the latent variables are
\begin{align}
Z_i = \sqrt{\rho} X + \sqrt{1-\rho} \varepsilon_i, \qquad X,\varepsilon_i \sim \mathcal{N}(0,1) \text{ i.i.d.}
\end{align}
and default times are
\begin{align}
\tau_i = F_i^{-1}(\Phi(Z_i)), \qquad F_i(t) = 1 - Q(0,t).
\end{align}

For a given systemic correlation $\rho = 0.2$, we can simulate the tranche loss at $T=5$:
\begin{align}
L^{0,0.03}(T) = \min\bigl(0.03, \max(L(T)-0,0)\bigr),\\ L(T) = \frac{1}{10}\sum_{i=1}^{10} (1-R) \mathbf{1}_{\{\tau_i \le 5\}}.
\end{align}

A Monte Carlo with $N=10,000$ scenarios yields the expected equity tranche loss
\begin{align}
\mathbb{E}[L^{0,0.03}(T)] \approx 2.1\%.
\end{align}




\textbf{Remark.} There are several limitations to the model. The Gaussian copula exhibits zero upper \textbf{tail dependence}:
\begin{align}
    \lambda_U=\lim_{u \uparrow 1}\mathbb{P}(U_2 > u \mid U_1 > u)=0.
\end{align}
Thus extreme default events do not cluster sufficiently under this model. In practice, different CDO tranches imply different implied correlation parameters, indicating that a single Gaussian copula parameter cannot simultaneously fit all tranches.


\section{Counterparty Risk and XVA}

\textbf{Definition.} \textbf{Counterparty risk} is the risk that a trading counterparty defaults prior to the maturity of a contract, causing losses due to the replacement cost of the position at default.

\textbf{Definition.} Let $V(t)$ denote the mark-to-market value of a derivative portfolio at time $t$ from the perspective of the investor. The \textbf{exposure} is defined as
\begin{align}
    E(t) = V(t).
\end{align}
The positive and negative parts are
\begin{align}
    E^+(t) = \max(V(t),0), \qquad E^-(t) = \max(-V(t),0).
\end{align}

\textbf{Definition.}
The \textbf{expected positive exposure (EPE)} and \textbf{expected negative exposure (ENE)} are
\begin{align}
    \text{EPE}(t) = \mathbb{E}[E^+(t)], \qquad
    \text{ENE}(t) = \mathbb{E}[E^-(t)],
\end{align}
where the expectation is taken under the risk-neutral measure.

\textbf{Remark.} In the presence of collateral and funding costs, the curve used for discounting cash flows need not coincide with the risk-free curve. Discounting reflects the remuneration of collateral, while funding curves reflect the institution’s actual borrowing and lending costs. This separation breaks the classical risk-neutral pricing framework and leads naturally to valuation adjustments.

\textbf{Definition.} \textbf{Collateral agreements} specify the posting of variation margin to cover current exposure and initial margin to cover potential future exposure. Let $C(t)$ denote the collateral account, then the collateralized exposure is
\begin{align}
    \widetilde{E}(t) = V(t) - C(t).
\end{align}

\textbf{Definition.} The following are adjustments to prices:
\begin{itemize}
    
\item \textbf{Credit Valuation Adjustment (CVA)} represents the expected loss due to counterparty default:
\begin{align}
    \text{CVA}
    =
    (1-R_c)\int_0^T D(0,t)\,\mathbb{E}[\widetilde{E}^+(t)]\, d\mathbb{P}(\tau_c \le t),
\end{align}
where $R_c$ is the counterparty recovery rate and $\tau_c$ is the counterparty default time.

\item \textbf{Debit Valuation Adjustment (DVA)} accounts for the institution’s own default risk:
\begin{align}
    \text{DVA}
    =
    (1-R_o)\int_0^T D(0,t)\,\mathbb{E}[\widetilde{E}^-(t)]\, d\mathbb{P}(\tau_o \le t),
\end{align}
where $\tau_o$ denotes the investor’s own default time.

\item \textbf{Funding Valuation Adjustment (FVA)} captures the cost or benefit of funding uncollateralized exposures:
\begin{align}
    \text{FVA}
    =
    \int_0^T D(0,t)\,\mathbb{E}[\widetilde{E}(t)]\, s_f(t)\, dt,
\end{align}
where $s_f(t)$ is the funding spread over the discounting rate.

\item \textbf{Capital Valuation Adjustment (KVA)} reflects the cost of holding regulatory capital against counterparty risk:
\begin{align}
    \text{KVA}
    =
    \int_0^T D(0,t)\,\mathbb{E}[K(t)]\, h\, dt,
\end{align}
where $K(t)$ is the required capital and $h$ is the hurdle rate.

\item \textbf{Margin Valuation Adjustment (MVA)} accounts for the funding cost of posting initial margin:
\begin{align}
    \text{MVA}
    =
    \int_0^T D(0,t)\,\mathbb{E}[\text{IM}(t)]\, s_f(t)\, dt.
\end{align}
\end{itemize}

\textbf{Remark.} While CVA represents a true economic cost, DVA reflects an accounting benefit and is controversial from a risk management perspective.

\textbf{Note.} Exposure profiles are typically computed by simulating the joint evolution of market risk factors and valuation paths, followed by computing $V(t)$ and collateral dynamically along each path.

\textbf{Definition.} \textbf{Wrong-way risk} arises when exposure and counterparty credit quality are positively correlated:
\begin{align}
    \text{Corr}(E^+(t), \lambda_c(t)) > 0,
\end{align}
where $\lambda_c(t)$ is the counterparty default intensity. Wrong-way risk invalidates factorized CVA formulas and requires joint modeling of market and credit risk.

\textbf{Definition.} A \textbf{netting set} is a collection of transactions subject to a legally enforceable netting agreement, under which exposures are aggregated before collateral and close-out are applied.

\textbf{Definition.} Upon default, the \textbf{close-out} amount specifies the valuation used to settle remaining obligations. Common conventions include risk-free close-out and replacement close-out, leading to different XVA implications.

\textbf{Proposition.} The full valuation of a derivative portfolio is therefore given by
\begin{align}
    V_{\text{total}}
    =
    V_{\text{clean}}
    - \text{CVA}
    + \text{DVA}
    - \text{FVA}
    - \text{KVA}
    - \text{MVA}.
\end{align}

\textbf{Example (XVA for a swap).}

Consider a 5-year payer interest rate swap (IRS) with notional \$100M, fixed rate $K=2\%$, floating payments quarterly, and discounting at $r=1\%$ flat. Assume the counterparty has recovery $R_c = 40\%$ and the investor has recovery $R_o = 40\%$.  

Let $V(t)$ denote the mark-to-market value of the IRS at time $t$ from the investor’s perspective. For simplicity, assume a deterministic exposure profile given by the following positive expected exposure (EPE):
\begin{align}
\text{EPE}(t) = \mathbb{E}[E^+(t)] = 5 \, e^{-0.05 t} \text{ (in \$M)}.
\end{align}

Similarly, the expected negative exposure (ENE) is:
\begin{align}
\text{ENE}(t) = \mathbb{E}[E^-(t)] = 2 \, e^{-0.05 t} \text{ (in \$M)}.
\end{align}

Let the counterparty default intensity be constant $\lambda_c = 1\%$ per year, and the investor’s own default intensity be $\lambda_o = 0.5\%$. The survival probability for counterparty up to time $t$ is
\begin{align}
Q_c(t) = e^{-\lambda_c t}.
\end{align}


Using the continuous-time approximation for CVA:
\begin{align}
\text{CVA} &= (1-R_c) \int_0^5 D(0,t) \, \text{EPE}(t) \, d(1-Q_c(t)) 
\\&= (1-0.4) \int_0^5 e^{-0.01 t} \cdot 5 e^{-0.05 t} \cdot \lambda_c e^{-\lambda_c t} dt.\\
&= 0.03 \int_0^5 e^{-0.07 t} dt.\\
&\approx 0.03 \cdot 4.21 \approx 0.126 \text{ (\$M)}.
\end{align}

Similarly, for the investor’s own default (DVA):
\begin{align}
\text{DVA} &= (1-R_o) \int_0^5 D(0,t) \, \text{ENE}(t) \, d(1-Q_o(t)) \\
&= 0.6 \int_0^5 e^{-0.01 t} \cdot 2 e^{-0.05 t} \cdot 0.005 e^{-0.005 t} dt.\\
&\approx 0.006 \cdot 4.27 \approx 0.0256 \text{ (\$M)}.
\end{align}

Now, assume no FVA, KVA, or MVA for simplicity. If the clean (risk-free) value of the IRS is \$0.8M:
\begin{align}
V_{\text{total}} = V_{\text{clean}} - \text{CVA} + \text{DVA} 
= 0.8 - 0.126 + 0.0256 \approx 0.6996 \text{ (\$M)}.
\end{align}

The CVA reduces the portfolio value due to counterparty credit risk, while the DVA partially offsets this, reflecting the investor’s own default risk.In practice, exposure profiles are stochastic and would be computed via Monte Carlo simulations of the underlying market risk factors. Netting and wrong-way risk would adjust the EPE and ENE further.


\chapter{Portfolio Management}

\textbf{Motivation.} How can positions be hedged against risk? Can positions "beat the market" without incurring large risk? This section investigates investment allocation.

\section{Portfolio Theory}

\subsection{Mean-Variance Analysis}

\textbf{Definition.} Consider a single-period economy with $m$ risky assets and one risk-free asset. Let the random returns on the risky assets be
\begin{align}
    \vec{R} = (R_1,\dots,R_m),
\end{align}
and let the risk-free return be constant,
\begin{align}
    R_0 = r_0.
\end{align}

Let $\vec{w} = (w_1,\dots,w_m)$ denote the portfolio weights invested in the risky assets. The weight invested in the risk-free asset is
\begin{align}
    w_0 = 1 - \vec{w}\cdot\vec{1}_m,
\end{align}
which may be negative in the presence of borrowing.

The portfolio return is
\begin{align}
    R_p = \vec{w}\cdot\vec{R} + w_0 r_0.
\end{align}

Define the vector of expected returns and the covariance matrix by
\begin{align}
    \vec{\mu} = \mathbb{E}[\vec{R}], 
    \qquad
    \Sigma = \mathrm{Var}(\vec{R}) = \big(\mathrm{Cov}(R_i,R_j)\big)_{i,j=1}^m,
\end{align}
where $\Sigma$ is symmetric and positive definite.

Then the mean and variance of the portfolio return under the \textbf{Markowitz model} are
\begin{align}
    \mathbb{E}[R_p] = \vec{w}\cdot\vec{\mu} + (1-\vec{w}\cdot\vec{1}_m)r_0, \quad
    \mathrm{Var}(R_p) = \vec{w}^\top \Sigma \vec{w}.
\end{align}

\textbf{Definition.} A rational investor is assumed to have an increasing, concave utility function $U$. The \textbf{portfolio choice problem} is
\begin{align}
    \max_{\vec{w}} \; \mathbb{E}\big[U(1+R_p)\big].
\end{align}

For power utility with constant relative risk aversion $\gamma>0$,
\begin{align}
    U(x) = \frac{x^{1-\gamma}}{1-\gamma},
\end{align}
a second-order Taylor approximation implies that maximizing expected utility is equivalent to the mean-variance problem
\begin{align}
    \max_{\vec{w}} \; 
    \Big( \mathbb{E}[R_p] - \frac{\gamma}{2}\mathrm{Var}(R_p) \Big).
\end{align}

\textbf{Theorem (Optimal portfolio).}
The solution to the mean--variance optimization problem is
\begin{align}
    \vec{w}^\ast = \frac{1}{\gamma}\Sigma^{-1}(\vec{\mu}-r_0\vec{1}_m),
\end{align}
with the remaining wealth invested in the risk-free asset.

The set of all optimal portfolios for varying $\gamma$ forms the \textbf{mean-variance efficient frontier}.

\textbf{Remark.} This is the equivalent of the \textbf{Kelly criterion} for optimal bet size in continuous time, with the addition of the risk-free asset and the risk aversion.

\textbf{Definition.} The \textbf{tangency portfolio} is the unique efficient portfolio that is fully invested in risky assets, i.e.\ whose weights sum to one. The corresponding risk aversion is
\begin{align}
    \hat{\gamma} = \vec{1}_m^\top \Sigma^{-1}(\vec{\mu}-r_0\vec{1}_m).
\end{align}

The tangency portfolio weights are
\begin{align}
    \hat{\vec{w}} = \frac{1}{\hat{\gamma}}\Sigma^{-1}(\vec{\mu}-r_0\vec{1}_m),
\end{align}
and its expected return is
\begin{align}
    \mathbb{E}[\hat{R}_p] = \hat{\vec{w}}\cdot\vec{\mu}.
\end{align}

\textbf{Theorem (Two-fund separation).}
Every optimal portfolio can be written as a combination of the risk-free asset and the tangency portfolio:
\begin{align}
    \vec{w} = \frac{\hat{\gamma}}{\gamma}\hat{\vec{w}}.
\end{align}

Consequently,
\begin{align}
    \mathbb{E}[R_p] = r_0 + \frac{\hat{\gamma}}{\gamma}\big(\mathbb{E}[\hat{R}_p]-r_0\big), \quad
    \mathrm{Var}(R_p) = \frac{\hat{\gamma}^2}{\gamma^2}\mathrm{Var}(\hat{R}_p).
\end{align}

\textbf{Definition.} Eliminating $\gamma$ yields
\begin{align}
    \mathbb{E}[R_p]
    = r_0 + 
    \frac{\mathbb{E}[\hat{R}_p]-r_0}{\sqrt{\mathrm{Var}(\hat{R}_p)}}
    \sqrt{\mathrm{Var}(R_p)},
\end{align}
which defines the \textbf{capital allocation line (CAL)}. Its slope is the \textbf{Sharpe ratio} of the tangency portfolio.

\subsection{Factor Models and Evaluation}

\textbf{Theorem.} In equilibrium, asset returns must be consistent with the portfolio choices of all investors. Assume that all investors are mean-variance optimizers, there exists a risk-free asset, investors have homogeneous beliefs, and markets clear. Let the \textbf{market portfolio} be the value-weighted portfolio of all risky assets, with weights $\vec{w}_m$. Its expected return is
\begin{align}
    \mathbb{E}[R_m] = \vec{w}_m\cdot\vec{\mu} + (1-\vec{w}_m\cdot\vec{1}_m)r_0.
\end{align}

Then under the \textbf{capital asset pricing model (CAPM)}, each asset $i$ has,
\begin{align}
    \mathbb{E}[R_i - r_0] = \beta_i \mathbb{E}[R_m - r_0],
\end{align}
where
\begin{align}
    \beta_i = \frac{\mathrm{Cov}(R_i,R_m)}{\mathrm{Var}(R_m)}.
\end{align}

Thus, only systematic risk, as measured by $\beta_i$, is priced in equilibrium.

\textbf{Definition.} More generally, expected returns may depend on exposure to multiple systematic risk factors. Call a \textbf{multi-factor model} on factors $F_1,\dots,F_J$:
\begin{align}
    \mathbb{E}[R_i - r_0] = \sum_{j=1}^J \beta_{i,j}\mathbb{E}[F_j],
\end{align}
with factor loadings
\begin{align}
    \beta_{i,j} = \frac{\mathrm{Cov}(R_i,F_j)}{\mathrm{Var}(F_j)}.
\end{align}

Such models include the Fama-French factor models and form the basis for empirical asset pricing.

\textbf{Definition.} In practice, portfolio performance is evaluated relative to a benchmark, often represented as a factor or portfolio. Given a factor model, fund returns satisfy the time-series regression
\begin{align}
    R_{i,t} - r_{0,t}= \sum_{j=1}^J \beta_{i,j} F_{j,t} + \alpha_i + \varepsilon_{i,t},
\end{align}
where \textbf{alpha}, $\alpha_i$, measures abnormal performance not explained by factor exposures, and each \textbf{beta} measures performance via correlation with the factors.

\textbf{Definition.} The \textbf{information ratio} of a fund is defined as
\begin{align}
    \mathrm{IR}_i = \frac{\alpha_i}{\sigma(\varepsilon_{i,t})},
\end{align}
and measures risk-adjusted excess performance relative to the benchmark.

\section{Portfolio Risk}

\textbf{Motivation.} Practical investment requires explicit control, measurement, and mitigation of risk. Risk management provides quantitative tools to measure downside exposure, enforce limits, and ensure portfolio robustness under adverse market conditions.

\textbf{Definition.} Let $L$ be a real-valued random variable representing the \textbf{loss} of a portfolio over a fixed horizon, where positive values correspond to losses. The distribution of $L$ summarizes the portfolio's risk profile.

\textbf{Definition.} For a confidence level $\alpha \in (0,1)$, the \textbf{Value at Risk (VaR)} at level $\alpha$ is defined as
\begin{align}
    \mathrm{VaR}_\alpha(L)
    = \inf \big\{ \ell \in \mathbb{R} : \mathbb{P}(L \le \ell) \ge \alpha \big\}.
\end{align}
Equivalently, $\mathrm{VaR}_\alpha$ is the $\alpha$-quantile of the loss distribution. With probability $\alpha$, the realized loss will not exceed $\mathrm{VaR}_\alpha$ over the given horizon.

\textbf{Remark.} Despite its widespread use, VaR has important theoretical shortcomings. The failure of subadditivity implies that diversification may appear to \emph{increase} risk under VaR, contradicting basic financial intuition.

\textbf{Definition.}
The \textbf{Expected Shortfall} (ES), also called \textbf{Conditional Value at Risk (CVaR)}, at level $\alpha$ is
\begin{align}
    \mathrm{ES}_\alpha(L)
    = \mathbb{E}\big[ L \mid L \ge \mathrm{VaR}_\alpha(L) \big].
\end{align}
It measures the expected loss in the worst $(1-\alpha)$ fraction of cases.

\textbf{Definition.}
A risk measure $\rho(L)$ is called \textbf{coherent} if it satisfies:
\begin{enumerate}
    \item \textit{Monotonicity:} $L_1 \le L_2 \Rightarrow \rho(L_1) \le \rho(L_2)$
    \item \textit{Translation invariance:} $\rho(L + c) = \rho(L) + c$
    \item \textit{Positive homogeneity:} $\rho(\lambda L) = \lambda \rho(L)$ for $\lambda > 0$
    \item \textit{Subadditivity:} $\rho(L_1 + L_2) \le \rho(L_1) + \rho(L_2)$
\end{enumerate}

\textbf{Theorem.}
Expected Shortfall is a coherent risk measure, whereas Value at Risk is not in general.

\textbf{Definition.}
Let $W_t$ denote portfolio value. The \textbf{maximum drawdown} over $[0,T]$ is
\begin{align}
    \mathrm{MDD}
    = \max_{0 \le t \le T}
    \left(
        \sup_{0 \le s \le t} W_s - W_t
    \right).
\end{align}

\textbf{Remark.}
Drawdowns capture path-dependent risk ignored by variance-based measures and are central to capital allocation, leverage control, and investor behavior.

\textbf{Proposition (Diversification).}
For a portfolio with weight vector $\vec{w}$ and covariance matrix $\Sigma$,
\begin{align}
    \mathrm{Var}(R_p) = \vec{w}^\top \Sigma \vec{w}
\end{align}
is reduced when assets exhibit imperfect correlation.

\textit{Proof:} Expanding the quadratic form gives $\vec{w}^\top \Sigma \vec{w} = \sum_i^m w_i \sigma^2_i + \sum_{i \neq j} w_iw_jCov(\sigma_i,\sigma_j)$, and we know $Cov(\sigma_i,\sigma_j) = \rho_{ij}\sigma_i\sigma_j$. Hence, this can be written as $\sum_i^m w_i \sigma^2_i + \sum_{i \neq j} w_iw_j\rho_{ij}\sigma_i\sigma_j$. Since $\rho_{ij} \in [-1,1]$, we thus have $\vec{w}^\top \Sigma \vec{w} \leq (\sum_i^m w_i \sigma_i)^2$, since the cross terms in the portfolio variance are less than or equal to the square of the sum of weighted standard deviations.

\textbf{Remark.} Diversification is helpful in eliminating \textbf{idiosyncratic risk} of individual securities, however it cannot eliminate \textbf{systemic risk} that affects the entire market.

\textbf{Definition.}
The \textbf{marginal risk contribution} contribution of asset $i$ to portfolio variance is
\begin{align}
    \mathrm{MRC}_i = \frac{\partial}{\partial w_i} \mathrm{Var}(R_p)
    = 2(\Sigma \vec{w})_i.
\end{align}
The \textbf{total risk contribution} of asset $i$ is
\begin{align}
    \mathrm{RC}_i = w_i (\Sigma \vec{w})_i.
\end{align}

\textbf{Proposition.} Consider a \textbf{hedge}, a position constructed to reduce sensitivity to a given risk factor, typically by taking an offsetting exposure. Let a portfolio have factor exposure $\beta$ to a risk factor $F$. A hedge position $h$ satisfying
\begin{align}
    \beta_{\text{portfolio}} + \beta_h = 0
\end{align}
eliminates first-order exposure to $F$.

\textbf{Remark.}
In practice, hedging reduces variance but may introduce basis risk, transaction costs, and model risk.

\textbf{Definition.}
A \textbf{risk limit} is a constraint imposed on a portfolio risk measure, such as
\begin{align}
    \mathrm{VaR}_\alpha(L) \le \ell_{\max},
    \qquad
    \mathrm{ES}_\alpha(L) \le e_{\max},
\end{align}
or on factor exposures, leverage, or drawdowns.

\textbf{Proposition.}
Imposing convex risk constraints preserves tractability of portfolio optimization problems and prevents excessive concentration or leverage.

\textbf{Definition.} A \textbf{stress test} evaluates portfolio performance under extreme but plausible scenarios, such as large volatility shocks, correlation breakdowns, liquidity freezes, or macroeconomic regime shifts. More generally, \textbf{scenario analysis} computes portfolio losses under explicitly specified joint moves in risk factors.


\chapter{Markets and Trading}

\textbf{Motivation.} Unlike frictionless models in asset pricing, liquidity, transaction costs, and strategic behavior impact how traders behave. Market microstructure studies how trades are executed in practice and how prices form through the interaction of market participants. 

\section{Exchanges}

\textbf{Definition.} A \textbf{securities exchange} is a market venue for the exchange of stocks, bonds, etc. between stockbrokers and traders. Tradable securities are \emph{listed} on the exchange, and transactions are done by \emph{open outcry auction}. Examples are the NYSE and NASDAQ, which trade stocks, bonds, options, exchange-traded funds (ETFs), and more. Stocks do not need to be traded on exchanges, and products such as forwards or swaps are traded off-exchange directly between two parties, known as \textbf{over-the-counter}.

\textbf{Definition.} A \textbf{broker} is an agent who trades stocks and other investments on an exchange on behalf of someone else for a markup or fee. Since the average investor does not have a seat on the NYSE, brokerage firms such as Fidelity are the vehicle for investments. Stockbrokers in the US must pass Series exams, and generally act as advisors and investment managers for clients.

\textbf{Definition.} \textbf{Market liquidity} is a measure of the trade-off between how quickly an asset can be sold and at what price it can be sold. In a liquid markets, assets can be converted into cash easily and quickly, without greatly impacting market price.

\textbf{Definition.} In a transaction of a good or asset, \textbf{adverse selection} occurs when one party, either the buyer or the seller, has information about the product quality that the other party does not. This asymmetric information might concern hidden defects, such as the famous ''market for Lemons''.

\textbf{Definition.}
A \textbf{central limit order book (CLOB)} is a market mechanism that records outstanding buy and sell limit orders for a given asset. At any time $t$, the order book consists of:
\begin{itemize}
    \item A set of \textbf{bid} (buyers) prices $\{p_i^b\}$ with associated volumes $\{q_i^b\}$,
    \item A set of \textbf{ask} (sellers) prices $\{p_j^a\}$ with associated volumes $\{q_j^a\}$,
\end{itemize}
where bids are sorted in decreasing price order and asks in increasing price order.

\textbf{Definition.}
The \textbf{best bid} $p_t^b$ is the highest outstanding bid price, and the \textbf{best ask} $p_t^a$ is the lowest outstanding ask price. The \textbf{midprice} and \textbf{bid-ask spread} are defined respectively by
\begin{align}
    m_t = \frac{p_t^a + p_t^b}{2}, \quad 
    s_t = p_t^a - p_t^b .
\end{align}
The midprice is commonly used as a proxy for the ``efficient price''.

\textbf{Definition.}
Common order types include:
\begin{itemize}
    \item \textbf{Market orders}, which execute immediately against the best available prices,
    \item \textbf{Limit orders}, which specify a maximum (buy) or minimum (sell) execution price,
    \item \textbf{Cancel orders}, which remove existing limit orders.
\end{itemize}

\textbf{Remark.}
Market orders consume liquidity, while limit orders provide liquidity. The interaction between the two drives short-term price dynamics.

\textbf{Definition.} A \textbf{market maker} is a firm that stands ready to buy or sell stocks at a publicly quoted price. The market maker provides liquidity to the market and profits via the bid-ask spread, which compensates for adverse selection and inventory risk. Examples of market makers are Jane Street or Optiver.

\textbf{Definition.} In contrast to a CLOB, a \textbf{Request for Quote (RFQ)} trade execution model occurs when buyers and sellers request bid and ask prices quoted from a number of market makers. Traders do not trade with each other at chosen prices, but rather with the market makers.

\section{Optimal Execution}

\textbf{Motivation.} Large trades cannot generally be executed instantaneously without incurring significant market impact. Optimal execution models aim to minimize trading costs while managing risk.

\textbf{Definition (Execution Problem).}
An agent seeks to execute a total quantity $Q$ of shares over a finite horizon $[0,T]$, by choosing a trading strategy $(q_t)_{t\in[0,T]}$, where $q_t$ denotes the trading rate.

\textbf{Assumptions.} The \textbf{Almgren-Chriss model} assumes the following:

The unaffected asset midprice $(S_t)_{t\in[0,T]}$ evolves as a martingale under the agent’s pricing measure:
\begin{align}
    dS_t = \sigma\, dW_t,
\end{align}
where $\sigma > 0$ is constant volatility and $W_t$ is a standard Brownian motion. The agent’s trades do not influence this reference price.

Trading at instantaneous rate $q_t$ affects execution prices through two channels: \emph{temporary impact}, reflecting liquidity consumption, which affects only the current execution price, and \emph{permanent impact}, reflecting information leakage or inventory effects, which shifts all future prices.

In the linear impact model, the execution price is
\begin{align}
    \widetilde S_t = S_t - \eta q_t - \gamma \int_0^t q_s\,ds,
\end{align}
where $\eta \ge 0$ and $\gamma \ge 0$ are coefficients representing the impacts respectively.

\textbf{Definition.} Let $X_t$ denote the remaining inventory at time $t$. The trading rate $q_t$ satisfies the \textbf{inventory process}
\begin{align}
    dX_t = -q_t\,dt, \qquad X_0 = Q, \quad X_T = 0.
\end{align}
The total \textbf{execution cost} relative to the initial mark-to-market value $Q S_0$ is
\begin{align}
    C=\int_0^T q_t \widetilde S_t\,dt - Q S_0.
\end{align}

\textbf{Proposition.} Under the above assumptions, the execution cost decomposes as
\begin{align}
    C=\eta \int_0^T q_t^2\,dt+\frac{\gamma}{2}Q^2-\sigma \int_0^T X_t\, dW_t.
\end{align}

\textbf{Remark.}
The first term represents temporary impact costs, the second term is the deterministic permanent impact cost, and the final term captures price risk due to holding inventory over time.

\textbf{Proposition.} For an agent choosing a trading strategy $(q_t)_{t\in[0,T]}$ to minimize the mean-variance criterion
\begin{align}
    \mathbb{E}[C] + \lambda \,\mathrm{Var}(C),
\end{align}
where $\lambda \ge 0$ is a risk-aversion parameter, the objective reduces to
\begin{align}
    \min_{(X_t)} \;\int_0^T \left(\eta \dot X_t^2+\lambda \sigma^2 X_t^2\right) dt,
\end{align}
subject to $X_0 = Q$ and $X_T = 0$.

\textbf{Theorem (Optimal execution path).}
The optimal inventory trajectory satisfies the Euler-Lagrange equation
\begin{align}
    \ddot X_t = \frac{\lambda \sigma^2}{\eta} X_t,
\end{align}
with boundary conditions $X_0 = Q$, $X_T = 0$.
The unique solution is
\begin{align}
    X_t=Q\frac{\sinh\!\bigl(\kappa(T-t)\bigr)}{\sinh(\kappa T)},
    \qquad
    \kappa = \sqrt{\frac{\lambda \sigma^2}{\eta}}.
\end{align}

\textbf{Corollary.}
The optimal trading speed is thus
\begin{align}
    q_t = -\dot X_t=Q\frac{\kappa \cosh\!\bigl(\kappa(T-t)\bigr)}{\sinh(\kappa T)}.
\end{align}
As $\lambda \to 0$, the strategy minimizes expected cost only and trades linearly in time. As $\lambda \to \infty$, the strategy becomes increasingly front-loaded, approaching instantaneous liquidation.

\textbf{Remark (Limitations).}
The Almgren-Chriss model assumes linear impact, continuous trading, and exogenous price dynamics. Extensions incorporate nonlinear impact, stochastic liquidity, discrete trading, and limit order book dynamics.

\chapter{Time Series Analysis}

\textbf{Motivation.} How can asset data over time be understood? Time series analysis concerns the modeling and statistical properties of data indexed in time order. In finance, understanding serial dependence, stationarity, and volatility dynamics is essential for forecasting, risk modeling, and econometric inference.

\section{Time Series Foundations}

\subsection{Models and Tests}

\textbf{Definition.}
A discrete-time stochastic process $\{X_t\}$ is a \textbf{time series}. The time series $\{X_t\}$ is \textbf{strictly stationary} if for all $m\in\mathbb{N}$ and all time shifts $\tau$,
\begin{align}
\mathbb{P}(X_{t_1+\tau},\ldots,X_{t_m+\tau}) = \mathbb{P}(X_{t_1},\ldots,X_{t_m}),
\end{align}
i.e., all finite–dimensional distributions are invariant under time shifts. $\{X_t\}$ is \textbf{weakly stationary} if
\begin{align}
\mathbb{E}[X_t]=\mu,\quad
\mathrm{Var}(X_t)=\sigma^2<\infty,\quad
\mathrm{Cov}(X_t,X_{t+\tau})=\Gamma(\tau),
\end{align}
where $\mu,\sigma^2,\Gamma(\tau)$ (autocovariance) do not depend on $t$. The \textbf{autocorrelation function} (ACF) is defined by
\begin{align}
\rho(\tau) = \frac{\gamma(\tau)}{\gamma(0)}.
\end{align}
Stationary $\{X_t\}$ is called \textbf{ergodic} if 
\begin{align}
    \lim_{T \rightarrow \infty} \frac 1T \sum_{1 \leq k \leq T} X_{t+k} = \mu
\end{align}

\textbf{Definition.} Define the \textbf{lag operator} $L$ by
\begin{align}
    L^k(X_t)=X_{t-k},
\end{align}
and the \textbf{difference operator} $\Delta$ by
\begin{align}
    \Delta^k = (1-L)^k.
\end{align}

\textbf{Theorem (Wold representation).} Any zero-mean weakly stationary process is equivalent to
\begin{align}
X_t = V_t + \sum_{i=0}^\infty\psi_i\eta_{t-i} = V_t + \sum_{i=0}^\infty\psi_iL^i\eta_t = V_t + \psi(L)\epsilon_t,
\end{align}
where $\{\epsilon_t\} \sim \mathcal{N}(0,\sigma^2)$ is linearly unpredictable white noise, $\psi_0=1$, $\sum_i\psi_i^2<\infty$, and $V_t$ is deterministic. This expresses $X_t$ as an infinite moving average.

\textbf{Definition.} For operator $\psi(L)$, if there exists an inverse
\begin{align}
    \psi^{-1}(L) = \sum_{i=0}^\infty\psi_i^*L^i,
\end{align}
such that $\psi(L)\psi^{-1}(L)=L^0$, then a moving average time series is \textbf{invertible} with equivalent autoregressive representation
\begin{align}
    X_t = \psi(L)\epsilon_t \Leftrightarrow \psi^{-1}(L)X_t =\epsilon_t.
\end{align}

\textbf{Definition.} An \textbf{MA($q$) (moving average) model} takes the form
\begin{align}
X_t-\mu = \theta(L)\epsilon_t,
\end{align}
for characteristic polynomial
\begin{align}
    \theta(z)=1+\theta_1z+\cdots+\theta_qz^q.
\end{align}

\textbf{Proposition.} MA($q$) processes are always weakly stationary.

\textit{Proof idea.} Taking the expected value of both sides yields $\mathbb{E}[X_t]=\mu$, since white noise has mean zero. Taking the covariance $Cov(X_t,X_{t+\tau})$ will yield zero for the expectation of different white noises, and will give the product of coefficients times $\sigma^2$ when white noises overlap. The number of identical white noises is determined by the lag $\tau$, so this is indeed weakly stationary.

\textbf{Definition.} An \textbf{AR($p$) (autoregressive) model} is
\begin{align}
\phi(L)(X_t-\mu) = \epsilon_t,
\end{align}
for characteristic polynomial
\begin{align}
    \phi(z)=1-\phi_1z-\cdots-\phi_pz^p.
\end{align}

\textbf{Definition.} An AR($p$) process is said to possess a \textbf{unit root} if the characteristic equation
\begin{align}
\phi(z) = 0
\end{align}
has at least one root $z_0$ such that $|z_0| = 1$.

\textbf{Proposition.} For a general AR($p$) process, stationarity requires that all roots of $\phi(z)$ lie strictly outside the unit circle. 

\textit{Proof.} A time series having a Wold representation as an MA($\infty$) process is necessary and sufficient for being weakly stationary. This moving average time series is obtainable via inverting the characteristic polynomial evaluated with the lag operator, as per the definition of invertible. Hence, there must exist a representation of $1/\phi(z)$ as a convergent power series. 

However, it is known from complex analysis that this series, centered at zero, converges if and only if there are no poles within the unit disk. Hence, there cannot be any roots that lie within the unit circle for the process to admit a moving average representation with summable coefficients. \hfill $\square$

\textbf{Example.} Consider the AR(1) process
\begin{align}
X_t = \phi X_{t-1} + \varepsilon_t.
\end{align}
The characteristic polynomial is
\begin{align}
\phi(z) = 1 - \phi z.
\end{align}
This polynomial has a root at $z = 1/\phi$. A unit root occurs when $\phi = 1$, yielding
\begin{align}
X_t = X_{t-1} + \varepsilon_t,
\end{align}
which is a random walk. Iterating forward gives
\begin{align}
X_t = X_0 + \sum_{j=1}^t \varepsilon_j.
\end{align}
Since the shocks accumulate permanently,
\begin{align}
\mathbb{E}[X_t] = X_0, \qquad \mathrm{Var}(X_t) = t \sigma^2,
\end{align}
and the variance grows without bound as $t \to \infty$. Hence, the process is not weakly stationary.

\textbf{Theorem.} Many financial time series exhibit persistent non-stationarity consistent with unit roots. The classic test for a unit root in an AR(1) context is the \textbf{Dickey–Fuller test}. Rewriting an AR(1) process as
\begin{align}
X_t = \phi X_{t-1} + \epsilon_t \rightarrow \Delta X_t = (\phi-1)X_{t-1} + \epsilon_t = \delta X_{t-1} + \epsilon_t,
\end{align}
an OLS estimator for $\Hat{\delta}$ can be calculated. However, under the null, the test statistic has a nonstandard distribution requiring special critical values. This test has null hypothesis $\phi=1$ (unit root, non-stationary) and alternative $|\phi|<1$ (stationary). 

\textbf{Remark.} Augmented Dickey-Fuller (ADF) and related tests (Phillips–Perron) control for higher–order dynamics, while KPSS tests take stationarity as the null.

\textbf{Definition.} A process $\{X_t\}$ follows an \textbf{ARMA$(p,q)$ model} if
\begin{align}
\phi(L)(X_t-\mu) = \theta(L)\epsilon_t,
\end{align}
where $\{\epsilon_t\}$ is white noise with variance $\sigma^2$, and
\begin{align}
\phi(L)=1-\phi_1L-\cdots-\phi_pL^p,\qquad
\theta(L)=1+\theta_1L+\cdots+\theta_qL^q. 
\end{align}
The associated Wold decomposition yields
\begin{align}
X_t = \mu + \psi(L)\eta_t,\quad \psi(L)=\phi(L)^{-1}\theta(L),
\end{align}
provided the process is stationary and invertible. 

\textbf{Definition.} A unit root at $z=1$ implies that the process can be factored as
\begin{align}
\phi(L) = (1 - L)\psi(L),
\end{align}
leading to the representation
\begin{align}
(1 - L)X_t = \psi(L)^{-1}\varepsilon_t.
\end{align}
Thus, the first difference $\Delta X_t = X_t - X_{t-1}$ is stationary, while $X_t$ itself is not. Such a process is said to be \textbf{integrated} of order one, denoted $I(1)$.
More generally, if $(1 - L)^d$ divides $\phi(L)$, the process is integrated of order $d$, written $I(d)$.

\textbf{Definition.} To model non-stationary series with stochastic trends, the ARMA framework is extended by differencing. If $\Delta^dX_t$ is stationary and follows an ARMA$(p,q)$ model, then $X_t$ is said to follow an \textbf{ARIMA$(p,d,q)$} model:
\begin{align}
\phi(L)\Delta^dX_t = \theta(L)\epsilon_t,
\end{align}
Pure random walks and integrated processes $I(1)$ are special cases of ARIMA with $d=1$. 

\subsection{Estimation and Model Selection}

ARMA and ARIMA models are typically estimated using MLE. Under the assumption of Gaussian innovations, the likelihood function is fully characterized by the conditional mean and variance implied by the model, and MLE is asymptotically efficient. For an ARMA$(p,q)$ process,
\begin{align}
\phi(L) X_t = \theta(L)\varepsilon_t, \qquad \varepsilon_t \sim \mathcal{N}(0,\sigma^2),
\end{align}
the likelihood depends on the parameter vector $(\phi_1,\dots,\phi_p,\theta_1,\dots,\theta_q,\sigma^2)$ and is maximized numerically, often using exact likelihood methods or a state-space representation with Kalman filtering.

In special cases, simpler estimation techniques are available. For pure autoregressive models, the \textbf{Yule-Walker equations} relate the autoregressive coefficients to the theoretical autocovariance function:
\begin{align}
\gamma(k) = \sum_{j=1}^p \phi_j \gamma(k-j), \qquad k \ge 1.
\end{align}
Replacing population autocovariances with their sample counterparts yields closed-form estimators. While computationally efficient, Yule-Walker estimators are generally less statistically efficient than MLE, particularly in small samples.

Model order selection requires balancing goodness of fit against model complexity. Information criteria provide a formal framework for this trade-off. Let $\hat{\sigma}^2$ denote the estimated innovation variance and $n$ the sample size. Commonly used criteria include:
\begin{align}
\mathrm{AIC}(p,q) &= \log(\hat{\sigma}^2) + \frac{2(p+q)}{n}, \\
\mathrm{BIC}(p,q) &= \log(\hat{\sigma}^2) + \frac{\log n \,(p+q)}{n}.
\end{align}
The \textbf{Akaike Information Criterion (AIC)} is motivated by minimizing the expected Kullback-Leibler divergence between the true data-generating process and the fitted model, and therefore tends to favor more flexible specifications. The \textbf{Bayesian Information Criterion (BIC)} imposes a stronger penalty on complexity and is consistent for model selection under standard regularity conditions. In practice, AIC is often preferred for forecasting applications, while BIC is favored when the goal is parsimonious structural modeling.

\section{Volatility Modeling}

\textbf{Motivation.} Empirical studies of financial return series reveal features that are not captured by linear time-series models such as ARMA or ARIMA. In particular, while raw returns often exhibit little serial correlation, functions of returns - most notably squared or absolute returns - display strong and persistent dependence. This motivates explicit modeling of the conditional variance process.

\subsection{Observations and Models}

\textbf{Remark.}
There are several well-documented empirical properties of asset return volatility:

\textit{Volatility clustering:}
Large price movements tend to be followed by large movements (of either sign), and small movements tend to be followed by small movements. Formally, while $\{X_t\}$ may be weakly autocorrelated, the processes $\{|X_t|\}$ or $\{X_t^2\}$ exhibit strong positive autocorrelation over time. This phenomenon is referred to as \textbf{volatility clustering}.

\textit{Heavy tails:}
Empirical return distributions exhibit excess kurtosis relative to the Gaussian distribution. That is,
\begin{align}
\mathbb{P}(|X_t| > x) \sim x^{-\alpha}, \quad \alpha < \infty,
\end{align}
for large $x$, indicating power-law or sub-exponential tail behavior. This has important implications for risk measurement and extreme-event modeling.

\textit{Leverage effect:}
Negative returns tend to be followed by higher future volatility than positive returns of the same magnitude. This asymmetric response of volatility to shocks is known as the \textbf{leverage effect} and reflects both financial leverage and behavioral mechanisms.

\textit{Long memory:}
Volatility proxies such as $|X_t|$ or $X_t^2$ often display slowly decaying autocorrelation functions,
\begin{align}
\text{Corr}(X_t^2, X_{t+k}^2) \sim k^{-\delta}, \quad 0 < \delta < 1,
\end{align}
suggesting long-range dependence rather than the exponential decay implied by short-memory models.

\textit{Hurst exponent:}
Long memory is often quantified using the \textbf{Hurst exponent} $H \in (0,1)$, defined via scaling behavior
\begin{align}
\mathbb{E}[|X_{t+h} - X_t|^2] \sim h^{2H}.
\end{align}
For volatility processes, empirical estimates frequently yield $H > \tfrac{1}{2}$, consistent with persistent dependence. In contrast, Brownian motion has $H = \tfrac{1}{2}$.

\textbf{Definition.} While ARMA/ARIMA models address autocorrelation in levels, financial time series often exhibit persistent time-varying conditional variance. An \textbf{ARCH($q$) (autoregressive conditional heteroskedasticity) model} specifies
\begin{align}
X_t = \sigma_t z_t, \qquad
\sigma_t^2 = \alpha_0 + \sum_{i=1}^q \alpha_i X_{t-i}^2,
\end{align}
where $\{z_t\}$ is an i.i.d.\ sequence with $\mathbb{E}[z_t]=0$ and $\mathbb{E}[z_t^2]=1$, and $\alpha_0>0$, $\alpha_i \ge 0$.

ARCH models capture volatility clustering by allowing large past shocks to increase future conditional variance. However, high-order ARCH models are often required in practice, motivating a more parsimonious extension.

\textbf{Definition.} A \textbf{GARCH($p,q$) (generalized ARCH) model} incorporates lagged conditional variances:
\begin{align}
\sigma_t^2 = \omega + \sum_{i=1}^q \alpha_i X_{t-i}^2 + \sum_{j=1}^p \beta_j \sigma_{t-j}^2,
\end{align}
with $\omega>0$, $\alpha_i,\beta_j \ge 0$.

\textbf{Proposition.} For a GARCH(1,1) model, a sufficient condition for covariance stationarity is
\begin{align}
\alpha_1 + \beta_1 < 1,
\end{align}
in which case the unconditional variance exists and equals
\begin{align}
\mathbb{E}[\sigma_t^2] = \frac{\omega}{1 - \alpha_1 - \beta_1}.
\end{align}
When $\alpha_1 + \beta_1$ is close to one, volatility shocks decay slowly, producing highly persistent volatility dynamics.

\textbf{Definition.} Standard ARCH and GARCH models are symmetric in the sense that positive and negative shocks of equal magnitude have identical effects on future volatility. This contradicts empirical evidence. An \textbf{EGARCH (exponential GARCH)} model specifies
\begin{align}
\log \sigma_t^2= \omega+ \sum_{j=1}^p \beta_j \log \sigma_{t-j}^2+ \sum_{i=1}^q \left[\alpha_i z_{t-i}+ \gamma_i (|z_{t-i}| - \mathbb{E}|z_{t-i}|)\right],
\end{align}
where asymmetry is introduced through the $\alpha_i$ terms. Negative shocks can increase volatility more than positive ones without imposing non-negativity constraints on parameters.

\textbf{Definition.} A \textbf{GJR-GARCH} model introduces asymmetry directly via an indicator:
\begin{align}
\sigma_t^2 = \omega + \alpha X_{t-1}^2
+ \gamma X_{t-1}^2 \mathbf{1}_{\{X_{t-1}<0\}}
+ \beta \sigma_{t-1}^2.
\end{align}
Here, negative returns have an amplified impact on future volatility when $\gamma>0$.

\textbf{Definition.} While GARCH-type models generate persistent volatility, they still imply exponential decay of autocorrelations. To capture true long memory, fractional models are introduced. A \textbf{FIGARCH (fractionally integrated GARCH)} model replaces the lag polynomial with a fractional difference operator:
\begin{align}
\sigma_t^2 = \omega + \left[1 - \beta(L)\right]^{-1}
\left[1 - \Delta^d\right] \alpha(L) X_t^2,
\end{align}
where $d \in (0,1)$ governs the degree of long memory.

FIGARCH models generate hyperbolically decaying autocorrelations in squared returns, consistent with empirical evidence, at the cost of increased complexity and weaker moment conditions.

\textbf{Example (GARCH-type Models).} Consider a daily return series $\{X_t\}$ for a hypothetical equity with sample unconditional variance $\hat{\sigma}^2 \approx 0.0004$ (i.e.\ standard deviation $\approx 2\%$). We illustrate different volatility models:

Suppose we fit an ARCH(1) model:
\begin{align}
X_t = \sigma_t z_t, \qquad \sigma_t^2 = 0.0001 + 0.3 X_{t-1}^2, \quad z_t \sim \mathcal{N}(0,1).
\end{align}
If yesterday’s return was $X_{t-1} = 0.04$ (4\%), the conditional variance today is
\begin{align}
\sigma_t^2 = 0.00058,
\end{align}
so $\sigma_t \approx 0.0241$ (2.41\%). This illustrates volatility clustering (a large past shock increases today's variance).

Consider a GARCH(1,1) model:
\begin{align}
\sigma_t^2 = 0.0001 + 0.3 X_{t-1}^2 + 0.6 \sigma_{t-1}^2.
\end{align}
Assume $\sigma_{t-1}^2 = 0.0004$ and $X_{t-1} = 0.02$:
\begin{align}
\sigma_t^2 = 0.00046.
\end{align}
The unconditional variance is
\begin{align}
\mathbb{E}[\sigma_t^2] = \frac{\omega}{1-\alpha_1-\beta_1} = \frac{0.0001}{1-0.3-0.6} = 0.001,
\end{align}
demonstrating persistent volatility when $\alpha_1 + \beta_1$ is close to 1.

Consider now a GJR-GARCH to capture asymmetry:
\begin{align}
\sigma_t^2 = 0.0001 + 0.3 X_{t-1}^2 + 0.2 X_{t-1}^2 \mathbf{1}_{\{X_{t-1}<0\}} + 0.5 \sigma_{t-1}^2.
\end{align}
If yesterday’s return was $X_{t-1} = -0.03$, then
\begin{align}
\sigma_t^2  = 0.00075,
\end{align}
so negative returns increase volatility more than positive returns, illustrating the leverage effect.

In a FIGARCH(1,d,1) model with $d=0.4$, the conditional variance is influenced by the fractional difference of past squared returns:
\begin{align}
\sigma_t^2 = \omega + \left[1 - \beta(L)\right]^{-1} \left[1 - \Delta^{0.4}\right] \alpha(L) X_t^2.
\end{align}
Unlike standard GARCH, shocks decay hyperbolically:
\begin{align}
\text{Corr}(X_t^2, X_{t+k}^2) \sim k^{-0.4}, \quad k \to \infty,
\end{align}
so volatility remains correlated over long horizons, consistent with empirical long memory. 


\subsection{Forecasting versus Pricing}

ARCH-family models are primarily designed for \emph{forecasting} conditional variance under the physical probability measure $\mathbb{P}$. They are widely used for risk management (VaR, ES) and volatility forecasting.

However, these models do not define a full arbitrage-free price process for the underlying asset and do not specify dynamics under a risk-neutral measure. Consequently, they are not directly suitable for derivative pricing without additional assumptions or measure changes.

In contrast, volatility models used for \emph{pricing}, such as stochastic volatility or local volatility models, are embedded within continuous-time, no-arbitrage frameworks and explicitly specify dynamics under equivalent martingale measures. Bridging the gap between statistically calibrated volatility models and arbitrage-free pricing remains a central challenge in quantitative finance.

\section{Spectral Analysis and Cointegration}

\textbf{Motivation.} How can cyclical behavior be captured? Rather than analyzing dependence through autocovariances in the time domain, spectral analysis decomposes variability across frequencies, revealing behavior that may not be evident from finite-lag correlations. Likewise, many economic and financial time series are nonstationary but move together over long horizons. Cointegration formalizes this notion.

\textbf{Definition.} Let $\{X_t\}_{t \in \mathbb{Z}}$ be a weakly stationary process with autocovariance function
\begin{align}
\Gamma(k) = \text{Cov}(X_t, X_{t-k}).
\end{align}
The \textbf{spectral density} of $X_t$ is defined as
\begin{align}
f(\lambda)
= \frac{1}{2\pi} \sum_{k=-\infty}^{\infty} \Gamma(k) e^{-i \lambda k},
\qquad \lambda \in [-\pi, \pi].
\end{align}
When $\sum_k |\Gamma(k)| < \infty$, the series converges absolutely and $f(\lambda)$ is continuous.

The spectral density provides a decomposition of the variance of $X_t$ across frequencies, with low frequencies corresponding to long-run components and high frequencies corresponding to short-run fluctuations.

\textbf{Proposition.} The autocovariance function can be recovered from the spectral density via the inverse Fourier transform:
\begin{align}
\Gamma(k) = \int_{-\pi}^{\pi} e^{i \lambda k} f(\lambda)\, d\lambda,
\end{align}
establishing a one-to-one correspondence between time- and frequency-domain representations.

\textbf{Proposition.} For linear time-series models, the spectral density admits a closed-form expression. Let $\{X_t\}$ follow an ARMA$(p,q)$ process
\begin{align}
\phi(L) X_t = \theta(L) \varepsilon_t, \qquad \varepsilon_t \sim \text{i.i.d. } (0,\sigma^2),
\end{align}
where $\phi(z)$ and $\theta(z)$ are polynomials in the lag operator. Then the spectral density is given by
\begin{align}
f(\lambda)
= \frac{\sigma^2}{2\pi}
\frac{|\theta(e^{-i\lambda})|^2}{|\phi(e^{-i\lambda})|^2}.
\end{align}
Zeros of $\phi(e^{-i\lambda})$ close to the unit circle generate sharp peaks in the spectral density at low frequencies, corresponding to highly persistent dynamics. Poles at $\lambda = 0$ correspond to unit-root or near-unit-root behavior. Flat spectra correspond to white noise, and slowly decaying autocorrelations manifest as high spectral mass near zero frequency.

\textbf{Definition.} Let $X_t \in \mathbb{R}^k$ be a vector of integrated processes of order one, $I(1)$. The components of $X_t$ are said to be \textbf{cointegrated} if there exists a nonzero vector $\beta \in \mathbb{R}^k$ such that
\begin{align}
\beta^\top X_t \sim I(0).
\end{align}
The vector $\beta$ defines a long-run equilibrium relationship among the components of $X_t$.

\textbf{Remark.} Cointegration eliminates low-frequency divergence: while individual components of $X_t$ exhibit infinite variance at frequency zero, the cointegrating combination $\beta^\top X_t$ has finite spectral mass near $\lambda = 0$. In this sense, cointegration is fundamentally a \emph{low-frequency restriction}.

\textbf{Theorem (Granger representation).} If $X_t$ is a cointegrated $I(1)$ vector process, then it admits a \textbf{vector error-correction model (VECM)} representation:
\begin{align}
\Delta X_t
= \Pi X_{t-1}
+ \sum_{j=1}^{p-1} \Gamma_j \Delta X_{t-j}
+ \varepsilon_t,
\end{align}
where $\Pi = \alpha \beta^\top$ has reduced rank. Here, $\beta$ contains the cointegrating vectors, $\alpha$ governs the speed at which deviations from long-run equilibrium are corrected, and short-run dynamics are captured by lagged differences.

\textbf{Remark.} Two standard approaches are widely used in practice:
\begin{itemize}
\item The \textbf{Engle--Granger two-step procedure}, which estimates the long-run relationship via regression and tests the residuals for stationarity;
\item \textbf{Johansen tests}, which use a likelihood-based framework to infer the number of cointegrating relationships in a multivariate system.
\end{itemize}

\textbf{Remark.} Cointegration plays a central role in financial modeling such as \textbf{pairs trading and statistical arbitrage}, where mean-reverting spreads are constructed from nonstationary price series. However, care must be taken when embedding such models into no-arbitrage pricing frameworks.

\chapter{Numerical Methods}

\textbf{Motivation.} Many models of interest in quantitative finance do not admit closed-form solutions for derivative prices or risk measures. As a result, numerical methods play a central role in both pricing and calibration. Many also reduce to minimizing or maximizing an objective function, or equivalently solving a system of nonlinear equations. Optimization thus arises in model calibration, portfolio construction, risk management, and optimal control.

\section{Common Methods in Finance}

\subsection{Monte Carlo}

\textbf{Definition.}
\textbf{Monte Carlo methods} estimate expectations by simulating a large number of independent sample paths of the underlying stochastic process. By the Law of Large Numbers, these estimates converge almost surely to the true expectation.

Under the risk-neutral measure $\mathbb{Q}$, the time-$0$ value of a derivative with payoff $\Phi(X_T)$ is
\begin{align}
V_0 = e^{-rT}\mathbb{E}^{\mathbb{Q}}[\Phi(X_T)].
\end{align}

Approximating the expectation with $M$ simulated paths yields the Monte Carlo estimator
\begin{align}
V_0^{(M)} = e^{-rT}\frac{1}{M}\sum_{m=1}^M \Phi(X_T^{(m)}).
\end{align}

\textbf{Theorem (Monte Carlo convergence).}
If $\mathbb{E}^{\mathbb{Q}}[\Phi(X_T)^2] < \infty$, then
\begin{align}
V_0^{(M)} \xrightarrow{a.s.} V_0,
\qquad
\sqrt{M}\big(V_0^{(M)} - V_0\big)
\xrightarrow{d} \mathcal{N}(0,\sigma^2),
\end{align}
where $\sigma^2 = \mathrm{Var}^{\mathbb{Q}}(\Phi(X_T))$.

Consequently, the root mean square error decays at rate $\mathcal{O}(M^{-1/2})$, independent of the dimension of the problem.

\textbf{Definition.}
Consider a stochastic differential equation
\begin{align}
dX_t = \mu(t,X_t)\,dt + \sigma(t,X_t)\,dW_t,
\end{align}
where $W_t$ is a standard Brownian motion.

In general, exact simulation of $X_t$ is not available, and numerical discretization schemes must be used. Let $\Delta t = T/N$ and $t_n = n\Delta t$. The \textbf{Euler-Maruyama approximation} is
\begin{align}
X_{n+1}
= X_n
+ \mu(t_n,X_n)\Delta t
+ \sigma(t_n,X_n)\Delta W_n,
\end{align}
where $\Delta W_n \sim \mathcal{N}(0,\Delta t)$ are independent.

\textbf{Definition.}
Let $X_T$ be the true solution and $X_T^{(N)}$ its numerical approximation. The approxination scheme has \textbf{strong order} $\alpha$ if
\begin{align}
\mathbb{E}\big[|X_T - X_T^{(N)}|\big] = \mathcal{O}(\Delta t^\alpha).
\end{align}
The approximation scheme has \textbf{weak order} $\beta$ if for all smooth test functions $\varphi$,
\begin{align}
|\mathbb{E}[\varphi(X_T)] - \mathbb{E}[\varphi(X_T^{(N)})]|
= \mathcal{O}(\Delta t^\beta).
\end{align}
The Euler--Maruyama scheme has strong order $1/2$ and weak order $1$ under standard Lipschitz assumptions.

\textbf{Remark.}
In option pricing, weak convergence is typically sufficient, since only expectations of payoffs are required.

\textbf{Definition.}
\textbf{Variance reduction techniques} aim to decrease $\mathrm{Var}(V_0^{(M)})$ without increasing the number of simulations, thereby improving estimator efficiency.
\begin{itemize}

\item \textbf{Antithetic variates.}
If $X_T(W)$ is simulated using Brownian motion $W$, then simulating both $W$ and $-W$ and averaging the payoffs can reduce variance when the payoff is monotone in $W$.

\item \textbf{Control variates.}
Let $Y$ be a random variable with known expectation $\mathbb{E}[Y]$. For a scalar $\theta$,
\begin{align}
\Phi^\ast = \Phi - \theta(Y - \mathbb{E}[Y]).
\end{align}
The optimal $\theta$ minimizing variance is
\begin{align}
\theta^\ast = \frac{\mathrm{Cov}(\Phi,Y)}{\mathrm{Var}(Y)}.
\end{align}
Control variates are among the most effective techniques in financial Monte Carlo, particularly when pricing options with known Black--Scholes prices.

\item \textbf{Importance sampling.}
Importance sampling changes the probability measure to emphasize rare but important events, such as deep out-of-the-money option payoffs. If $\mathbb{Q}$ is replaced by $\widetilde{\mathbb{Q}}$, then
\begin{align}
\mathbb{E}^{\mathbb{Q}}[\Phi]
= \mathbb{E}^{\widetilde{\mathbb{Q}}}\!\left[
\Phi \frac{d\mathbb{Q}}{d\widetilde{\mathbb{Q}}}
\right].
\end{align}

\end{itemize}

\textbf{Definition.}
\textbf{Quasi-Monte Carlo (QMC)} methods replace pseudo-random numbers with low-discrepancy sequences such as Sobol or Halton sequences.

\textbf{Theorem (Koksma--Hlawka inequality).}
For a function $f$ of bounded variation,
\begin{align}
\left|
\frac{1}{M}\sum_{m=1}^M f(u_m)
- \int_{[0,1]^d} f(u)\,du
\right|
\le V(f) D_M,
\end{align}
where $V(f)$ is the Hardy-Krause variation, and $D_M$ is the discrepancy of the point set.

In practice, QMC often achieves convergence rates close to $\mathcal{O}(M^{-1})$ for moderate effective dimension, though without the probabilistic error guarantees of standard Monte Carlo.

\textbf{Definition (Least squares Monte Carlo).}
Monte Carlo methods naturally handle path-dependent payoffs such as Asian, barrier, and lookback options. However, pricing American options introduces optimal stopping problems. The \textbf{Longstaff-Schwartz algorithm} approximates the continuation value by regressing future discounted payoffs onto basis functions of the state variables, yielding an approximate optimal stopping rule.

\textbf{Remark.}
Monte Carlo pricing of American options is inherently biased due to approximation of the stopping boundary, but the bias can be controlled with sufficiently rich basis functions and large sample sizes.


\subsection{Finite Difference Methods}

\textbf{Motivation:} For Markovian models, derivative prices admit a representation as solutions to partial differential equations via the Feynman-Kac theorem. Let $X_t$ be a Markov process with infinitesimal generator $\mathcal{L}$. Then the value function
\begin{align}
V(t,x) = \mathbb{E}^{\mathbb{Q}}_{t,x}\!\left[ e^{-r(T-t)}\Phi(X_T) \right]
\end{align}
satisfies the backward pricing PDE
\begin{align}
\frac{\partial V}{\partial t}(t,x)
+ \mathcal{L} V(t,x)
- r V(t,x)
= 0,
\qquad
V(T,x) = \Phi(x).
\end{align}
It is not immediately obvious how to analytically solve this.

\textbf{Definition:} To solve numerically, \textbf{finite difference methods} approximate the PDE by discretizing time and state space. Let $t_n = n\Delta t$ and $x_i = x_{\min} + i\Delta x$. The continuous derivatives are replaced by finite difference quotients, yielding a system of algebraic equations for the grid values $V_i^n \approx V(t_n,x_i)$.

Common discretization schemes include:
\begin{itemize}
\item \textbf{Explicit} (forward-time, centered-space): simple to implement but conditionally stable,
\item \textbf{Implicit} (backward-time, centered-space): unconditionally stable but requires solving linear systems,
\item \textbf{Crank--Nicolson}: second-order accurate in time, combining explicit and implicit methods.
\end{itemize}

\textbf{Definition.}
A finite difference scheme is \textbf{consistent} if the local truncation error vanishes as $\Delta t,\Delta x \to 0$, and is \textbf{stable} if numerical errors do not grow uncontrollably during iteration.

\textbf{Theorem (Lax equivalence).}
For linear initial-value problems, consistency and stability together imply convergence of the numerical solution to the true solution.

\textbf{Remark.}
Explicit schemes are subject to CFL-type stability conditions linking $\Delta t$ and $\Delta x$, whereas implicit and Crank--Nicolson schemes are unconditionally stable and therefore preferred in practice.

\textbf{Example (American put).} Let $S_t$ follow geometric Brownian motion under the risk-neutral measure:
\begin{align}
    dS_t = r S_t\,dt + \sigma S_t\,dW_t,
\end{align}
with constant interest rate $r$ and volatility $\sigma$. Consider an American put option with strike $K$ and maturity $T$, whose payoff is
\begin{align}
    \Phi(S) = \max(K - S,0)^.
\end{align}

The option value $V(t,S)$ satisfies the variational inequality
\begin{align}
\max\Big(
\frac{\partial V}{\partial t}
+ \tfrac12\sigma^2 S^2 \frac{\partial^2 V}{\partial S^2}
+ r S \frac{\partial V}{\partial S}
- r V,\;
(K-S) - V
\Big) = 0,
\end{align}
with terminal condition
\begin{align}
V(T,S) = \max(K-S,0).
\end{align}
At each time and asset level, the option value is the maximum of the continuation value and the intrinsic value.

To discretize, let the spatial grid be $S_i = i\Delta S$, $i=0,\dots,I$, and the time grid $t_n = n\Delta t$, $n=0,\dots,N$, with $t_N = T$. Denote the numerical approximation by $V_i^n \approx V(t_n,S_i)$. Using a backward-time, centered-space discretization, the Black-Scholes operator is approximated by
\begin{align}
\mathcal{L}V_i^{n+1}
&=
\tfrac12\sigma^2 S_i^2
\frac{V_{i+1}^{n+1}-2V_i^{n+1}+V_{i-1}^{n+1}}{(\Delta S)^2}
+ r S_i
\frac{V_{i+1}^{n+1}-V_{i-1}^{n+1}}{2\Delta S}
- r V_i^{n+1}.
\end{align}
The fully implicit time discretization yields
\begin{align}
\frac{V_i^{n+1}-V_i^n}{\Delta t}
+ \mathcal{L}V_i^{n+1} = 0.
\end{align}

At each time step, the American constraint is enforced by
\begin{align}
V_i^n = \max\big( V_i^n,\; K - S_i \big).
\end{align}

Equivalently, the problem can be written as a discrete variational inequality:
\begin{align}
V_i^n \ge K-S_i,
\qquad
\frac{V_i^{n+1}-V_i^n}{\Delta t}
+ \mathcal{L}V_i^{n+1} \le 0,
\end{align}
with complementarity at each grid point.

Boundary conditions are chosen as:
\begin{align}
V(t,0) &= K, \\
V(t,S_{\max}) &= 0,
\end{align}
reflecting certain exercise at zero asset price and negligible value at large prices.

The numerical procedure proceeds as follows:
\begin{enumerate}
\item Initialize $V_i^N = \max(K-S_i,0)$ at maturity.
\item Step backward in time by solving the linear system for $V^{n+1}$.
\item Enforce the early exercise condition pointwise:
\begin{align}
V_i^n \leftarrow \max(V_i^n, K-S_i).
\end{align}
\item Repeat until $t=0$.
\end{enumerate}

The early exercise boundary $S^\ast(t)$ is implicitly defined by
\begin{align}
V(t,S^\ast(t)) = K - S^\ast(t).
\end{align}
Finite difference methods naturally approximate this boundary as the interface between grid points where the intrinsic value dominates and where continuation is optimal.

\textbf{Remark.}
Finite difference methods have high accuracy for low-dimensional problems and handling of early exercise features, yet computational cost grows exponentially with dimension. As a result, finite difference methods are primarily used for one- and two-dimensional problems, while Monte Carlo methods dominate in higher-dimensional settings.

\section{Optimization and Root Finding}

\subsection{Optimization Techniques}

\textbf{Definition.} An \textbf{optimization problem} consists of
\begin{align}
    \min_{x \in \mathcal{D}} \; f(x),
\end{align}
where $f:\mathbb{R}^n \to \mathbb{R}$ is the objective function and $\mathcal{D}\subseteq\mathbb{R}^n$ is the feasible set.

A point $x^\star$ is a \emph{local minimum} if $f(x^\star) \le f(x)$ for all $x$ in a neighborhood of $x^\star$, and a \emph{global minimum} if the inequality holds for all $x\in\mathcal{D}$.

\textbf{Definition:} A set $C$ is called \textbf{convex} if the line segment between any two points in the set also is in $C$:
\begin{align}
    x,y \in C \Rightarrow (1-t)x + ty \in C, \forall t \in [0,1].
\end{align}
A \textbf{convex function} $f:X \rightarrow \mathbb{R}^n$ defined on a convex subset, likewise, has the line segment connecting any two points on the graph greater than or equal to the function value (the epigraph is convex):
\begin{align}
    x_1,x_2 \in X \Rightarrow f(tx_1 + (1-t)x_2) \leq tf(x_1) + (1-t)f(x_2), \forall t \in [0,1].
\end{align}
\textbf{Convex optimization} minimizes convex functions over convex subsets.

\textbf{Theorem.} A function $f$ is convex if and only if its domain is convex and it satisfies the \textbf{first-order convexity condition}
\begin{align}
    f(y) \leq f(x) + \nabla f(x)^T (y-x), \forall x, y \in \text{dom} (f).
\end{align}
Alternatively, a function $f$ is convex if and only if its domain is convex and it satisfies the \textbf{second-order convexity condition}
\begin{align}
    \nabla^2 f(x) \geq 0, \forall x \in \text{dom} (f).
\end{align}

\textbf{Definition.} Given a differentiable objective $f$, \textbf{gradient descent} is a first-order method that iterates
\begin{align}
    x_{k+1} = x_k - \alpha_k \nabla f(x_k),
\end{align}
where $\alpha_k>0$ is a step size. Gradient descent is robust and easy to implement, but can converge slowly, especially for ill-conditioned problems.

\textbf{Definition.} If $f$ is twice differentiable, \textbf{Newton's method} is a second-order method that updates
\begin{align}
    x_{k+1} = x_k - \nabla^2 f(x_k)^{-1}\nabla f(x_k),
\end{align}
where $\nabla^2 f$ is the Hessian. Newton's method converges quadratically near the optimum but requires inversion of the Hessian, which may be unstable or computationally expensive.

\textbf{Definition.}
The \textbf{BFGS algorithm} is a quasi-Newton method that updates an approximation $H_k \approx \nabla^2 f(x_k)^{-1}$ via rank-two updates that preserve symmetry and positive definiteness. BFGS provides a good balance between robustness and speed, and is widely used in model calibration.

\textbf{Definition.} A \textbf{constrained optimization problem} takes the form
\begin{align}
    \min_x \; f(x)
    \quad \text{subject to} \quad
    h_i(x)=0, \quad g_j(x) \geq 0
\end{align}
for arbitrary numbers of constraints.

\textbf{Theorem (Karush-Kuhn-Tucker).} 
For constrained optimization of a continuously differentiable, convex $f$, with $g_j$ convex and $h_i$ affine, then for a local minimum $x^*$, there exist $\lambda_i, \mu_j$ satisfying the following conditions. Any point $x^*$ satisfying the following conditions is also a global minimum.

Define the \textbf{Lagrangian} as
\begin{align}
    \mathcal{L}(x,\lambda,\mu)=f(x) + \sum_i^p \lambda_i h_i(x) + \sum_j^q \mu_j g_j(x).
\end{align}

\begin{itemize}
\item $\nabla_x\mathcal{L}(x^*,\lambda,\mu) = 0$ (stationary Lagrangian).
\item The point $x^*$ satisfies the constraints (primal feasibility).
\item $\mu_j \geq 0$ (dual feasibility).
\item $\mu_jg_j(x^*)=0$ (complementary slackness).
\end{itemize}

\textbf{Definition.}
An optimization problem is \textbf{ill-conditioned} if small perturbations in data or parameters lead to large changes in the solution. 

Parameters are \textbf{identifiable} if distinct parameter values produce distinct model outputs. Non-identifiability is common in over-parameterized models and leads to flat directions in the objective function.

\textbf{Definition.} \textbf{Regularization} augments the objective function to stabilize optimization:
\begin{align}
    f_{\text{reg}}(x)
    =
    f(x) + \lambda R(x),
\end{align}
where $R(x)$ is a penalty term. \textbf{$\ell_2$ regularization} is defined as
\begin{align}
    R(x) = \|x\|_2^2
\end{align}
and improves conditioning, and \textbf{$\ell_1$ regularization} is defined as
\begin{align}
    R(x) = \|x\|_1
\end{align}
and promotes sparsity.

\textbf{Remark.}
Calibration objectives are often non-convex due to nonlinear model dynamics, latent variables, discrete market instruments, correlation parameters. As a result, optimization may exhibit multiple local minima, making initialization and regularization critical.

\subsection{Root Finding and Programming}

\textbf{Definition.} A \textbf{root-finding problem} asks to find $x$ such that
\begin{align}
    F(x)=0,
\end{align}
for a vector-valued function $F$.

\textbf{Remark.}
Calibration of implied volatility or CDS hazard rates is often posed as root-finding rather than optimization.

\textbf{Definition.}
A \textbf{quadratic program} minimizes
\begin{align}
    \frac12 x^\top Q x + c^\top x
\end{align}
subject to linear constraints.

\textbf{Proposition.}
Let $\mu$ be expected returns and $\Sigma$ the covariance matrix. The mean-variance problem is:
\begin{align}
    \min_w \; \frac{1}{2} w^\top \Sigma w - \lambda w^\top \mu
    \quad \text{subject to} \quad \mathbf{1}^\top w = 1.
\end{align}
The mean-variance problem is a convex quadratic program.

\textbf{Definition.} A \textbf{shrinkage estimator} of the covariance matrix is:
\begin{align}
    \hat\Sigma = \alpha \Sigma_{\text{sample}} + (1-\alpha)\Sigma_0,
\end{align}
where $\Sigma_0$ is a structured target. Shrinkage improves stability in high-dimensional settings.

\chapter{Machine Learning Methods}

\textbf{Motivation.} How are strategies work-shopped and tested? This section explores how statistical learning is applied to finance, and how models are validated.

\section{Common Methods in Finance}

\textbf{Definition.}
Regression analysis seeks to model the relationship between a dependent variable and one or more explanatory variables. In its simplest linear form, the \textbf{regression model} is written as
\begin{align}
Y = X\beta + \varepsilon,
\end{align}
where $Y \in \mathbb{R}^n$ is the vector of observed responses, $X \in \mathbb{R}^{n \times p}$ is the design matrix, $\beta \in \mathbb{R}^p$ is the vector of unknown coefficients, and $\varepsilon \in \mathbb{R}^n$ is a vector of random errors.

A common assumption is
\begin{align}
\mathbb{E}[\varepsilon] = 0,
\qquad
\mathrm{Var}(\varepsilon) = \sigma^2 I_n.
\end{align}

\textbf{Definition.}
The \textbf{ordinary least squares (OLS)} estimator is defined by
\begin{align}
\hat{\beta}_{\text{OLS}}
= \arg\min_{\beta} \|Y - X\beta\|_2^2
= (X^\top X)^{-1}X^\top Y,
\end{align}
provided $X^\top X$ is invertible.

\textbf{Theorem (Gauss--Markov).}
If the regression model is linear in parameters, $\mathbb{E}[\varepsilon]=0$, $\mathrm{Var}(\varepsilon)=\sigma^2 I_n$, and $X$ has full column rank, then $\hat{\beta}_{\text{OLS}}$ is the \emph{best linear unbiased estimator} (BLUE) of $\beta$.

\textbf{Definition.}
Given a parametric model $f(x;\theta)$ and observations $\{x_i\}_{i=1}^n$, the \textbf{maximum likelihood estimator (MLE)} is
\begin{align}
\hat{\theta}
=
\arg\max_\theta \mathcal{L}(\theta)
=
\arg\max_\theta \prod_{i=1}^n f(x_i;\theta).
\end{align}

\textbf{Remark.}
Under Gaussian errors, the OLS estimator coincides with the MLE.


\textbf{Definition.}
In high-dimensional or noisy financial datasets, ordinary least squares often suffers from overfitting or multicollinearity. \textbf{Ridge regression} solves
\begin{align}
\hat{\beta}_{\text{ridge}}
=
\arg\min_\beta \left( \|Y - X\beta\|_2^2 + \lambda \|\beta\|_2^2 \right),
\end{align}
where $\lambda > 0$ controls the strength of regularization. The \textbf{lasso estimator} replaces the $\ell^2$ penalty with an $\ell^1$ penalty:
\begin{align}
\hat{\beta}_{\text{lasso}}
=
\arg\min_\beta \left( \|Y - X\beta\|_2^2 + \lambda \|\beta\|_1 \right).
\end{align}

\textbf{Remark.}
Lasso performs variable selection by setting some coefficients exactly to zero, making it particularly useful for factor selection in asset pricing models.


\textbf{Definition.}
\textbf{Hidden Markov Models (HMMs)} are probabilistic models for time series driven by an unobserved discrete state process. They are commonly used to model regime switching in returns or volatility.

An HMM consists of:
\begin{itemize}
\item a latent Markov chain $\{Z_t\}$ taking values in $\{1,\dots,K\}$,
\item an observation/emission process $\{Y_t\}$ such that
\begin{align}
Y_t \mid Z_t = k \sim f_k(\cdot),
\end{align}
\item a transition matrix $P$ satisfying
\begin{align}
\mathbb{P}(Z_t = j \mid Z_{t-1} = i) = P_{ij}.
\end{align}
\end{itemize}
Gaussian emission distributions are commonly used for log-returns or log-volatility.

\textbf{Theorem (Baum-Welch algorithm).} Given an HMM with $K$ hidden states, observations $\{Y_1,\dots,Y_T\}$, and unknown parameters
\begin{align}
\theta = (\pi, P, \{f_k\}_{k=1}^K),
\end{align}
where $\pi_i = \mathbb{P}(Z_1=i)$ are initial state probabilities, $P$ is the $K\times K$ transition matrix, and $f_k$ are emission densities, we wish to estimate $\theta$ from data.

Define the \emph{forward probability}:
\begin{align}
\alpha_t(i) = \mathbb{P}(Y_1,\dots,Y_t, Z_t=i \mid \theta),
\end{align}
computed recursively:
\begin{align}
\alpha_1(i) = \pi_i f_i(Y_1), \qquad
\alpha_{t+1}(j) = f_j(Y_{t+1}) \sum_{i=1}^K \alpha_t(i) P_{ij}.
\end{align}
Also define the \emph{backward probability}:
\begin{align}
\beta_t(i) = \mathbb{P}(Y_{t+1},\dots,Y_T \mid Z_t=i, \theta),
\end{align}
computed recursively:
\begin{align}
\beta_T(i) = 1, \qquad
\beta_t(i) = \sum_{j=1}^K P_{ij} f_j(Y_{t+1}) \beta_{t+1}(j).
\end{align}

\textit{E-step}: for expectations, compute the posterior probabilities of hidden states and transitions:
\begin{align}
\gamma_t(i) = \mathbb{P}(Z_t=i \mid Y_{1:T}, \theta) = \frac{\alpha_t(i) \beta_t(i)}{\sum_{j=1}^K \alpha_t(j) \beta_t(j)},
\end{align}
\begin{align}
\xi_t(i,j) = \mathbb{P}(Z_t=i, Z_{t+1}=j \mid Y_{1:T}, \theta) = \frac{\alpha_t(i) P_{ij} f_j(Y_{t+1}) \beta_{t+1}(j)}{\sum_{i,j} \alpha_t(i) P_{ij} f_j(Y_{t+1}) \beta_{t+1}(j)}.
\end{align}
 
\textit{M-step}: now, update parameters to maximize expected complete-data log-likelihood:
\begin{align}
\pi_i^{\text{new}} &= \gamma_1(i), \\
P_{ij}^{\text{new}} &= \frac{\sum_{t=1}^{T-1} \xi_t(i,j)}{\sum_{t=1}^{T-1} \gamma_t(i)}, \\
f_j^{\text{new}} &= \text{MLE of emission parameters weighted by } \gamma_t(j).
\end{align}
For Gaussian emissions $f_j = \mathcal{N}(\mu_j, \sigma_j^2)$:
\begin{align}
\mu_j^{\text{new}} = \frac{\sum_{t=1}^T \gamma_t(j) Y_t}{\sum_{t=1}^T \gamma_t(j)}, \quad
(\sigma_j^2)^{\text{new}} = \frac{\sum_{t=1}^T \gamma_t(j) (Y_t - \mu_j^{\text{new}})^2}{\sum_{t=1}^T \gamma_t(j)}.
\end{align}

\textit{Repeat} E-step and M-step until convergence of the log-likelihood
\begin{align}
\log \mathcal{L}(\theta) = \log \mathbb{P}(Y_{1:T} \mid \theta).
\end{align}

\textbf{Remark.} The Baum--Welch algorithm is an instance of the Expectation--Maximization (EM) algorithm tailored for HMMs. It guarantees monotone increase of the likelihood, but only convergence to a local maximum. Once trained, the most likely hidden state sequence can be inferred via the Viterbi algorithm.



\textbf{Theorem.} A \textbf{linear Gaussian state-space model} is defined by:
\begin{align}
\text{State (latent) dynamics:} \quad & X_t = A X_{t-1} + B u_t + w_t, \quad w_t \sim \mathcal{N}(0,Q), \\
\text{Observation:} \quad & Y_t = C X_t + v_t, \quad v_t \sim \mathcal{N}(0,R),
\end{align}
where:
\begin{itemize}
\item $X_t$ is the hidden state vector at time $t$,
\item $Y_t$ is the observed data vector,
\item $u_t$ is a known input (control) vector,
\item $w_t$ and $v_t$ are mutually independent Gaussian noise processes,
\item $A$, $B$, $C$ are known matrices of appropriate dimensions.
\end{itemize}

The goal of the \textbf{Kalman filter} is to estimate the hidden state $X_t$ given observations $Y_1,\dots,Y_t$ recursively. Let:
\begin{align}
\hat{X}_{t|t-1} &= \mathbb{E}[X_t \mid Y_1,\dots,Y_{t-1}] \quad \text{(prediction)}, \\
\hat{X}_{t|t} &= \mathbb{E}[X_t \mid Y_1,\dots,Y_t] \quad \text{(updated estimate)}.
\end{align}
\textit{Predict} the state and covariance at time $t$ given the estimate at $t-1$:
\begin{align}
\hat{X}_{t|t-1} &= A \hat{X}_{t-1|t-1} + B u_t, \\
P_{t|t-1} &= A P_{t-1|t-1} A^\top + Q,
\end{align}
where $P_{t|t-1} = \text{Var}[X_t - \hat{X}_{t|t-1}]$ is the predicted state covariance.

\textit{Update} by incorporating the new observation $Y_t$:
\begin{align}
K_t &= P_{t|t-1} C^\top \left(C P_{t|t-1} C^\top + R\right)^{-1} \quad \text{(Kalman gain)}, \\
\hat{X}_{t|t} &= \hat{X}_{t|t-1} + K_t \left(Y_t - C \hat{X}_{t|t-1}\right), \\
P_{t|t} &= (I - K_t C) P_{t|t-1}.
\end{align}
$K_t$ determines how much weight to give the new observation versus the prediction, and the term $Y_t - C \hat{X}_{t|t-1}$ is the \textbf{innovation} (prediction error).

\textit{Repeat} prediction and update for each $t=1,\dots,T$.  

\textbf{Remark.} The filter provides the best linear unbiased estimate of the state at each time. The innovation sequence is Gaussian and can be used for likelihood-based parameter estimation. The Kalman filter is particularly powerful in finance because many models (stochastic volatility, term structure models) are naturally linear in latent states or can be linearized, allowing real-time estimation of unobserved quantities.

\textbf{Definition.}
A \textbf{Random Forest} is an ensemble learning method that aggregates a collection of decision trees trained on bootstrapped samples of the data. 

Each tree is constructed by sampling observations with replacement, selecting a random subset of features at each split, growing the tree to reduce impurity (e.g.\ variance or Gini index). The final prediction is given by averaging (regression) or majority voting (classification).

\textbf{Remark.}
Random Forests are nonparametric and capture nonlinear interactions between variables without requiring explicit model specification. These can help with return and volatility forecasting, credit risk and default prediction, and feature importance analysis.

\textbf{Definition.}   Let $X \in \mathbb{R}^{n \times p}$ be a data matrix with $n$ observations and $p$ variables, assumed to be centered (zero mean for each column). \textbf{Principal component analysis (PCA)} finds orthogonal directions $v_1,\dots,v_p$ that maximize the variance of projected data:
\begin{align}
v_1 &= \arg\max_{\|v\|=1} \mathrm{Var}(Xv),\\
v_k &= \arg\max_{\|v\|=1, v \perp v_1,\dots,v_{k-1}} \mathrm{Var}(Xv), 
\end{align}
for $k=2,\dots,p$. The projections $Z = X V$ are called the \textbf{principal components}, where $V = [v_1,\dots,v_p]$ is the matrix of eigenvectors.
 
\textit{Compute} the sample covariance of $X$:
\begin{align}
\Sigma = \frac{1}{n-1} X^\top X \in \mathbb{R}^{p \times p}.
\end{align}

\textit{Solve} for eigenvalues $\lambda_1 \ge \lambda_2 \ge \dots \ge \lambda_p$ and corresponding eigenvectors $v_1,\dots,v_p$:
\begin{align}
\Sigma v_k = \lambda_k v_k.
\end{align}
The first principal component $v_1$ points in the direction of maximal variance. Each subsequent component explains the maximal remaining variance while being orthogonal to previous components.

\textit{Retain} only the first $r < p$ components to approximate the data:
\begin{align}
X \approx Z_r V_r^\top, \quad Z_r = X V_r, \quad V_r = [v_1,\dots,v_r].
\end{align}
The proportion of variance explained by the $k$-th component is
\begin{align}
\text{PVE}_k = \frac{\lambda_k}{\sum_{j=1}^p \lambda_j}.
\end{align}
Cumulative explained variance helps choose $r$ such that most variability is preserved.

\textbf{Remark.} PCA assumes linear relationships and maximizes variance, and does not necessarily capture nonlinear structure. Standardization (scaling each variable to unit variance) is often used when variables are on different scales. In finance, PCA is particularly useful for interpretable factor decomposition and stress testing.

\section{Validation and Backtesting}

\textbf{Motivation.} Unlike classical supervised learning settings, financial data are time-ordered, non-stationary, and subject to structural breaks. As a result, standard validation techniques must be adapted to control for temporal dependence, regime changes, and multiple sources of bias.

\textbf{Definition.} The most basic distinction in model evaluation is between \textbf{in-sample} (IS) and \textbf{out-of-sample} (OOS) performance.

In-sample testing measures performance on the same dataset used to estimate model parameters. While useful for debugging and diagnostics, strong in-sample fit alone is not evidence of predictive power and often reflects over-optimization.

Out-of-sample testing evaluates the model on data not used during training. The full dataset can be partitioned chronologically as
\begin{align}
\mathcal{D} = \mathcal{D}_{\text{train}} \cup \mathcal{D}_{\text{test}}, \quad 
\max(t \in \mathcal{D}_{\text{train}}) < \min(t \in \mathcal{D}_{\text{test}}).
\end{align}

\textbf{Definition.} The following biases occur often:
\begin{itemize}

\item \textbf{Look-ahead bias} occurs when future information is inadvertently used in model training or feature construction. Common sources include using revised macroeconomic data rather than real-time releases, normalizing features using full-sample statistics, and using future returns in label construction

\item \textbf{Data snooping} occurs when repeated experimentation on the same dataset leads to models that exploit noise rather than signal. Data snooping inflates apparent performance and invalidates classical statistical inference.

\item \textbf{Survivorship bias} arises when datasets include only assets that survive until the end of the sample period. This leads to systematically overstated performance, particularly in equity and credit strategies. Examples include equity indices excluding delisted firms or funds databases omitting liquidated funds. Proper backtests must include dead assets and historically accurate index constituents.
\end{itemize}


\textbf{Definition.} Standard $k$-fold cross-validation assumes i.i.d.\ observations and is generally inappropriate for financial time series. Nevertheless, structured variants can be used with care. In \textbf{blocked} or \textbf{time-series $k$-fold cross-validation}, folds respect temporal ordering, with training data always preceding validation data. This provides multiple OOS estimates while limiting information leakage.


\textbf{Definition.} To reflect real-world deployment, models are often evaluated using \textbf{rolling windows} or \textbf{walk-forward analysis}. In a rolling window framework, parameters are re-estimated over a fixed-length window:
\begin{align}
[t_i - \Delta, t_i] \rightarrow \hat{\theta}_i,
\end{align}
and tested on a subsequent holdout period. Walk-forward analysis chains these windows forward through time, producing a realistic sequence of OOS predictions. This approach allows simultaneous evaluation of predictive performance, parameter stability, and sensitivity to market conditions.

A deployable model should exhibit stable parameters across calibration windows. Let $\hat{\theta}_t$ denote parameters estimated at time $t$. Instability can be assessed via
\begin{align}
\|\hat{\theta}_{t+1} - \hat{\theta}_t\| \quad \text{or} \quad \operatorname{Var}(\hat{\theta}_t).
\end{align}

\textbf{Remark.} Financial markets exhibit structural breaks and regime changes driven by macroeconomic shifts, monetary policy, or crises. Models calibrated in one regime may fail catastrophically in another.

\textbf{Definition.} \textbf{Stress testing} evaluates model behavior under extreme but plausible scenarios, such as volatility spikes, liquidity shocks, and correlation breakdowns. Stress testing complements backtesting by probing regions of the state space not well represented in historical data.

\textbf{Definition.} \textbf{Over-optimization} occurs when model complexity or hyperparameter tuning is excessive relative to the available data. It manifests as strong IS performance, rapid OOS decay, and high parameter instability. Regularization, simplicity constraints, and strict OOS evaluation are primary fixes.

\textbf{Definition.} For risk models such as Value-at-Risk (VaR), validation focuses on exceedance behavior. Let $\alpha$ denote the VaR confidence level and $I_t$ an indicator of violation:
\begin{align}
I_t = \mathbf{1}\{L_t > \text{VaR}_\alpha(t)\}.
\end{align}
The \textbf{Kupiec test} (unconditional coverage) assesses whether the empirical violation rate matches $\alpha$. The \textbf{Christoffersen test} extends this by testing both correct coverage and independence of violations. Together, these form the basis of regulatory backtesting standards for market risk models.

\chapter{Model Risk, Calibration, and Practical Pitfalls}

\textbf{Motivation.} Up to this point, the focus of these notes has been on constructing mathematically consistent models for asset prices and using no-arbitrage arguments to derive pricing formulas. In practice, however, all models are approximations. They are calibrated to incomplete and noisy data, embedded in market microstructure frictions, and used for decision-making under uncertainty. This chapter addresses the gap between theoretically sound models and their real-world deployment.

\section{The Nature of Model Risk}

\textbf{Definition.} \textbf{Model risk} refers to the risk of financial loss arising from the use of an incorrect, misspecified, or misapplied model. Unlike market risk, model risk is endogenous, created by the modeling choices themselves.

Model risk arises from several sources:
\begin{itemize}
\item \textbf{Structural assumptions:} continuous paths, lognormal returns, constant parameters, or complete markets.
\item \textbf{Parametric choices:} selecting a specific volatility or interest-rate model from many plausible alternatives.
\item \textbf{Calibration error:} fitting parameters to finite, noisy, and regime-dependent data.
\item \textbf{Implementation error:} numerical discretization, Monte Carlo error, or coding mistakes.
\end{itemize}

A key distinction is that no-arbitrage conditions constrain prices \emph{relative} to one another, but do not uniquely determine the correct dynamics of the underlying risk factors.

\textbf{Remark.} The existence of a risk-neutral measure guarantees internal consistency of prices, not correctness of the model relative to reality.

\section{Meanings of Measures}

A recurring conceptual distinction is between the real-world probability measure $\mathbb{P}$ and a risk-neutral (or pricing) measure $\mathbb{Q}$.

Under $\mathbb{P}$:
\begin{itemize}
\item Asset dynamics reflect statistical properties of realized returns.
\item Parameters are estimated from historical time series.
\item Expectations correspond to forecasts.
\end{itemize}

Under $\mathbb{Q}$:
\begin{itemize}
\item Discounted asset prices are martingales.
\item Parameters are chosen to reproduce observed market prices.
\item Expectations correspond to arbitrage-free prices, not forecasts.
\end{itemize}

These measures coincide only in very special cases. In general, there is no reason to expect risk premia, jump intensities, or volatility dynamics to agree under $\mathbb{P}$ and $\mathbb{Q}$.

\textbf{Example.} Implied volatility extracted from option prices reflects the market price of volatility risk. Historical volatility estimated from returns measures realized variance under $\mathbb{P}$. The discrepancy between the two is itself a tradable risk premium.

\section{Calibration as an Inverse Problem}

Model calibration is the process of choosing parameters $\theta$ such that model prices $V^{\text{model}}(\theta)$ match observed market prices $V^{\text{mkt}}$.

Typically, this is formulated as an optimization problem:
\begin{align}
\min_{\theta} \sum_{i} w_i \left(V_i^{\text{model}}(\theta) - V_i^{\text{mkt}}\right)^2,
\end{align}
where the weights $w_i$ reflect liquidity, bid--ask spreads, or confidence in the data.

This inverse problem is often:
\begin{itemize}
\item \textbf{Ill-posed:} multiple parameter sets yield similar prices.
\item \textbf{Unstable:} small data changes lead to large parameter shifts.
\item \textbf{Over-parameterized:} more degrees of freedom than informative constraints.
\end{itemize}

\textbf{Remark.} A good calibration fit does not imply a good model. It only implies interpolation of current prices.

\section{Regime Dependence}

Market parameters are not constant. Volatility surfaces, correlation structures, and credit spreads evolve over time, often discontinuously.

Common manifestations include:
\begin{itemize}
\item Volatility smiles shifting shape intraday.
\item Heston parameters recalibrating to different values day-to-day.
\item Correlations increasing sharply during crises.
\end{itemize}

This regime dependence implies that calibrated parameters should be viewed as \emph{state variables}, not immutable constants.

\textbf{Example.} A local volatility surface calibrated today may produce arbitrage-free prices for vanilla options, yet generate unrealistic forward smiles or unstable hedging behavior when used dynamically.

\section{Incomplete Markets}

Classical replication arguments rely on market completeness. In practice:
\begin{itemize}
\item Jumps destroy perfect hedging.
\item Stochastic volatility introduces unhedgeable risk.
\item Transaction costs prevent continuous rebalancing.
\end{itemize}

As a result, hedging strategies minimize risk rather than eliminate it. This reframes pricing as a trade-off between replication error and risk tolerance.

\textbf{Remark.} In incomplete markets, prices are no longer unique. They depend on preferences, constraints, and capital considerations.

\section{Numerical Error}

Even when a model is theoretically correct, numerical implementations introduce additional error:
\begin{itemize}
\item Time discretization bias in Monte Carlo simulation.
\item Grid instability in finite-difference schemes.
\item Poor convergence of optimization routines.
\end{itemize}

\textbf{Example.} A Monte Carlo estimator with insufficient time steps may systematically misprice barrier options due to discretization of path-dependent events.

\section{Backtesting and Validation}

A model that fits prices today must still be validated against future data. Common validation tools include:
\begin{itemize}
\item Out-of-sample pricing error.
\item Hedging PnL attribution.
\item Stability of calibrated parameters.
\item Sensitivity to market perturbations.
\end{itemize}

Backtesting failures often arise from:
\begin{itemize}
\item Look-ahead bias.
\item Overfitting to noise.
\item Ignoring transaction costs and liquidity.
\end{itemize}

\section{Machine Learning and Overfitting}

Machine learning methods exacerbate model risk if used without structural constraints. Key pitfalls include:
\begin{itemize}
\item High in-sample performance with poor generalization.
\item Lack of economic interpretability.
\item Sensitivity to regime shifts.
\end{itemize}

ML methods are most effective when combined with domain structure, such as no-arbitrage constraints or known symmetries.

\section{Practical Philosophy of Modeling}

A useful mental model is:
\begin{quote}
\emph{Models are tools, not truths.}
\end{quote}

Good models are internally consistent, calibrated transparently, and fail in understood and monitored ways.

\textbf{Final Remark.} The goal of quantitative finance is not to eliminate uncertainty, but to quantify, price, and manage it. Mathematical rigor provides the foundation, but robust skepticism determines success in practice.




\end{document}
